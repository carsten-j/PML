
<!-- saved from url=(0084)https://wouterboomsma.github.io/pml2024/week2/continuous_latent_variable_models.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="color-scheme" content="light dark"></head><body><div class="line-gutter-backdrop"></div><form autocomplete="off"><label class="line-wrap-control">Line wrap<input type="checkbox" aria-label="Line wrap"></label></form><table><tbody><tr><td class="line-number" value="1"></td><td class="line-content"><span class="html-doctype">&lt;!doctype html&gt;</span></td></tr><tr><td class="line-number" value="2"></td><td class="line-content"><span class="html-tag">&lt;html&gt;</span></td></tr><tr><td class="line-number" value="3"></td><td class="line-content">	<span class="html-tag">&lt;head&gt;</span></td></tr><tr><td class="line-number" value="4"></td><td class="line-content">		<span class="html-tag">&lt;meta <span class="html-attribute-name">charset</span>="<span class="html-attribute-value">utf-8</span>"&gt;</span></td></tr><tr><td class="line-number" value="5"></td><td class="line-content">		<span class="html-tag">&lt;meta <span class="html-attribute-name">name</span>="<span class="html-attribute-value">viewport</span>" <span class="html-attribute-name">content</span>="<span class="html-attribute-value">width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no</span>"&gt;</span></td></tr><tr><td class="line-number" value="6"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="7"></td><td class="line-content">		<span class="html-tag">&lt;title&gt;</span>Probabilistic Machine Learning<span class="html-tag">&lt;/title&gt;</span></td></tr><tr><td class="line-number" value="8"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="9"></td><td class="line-content">		<span class="html-tag">&lt;link <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/dist/reset.css" rel="noreferrer noopener">../reveal.js-4.5.0/dist/reset.css</a>"&gt;</span></td></tr><tr><td class="line-number" value="10"></td><td class="line-content">		<span class="html-tag">&lt;link <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/dist/reveal.css" rel="noreferrer noopener">../reveal.js-4.5.0/dist/reveal.css</a>"&gt;</span></td></tr><tr><td class="line-number" value="11"></td><td class="line-content">		<span class="html-tag">&lt;link <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/dist/theme/white-helv.css" rel="noreferrer noopener">../reveal.js-4.5.0/dist/theme/white-helv.css</a>"&gt;</span></td></tr><tr><td class="line-number" value="12"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="13"></td><td class="line-content">		<span class="html-comment">&lt;!-- Theme used for syntax highlighted code --&gt;</span></td></tr><tr><td class="line-number" value="14"></td><td class="line-content">		<span class="html-tag">&lt;link <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/googlecode.css" rel="noreferrer noopener">../googlecode.css</a>"&gt;</span></td></tr><tr><td class="line-number" value="15"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="16"></td><td class="line-content">		<span class="html-tag">&lt;style&gt;</span></td></tr><tr><td class="line-number" value="17"></td><td class="line-content">			.reveal .slides {</td></tr><tr><td class="line-number" value="18"></td><td class="line-content">				text-align: left;</td></tr><tr><td class="line-number" value="19"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="20"></td><td class="line-content">			.reveal a {</td></tr><tr><td class="line-number" value="21"></td><td class="line-content">				color:DarkSlateBlue;</td></tr><tr><td class="line-number" value="22"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="23"></td><td class="line-content">			.reveal section img {</td></tr><tr><td class="line-number" value="24"></td><td class="line-content">				border: 1px solid lightgrey;</td></tr><tr><td class="line-number" value="25"></td><td class="line-content">				box-shadow: none;</td></tr><tr><td class="line-number" value="26"></td><td class="line-content">				margin:0;</td></tr><tr><td class="line-number" value="27"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="28"></td><td class="line-content">			.reveal section img.noborder {</td></tr><tr><td class="line-number" value="29"></td><td class="line-content">				border: none;</td></tr><tr><td class="line-number" value="30"></td><td class="line-content">				box-shadow: none;</td></tr><tr><td class="line-number" value="31"></td><td class="line-content">				margin:0</td></tr><tr><td class="line-number" value="32"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="33"></td><td class="line-content">			.reveal section img.center {</td></tr><tr><td class="line-number" value="34"></td><td class="line-content">				display: block;</td></tr><tr><td class="line-number" value="35"></td><td class="line-content">				margin: 0 auto;</td></tr><tr><td class="line-number" value="36"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="37"></td><td class="line-content">			.reveal section div.container{</td></tr><tr><td class="line-number" value="38"></td><td class="line-content">				display: flex;</td></tr><tr><td class="line-number" value="39"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="40"></td><td class="line-content">			.reveal section div.container div{</td></tr><tr><td class="line-number" value="41"></td><td class="line-content">				flex: 1;</td></tr><tr><td class="line-number" value="42"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="43"></td><td class="line-content">			.reveal dt.spaced {</td></tr><tr><td class="line-number" value="44"></td><td class="line-content">				margin-top:0.5em;</td></tr><tr><td class="line-number" value="45"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="46"></td><td class="line-content">			.MathJax_Display {</td></tr><tr><td class="line-number" value="47"></td><td class="line-content">				font-size: 75% !important;</td></tr><tr><td class="line-number" value="48"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="49"></td><td class="line-content">			.katex {</td></tr><tr><td class="line-number" value="50"></td><td class="line-content">				font-size: 100% !important;</td></tr><tr><td class="line-number" value="51"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="52"></td><td class="line-content">			.reveal .katex-display {</td></tr><tr><td class="line-number" value="53"></td><td class="line-content">				margin-top:0.25em;</td></tr><tr><td class="line-number" value="54"></td><td class="line-content">				margin-bottom:0.25em;</td></tr><tr><td class="line-number" value="55"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="56"></td><td class="line-content">			.reveal .katex-display&gt;.katex {</td></tr><tr><td class="line-number" value="57"></td><td class="line-content">				text-align:left;</td></tr><tr><td class="line-number" value="58"></td><td class="line-content">				margin-left:1em;</td></tr><tr><td class="line-number" value="59"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="60"></td><td class="line-content">			.reveal section dl.list dt {</td></tr><tr><td class="line-number" value="61"></td><td class="line-content">				display:list-item;</td></tr><tr><td class="line-number" value="62"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="63"></td><td class="line-content">			.reveal section dl.list dd {</td></tr><tr><td class="line-number" value="64"></td><td class="line-content">				margin-left:0;</td></tr><tr><td class="line-number" value="65"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="66"></td><td class="line-content">		<span class="html-tag">&lt;/style&gt;</span></td></tr><tr><td class="line-number" value="67"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="68"></td><td class="line-content">	<span class="html-tag">&lt;/head&gt;</span></td></tr><tr><td class="line-number" value="69"></td><td class="line-content">	<span class="html-tag">&lt;body&gt;</span></td></tr><tr><td class="line-number" value="70"></td><td class="line-content">		<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">reveal</span>"&gt;</span></td></tr><tr><td class="line-number" value="71"></td><td class="line-content">			<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">slides</span>"&gt;</span></td></tr><tr><td class="line-number" value="72"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="73"></td><td class="line-content">				<span class="html-tag">&lt;section&gt;</span></td></tr><tr><td class="line-number" value="74"></td><td class="line-content">					<span class="html-tag">&lt;br/&gt;</span></td></tr><tr><td class="line-number" value="75"></td><td class="line-content">					<span class="html-tag">&lt;h1&gt;</span>Probabilistic <span class="html-tag">&lt;br&gt;</span>Machine Learning<span class="html-tag">&lt;/h1&gt;</span></td></tr><tr><td class="line-number" value="76"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>Week 2, Thursday<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="77"></td><td class="line-content">					<span class="html-comment">&lt;!-- &lt;dl&gt; --&gt;</span></td></tr><tr><td class="line-number" value="78"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:left; font-size:100%; border:1px solid lightgrey; background-color: #fafafa; padding:0.5em; display:inline-block; margin-top:0em</span>"&gt;</span></td></tr><tr><td class="line-number" value="79"></td><td class="line-content">						<span class="html-tag">&lt;h4 <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-bottom: 0.2em</span>"&gt;</span>Continuous latent variables<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="80"></td><td class="line-content">						<span class="html-tag">&lt;dl <span class="html-attribute-name">class</span>="<span class="html-attribute-value">list</span>"&gt;</span></td></tr><tr><td class="line-number" value="81"></td><td class="line-content">							<span class="html-tag">&lt;dt&gt;</span>Probabilistic PCA<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="82"></td><td class="line-content">							<span class="html-tag">&lt;dt&gt;</span>Inference: Stochastic VI<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="83"></td><td class="line-content">							<span class="html-tag">&lt;dt&gt;</span>Variational autoencoders<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="84"></td><td class="line-content">						<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="85"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="86"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span style="margin-left:-4em"&gt;Latent variable models:&lt;/span&gt;&lt;br&gt;--&gt;</span></td></tr><tr><td class="line-number" value="87"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;ul&gt;--&gt;</span></td></tr><tr><td class="line-number" value="88"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;li&gt;Discrete: Mixture models&lt;/li&gt;--&gt;</span></td></tr><tr><td class="line-number" value="89"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;li&gt;Continuous: Probabilistic PCA&lt;/li&gt;--&gt;</span></td></tr><tr><td class="line-number" value="90"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/ul&gt;--&gt;</span></td></tr><tr><td class="line-number" value="91"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="92"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="93"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:center</span>"&gt;</span></td></tr><tr><td class="line-number" value="94"></td><td class="line-content">					<span class="html-tag">&lt;h2&gt;</span>Continuous latent variable models<span class="html-tag">&lt;/h2&gt;</span></td></tr><tr><td class="line-number" value="95"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="96"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="97"></td><td class="line-content">				<span class="html-tag">&lt;section &gt;</span></td></tr><tr><td class="line-number" value="98"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="99"></td><td class="line-content">					<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="100"></td><td class="line-content">						<span class="html-tag">&lt;h3&gt;</span>How can we create a <span class="html-tag">&lt;em&gt;</span>continuous<span class="html-tag">&lt;/em&gt;</span> latent variable model?<span class="html-tag">&lt;/h2&gt;</span></td></tr><tr><td class="line-number" value="101"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="102"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 3.5</span>"&gt;</span></td></tr><tr><td class="line-number" value="103"></td><td class="line-content">							<span class="html-comment">&lt;!-- Ingredients:&lt;br&gt; --&gt;</span></td></tr><tr><td class="line-number" value="104"></td><td class="line-content">							<span class="html-tag">&lt;dl <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-left:0</span>"&gt;</span></td></tr><tr><td class="line-number" value="105"></td><td class="line-content">								<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>We must choose some continuous distribution over \(\boldsymbol z\) (sometimes referred to as a <span class="html-tag">&lt;em&gt;</span>prior<span class="html-tag">&lt;/em&gt;</span>). Let's use a Gaussian:<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="106"></td><td class="line-content">								<span class="html-tag">&lt;dd&gt;</span>\(p(\boldsymbol z) = \mathcal{N}(\boldsymbol z | 0, {\boldsymbol I)}\)<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="107"></td><td class="line-content">								<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="108"></td><td class="line-content">								<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>We must choose some an output distribution that depends on our latent variable. Let's use a linear relationship:<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="109"></td><td class="line-content">								<span class="html-tag">&lt;dd&gt;</span>\(p(\boldsymbol x | \boldsymbol z) = \mathcal{N}(\boldsymbol x | \boldsymbol W \boldsymbol z + \boldsymbol \mu, \sigma^2 \boldsymbol I)\)<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="110"></td><td class="line-content">								<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="111"></td><td class="line-content">							<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="112"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>The latent \(\boldsymbol z\) is \(M\)-dimensional, and \(\boldsymbol W\) is a \(D \times M\) matrix mapping linearly from \(\boldsymbol z\) to \(\boldsymbol x\).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="113"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="114"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Note the simplicity of the model: the elements of \(x\) are independent given \(\boldsymbol z\), and the variances for all elements are the same.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="115"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="116"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>This model is called <span class="html-tag">&lt;em&gt;</span>Probabilistic PCA<span class="html-tag">&lt;/em&gt;</span><span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="117"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="118"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>(for a refresher on PCA, see slides below)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="119"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="120"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="121"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align: center; margin-left:0.5em; margin-top:0.5em</span>"&gt;</span></td></tr><tr><td class="line-number" value="122"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:40%; padding:0.5em</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder prml</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/prmlfigs-svg/Figure9.4.svg" rel="noreferrer noopener">../prmlfigs-svg/Figure9.4.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="123"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="124"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:60%</span>"&gt;</span>(same graphical model as for the discrete case)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="125"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="126"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="127"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="128"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="129"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="130"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="131"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Remember PCA?<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="132"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="133"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Core idea: Reduce the number of dimensions by finding linear combinations of features that capture most of the variance in the data.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="134"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="135"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="136"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"  <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow:2</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span></td></tr><tr><td class="line-number" value="137"></td><td class="line-content">							Two formal definitions:</td></tr><tr><td class="line-number" value="138"></td><td class="line-content">							<span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="139"></td><td class="line-content">								<span class="html-tag">&lt;li&gt;</span>Maximize the variance of the projected data.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="140"></td><td class="line-content">								<span class="html-tag">&lt;li&gt;</span>Minimize the sum-of-squared of the projection errors.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="141"></td><td class="line-content">							<span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="142"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>"&gt;</span>These are equivalent.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="143"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="144"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>"&gt;</span>PCA is calculated as the eigenvectors of the data covariance matrix.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="145"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="146"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>"&gt;</span></td></tr><tr><td class="line-number" value="147"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%; height:80%; background-image: url('Q7HIP.gif'); background-position: 50% 50%; background-size: cover;</span>"&gt;</span><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="148"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="149"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-left:15%; margin-right:0%</span>"&gt;</span></td></tr><tr><td class="line-number" value="150"></td><td class="line-content">								<span class="html-tag">&lt;p <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:40%</span>"&gt;</span>Figure from <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://stats.stackexchange.com/a/140579" rel="noreferrer noopener">https://stats.stackexchange.com/a/140579</a>"&gt;</span>https://stats.stackexchange.com/a/140579<span class="html-tag">&lt;/a&gt;</span>.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="151"></td><td class="line-content">							<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="152"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;div style="position:relative; height:100%;"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="153"></td><td class="line-content"><span class="html-comment">&lt;!--								&lt;img class="noborder" style="width:100%; position:absolute; clip-path: inset(0px 20px 0px 20px);" src="Q7HIP.gif"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="154"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="155"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="156"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="157"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="158"></td><td class="line-content">					<span class="html-tag">&lt;aside <span class="html-attribute-name">class</span>="<span class="html-attribute-value">notes</span>"&gt;</span></td></tr><tr><td class="line-number" value="159"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>Intuition about PCA: consider a dataset of patient data (age, weight, height, various quantities measured in blood tests. Some of these features will likely be correlated. Woth PCA, we can look for linear combinations of these original features.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="160"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>The stackexchange link is actually worth reading - it gives a very nice explanation of PCA at different levels of detail.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="161"></td><td class="line-content">					<span class="html-tag">&lt;/aside&gt;</span></td></tr><tr><td class="line-number" value="162"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="163"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="164"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="165"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>"&gt;</span></td></tr><tr><td class="line-number" value="166"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="167"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>Why eigenvectors of the covariance matrix?<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="168"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="169"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="170"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow:4</span>"&gt;</span></td></tr><tr><td class="line-number" value="171"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Consider a multivariate Gaussian with covariance \(\Sigma\) and mean 0<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="172"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="173"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Since \(\Sigma\) is square, symmetric, we can diagonalize it<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="174"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="175"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:100%</span>"&gt;</span></td></tr><tr><td class="line-number" value="176"></td><td class="line-content">					\[\begin{align*}\Sigma &amp;= R\tilde \Sigma R^T \\</td></tr><tr><td class="line-number" value="177"></td><td class="line-content">					&amp;= \begin{bmatrix}\vert &amp; \vert &amp; \cdots &amp; \vert \\ v_1 &amp; v_2 &amp; \cdots &amp; v_D \\ \vert &amp; \vert &amp; \cdots &amp; \vert\end{bmatrix} \begin{bmatrix}\lambda_1 &amp; &amp; &amp; \\ &amp; \lambda_2 &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; \lambda_D \end{bmatrix} \begin{bmatrix}\rule[.5ex]{2.5ex}{0.1pt}~v_1^T~\rule[.5ex]{2.5ex}{0.1pt} \\ \rule[.5ex]{2.5ex}{0.1pt}~v_2^T~\rule[.5ex]{2.5ex}{0.1pt} \\ \vdots \\ \rule[.5ex]{2.5ex}{0.1pt}~v_D^T~\rule[.5ex]{2.5ex}{0.1pt} \end{bmatrix}\end{align*}\]</td></tr><tr><td class="line-number" value="178"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="179"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="180"></td><td class="line-content">							where \( v_1, \ldots, v_D \) are the eigenvectors and \(\lambda_1, \ldots, \lambda_D\) are the eigenvalues of \(\Sigma\).</td></tr><tr><td class="line-number" value="181"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="182"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div style="margin-left:1em; text-align:center"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="183"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;img class="noborder center" style="width:100%" src="pca_data.svg" alt=""&gt;--&gt;</span></td></tr><tr><td class="line-number" value="184"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="185"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;span style="font-size:55%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="186"></td><td class="line-content"><span class="html-comment">&lt;!--							\(\Sigma = \begin{bmatrix}--&gt;</span></td></tr><tr><td class="line-number" value="187"></td><td class="line-content"><span class="html-comment">&lt;!--							0.7 &amp; 0.4 \\--&gt;</span></td></tr><tr><td class="line-number" value="188"></td><td class="line-content"><span class="html-comment">&lt;!--							0.4 &amp; 0.5 \\--&gt;</span></td></tr><tr><td class="line-number" value="189"></td><td class="line-content"><span class="html-comment">&lt;!--							\end{bmatrix}\)--&gt;</span></td></tr><tr><td class="line-number" value="190"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="191"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="192"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="193"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="194"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="195"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="196"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="197"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="198"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="199"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>Why eigenvectors of the covariance matrix? (2)<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="200"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="201"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Plugging \(\boldsymbol \Sigma = \boldsymbol R\tilde {\boldsymbol \Sigma} \boldsymbol R^T\) into the Gaussian PDF, we have<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="202"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="203"></td><td class="line-content">					\[\begin{align*}p(\boldsymbol x | \boldsymbol \mu, \boldsymbol \Sigma) &amp;\propto \exp (-\frac{1}{2}\boldsymbol x^T (\boldsymbol R\tilde {\boldsymbol \Sigma} \boldsymbol R^T)^{-1} \boldsymbol x) \end{align*}\]</td></tr><tr><td class="line-number" value="204"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="205"></td><td class="line-content">					\[\begin{align*}\htmlStyle{visibility:hidden;}{p(\boldsymbol x | \boldsymbol \mu, \boldsymbol \Sigma)} &amp;\propto \exp (-\frac{1}{2}\boldsymbol x^T ((\boldsymbol R^T)^{-1}\tilde {\boldsymbol \Sigma}^{-1} \boldsymbol R^{-1}) \boldsymbol x) \hspace{2em}&amp; \text{inverse of matrix product}\end{align*}\]</td></tr><tr><td class="line-number" value="206"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="207"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="208"></td><td class="line-content">						\[\begin{align*}\htmlStyle{visibility:hidden;}{p(\boldsymbol x | \boldsymbol \mu, \boldsymbol \Sigma)}&amp;\propto \exp (-\frac{1}{2}\boldsymbol x^T (\boldsymbol R\tilde {\boldsymbol \Sigma}^{-1} \boldsymbol R^T) \boldsymbol x) \hspace{2em}&amp; \text{since } \boldsymbol R \text{ is orthogonal} \end{align*}\]</td></tr><tr><td class="line-number" value="209"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="210"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="211"></td><td class="line-content">						\[\begin{align*}\htmlStyle{visibility:hidden;}{p(\boldsymbol x | \boldsymbol \mu, \boldsymbol \Sigma)}&amp;\propto \exp (-\frac{1}{2}(\boldsymbol R^T \boldsymbol x)^T \tilde {\boldsymbol \Sigma}^{-1} (\boldsymbol R^T \boldsymbol x)) \hspace{2em} &amp;\text{ since } (AB)^T = B^TA^T\end{align*}\]</td></tr><tr><td class="line-number" value="212"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="213"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>\(R\) can thus be interpreted as the rotation matrix which we can apply to our data such that our new feature dimensions have no covariance. <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="214"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="215"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Note that the eigen<span class="html-tag">&lt;em&gt;</span>values<span class="html-tag">&lt;/em&gt;</span> are the variances along these dimensions.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="216"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="217"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>By sorting according to the eigenvalues (descending order) and choosing the top \(k\), we get a dimensionality reduction scheme that explains \(\frac{\sum_i^k\lambda_i}{\sum_i^D \lambda_i}\) of the total variance. <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="218"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="219"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="220"></td><td class="line-content">				<span class="html-tag">&lt;section&gt;</span></td></tr><tr><td class="line-number" value="221"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>Example<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="222"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="223"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="224"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align: center</span>"&gt;</span></td></tr><tr><td class="line-number" value="225"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/pca1.svg" rel="noreferrer noopener">pca1.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="226"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="227"></td><td class="line-content">								\[\begin{align*}\boldsymbol \Sigma &amp;= \begin{bmatrix}</td></tr><tr><td class="line-number" value="228"></td><td class="line-content">								0.7 &amp; 0.4 \\</td></tr><tr><td class="line-number" value="229"></td><td class="line-content">								0.4 &amp; 0.5 \\</td></tr><tr><td class="line-number" value="230"></td><td class="line-content">								\end{bmatrix} \\&amp;= \boldsymbol R\tilde {\boldsymbol \Sigma} \boldsymbol R^T\end{align*}\]</td></tr><tr><td class="line-number" value="231"></td><td class="line-content">							<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="232"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="233"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align: center</span>"&gt;</span></td></tr><tr><td class="line-number" value="234"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/pca2.svg" rel="noreferrer noopener">pca2.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="235"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="236"></td><td class="line-content">								\[\begin{align*}\boldsymbol R &amp;= \begin{bmatrix}</td></tr><tr><td class="line-number" value="237"></td><td class="line-content">								0.79 &amp; -0.62 \\</td></tr><tr><td class="line-number" value="238"></td><td class="line-content">								0.62 &amp; 0.79 \\</td></tr><tr><td class="line-number" value="239"></td><td class="line-content">								\end{bmatrix} \\</td></tr><tr><td class="line-number" value="240"></td><td class="line-content">								\tilde {\boldsymbol \Sigma} &amp;= \begin{bmatrix}</td></tr><tr><td class="line-number" value="241"></td><td class="line-content">								1.01 &amp; 0\\</td></tr><tr><td class="line-number" value="242"></td><td class="line-content">								0 &amp; 0.19 \\</td></tr><tr><td class="line-number" value="243"></td><td class="line-content">								\end{bmatrix}\end{align*}\]</td></tr><tr><td class="line-number" value="244"></td><td class="line-content">							<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="245"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="246"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align: center</span>"&gt;</span></td></tr><tr><td class="line-number" value="247"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/pca3.svg" rel="noreferrer noopener">pca3.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="248"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="249"></td><td class="line-content">							\(\boldsymbol R^T \boldsymbol x\)</td></tr><tr><td class="line-number" value="250"></td><td class="line-content">							<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="251"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="252"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="253"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="254"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="255"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="256"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="257"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="258"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Probabilistic PCA<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="259"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="260"></td><td class="line-content">					<span class="html-comment">&lt;!-- &lt;p&gt;A probabilistic equivalent of PCA can be formulated as a latent variable model - where the latent variable is now continous.&lt;/p&gt; --&gt;</span></td></tr><tr><td class="line-number" value="261"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="262"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="263"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="264"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 1.</span>"&gt;</span></td></tr><tr><td class="line-number" value="265"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Probabilistic PCA is similar to PCA - but here we focus on the generative process - mapping from a latent variable \(\boldsymbol z \rightarrow \boldsymbol x\).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="266"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="267"></td><td class="line-content">							<span class="html-tag">&lt;ol&gt;</span></td></tr><tr><td class="line-number" value="268"></td><td class="line-content">								<span class="html-tag">&lt;li&gt;</span>We generate uncorrelated values from an \(M\)-dimensional Gaussian to produce \(z\).<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="269"></td><td class="line-content">								<span class="html-tag">&lt;li&gt;</span>We then map from \(z\) to our \(D\) dimensional \(x\) using a linear mapping.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="270"></td><td class="line-content">							<span class="html-tag">&lt;/ol&gt;</span></td></tr><tr><td class="line-number" value="271"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="272"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="273"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align: center; margin-left:0.5em; margin-top:0.5em; </span>"&gt;</span></td></tr><tr><td class="line-number" value="274"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="275"></td><td class="line-content">							<span class="html-tag">&lt;dl <span class="html-attribute-name">style</span>="<span class="html-attribute-value">border:1px solid lightgrey; padding:1em; font-size:90%</span>"&gt;</span></td></tr><tr><td class="line-number" value="276"></td><td class="line-content">								<span class="html-tag">&lt;dt&gt;</span>Prior distribution over \(M\)-dimensional \(\boldsymbol z\):<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="277"></td><td class="line-content">								<span class="html-tag">&lt;dd&gt;</span>\(p(\boldsymbol z) = \mathcal{N}(\boldsymbol z | 0, {\boldsymbol I)}\)<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="278"></td><td class="line-content">								<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Distribution over \(D\)-dimensional output variable - conditioned on \(\boldsymbol z\)<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="279"></td><td class="line-content">								<span class="html-tag">&lt;dd&gt;</span>\(p(\boldsymbol x | \boldsymbol z) = \mathcal{N}(\boldsymbol x | \boldsymbol W \boldsymbol z + \boldsymbol \mu, \sigma^2 \boldsymbol I)\)<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="280"></td><td class="line-content">							<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="281"></td><td class="line-content">							<span class="html-comment">&lt;!-- &lt;img style="width:20%; padding-top:1em" class="noborder prml" src="../prmlfigs-svg/Figure9.4.svg"&gt; --&gt;</span></td></tr><tr><td class="line-number" value="282"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="283"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="284"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="285"></td><td class="line-content">					<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder prml</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-right: 0; margin-left:auto; display:block; width:70%;margin-top:-2em</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/prmlfigs-svg/Figure12.9.svg" rel="noreferrer noopener">../prmlfigs-svg/Figure12.9.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="286"></td><td class="line-content">					</td></tr><tr><td class="line-number" value="287"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="288"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="289"></td><td class="line-content">				<span class="html-comment">&lt;!-- &lt;section style="font-size:90%"&gt;</span></td></tr><tr><td class="line-number" value="290"></td><td class="line-content"><span class="html-comment">					&lt;p&gt;PPCA: Illustration of the generative process&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="291"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="292"></td><td class="line-content"><span class="html-comment">					&lt;img class="noborder center prml" style="width:90%;margin-top:1em" src="../prmlfigs-svg/Figure12.9.svg"&gt;</span></td></tr><tr><td class="line-number" value="293"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="294"></td><td class="line-content"><span class="html-comment">					&lt;p class="fragment"&gt;Note that \(\boldsymbol x \sim p(\boldsymbol x | \widehat {\boldsymbol z})\) can be implemented as \[\boldsymbol x  = \boldsymbol W \boldsymbol z + \boldsymbol \mu + \sigma \boldsymbol\epsilon \hspace{3em}\text{where }\epsilon \sim \mathcal{N}(0,\boldsymbol I)\]&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="295"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="296"></td><td class="line-content"><span class="html-comment">					&lt;aside class="notes"&gt;</span></td></tr><tr><td class="line-number" value="297"></td><td class="line-content"><span class="html-comment">						&lt;p&gt;In contrast to PCA, we focus on the generative process - mapping from a latent variable \(\boldsymbol z \rightarrow \boldsymbol x\).&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="298"></td><td class="line-content"><span class="html-comment">					&lt;/aside&gt;</span></td></tr><tr><td class="line-number" value="299"></td><td class="line-content"><span class="html-comment">				&lt;/section&gt; --&gt;</span></td></tr><tr><td class="line-number" value="300"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="301"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:80%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="302"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h4&gt;PPCA: \(p(\boldsymbol x)\) and \(p(\boldsymbol z| \boldsymbol x)\) have closed-form solutions&lt;/h4&gt;--&gt;</span></td></tr><tr><td class="line-number" value="303"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="304"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="305"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;div class="container"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="306"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="307"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;p&gt;Because of the linearity of the mapping, and the Gaussian output, the marginal \(p(\boldsymbol x)\) is again a Gaussian:&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="308"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="309"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="310"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="311"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;img class="noborder center prml" style="width:100%;margin-top:0.0em; margin-left:1em" src="../prmlfigs-svg/Figure12.9.svg"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="312"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="313"></td><td class="line-content"><span class="html-comment">&lt;!--&amp;lt;!&amp;ndash;							&lt;div style="width:100%; height:80%; background-image: url('../prmlfigs-svg/Figure12.9.svg'); background-position: 95%; background-size: cover;"&gt;&lt;/div&gt;&amp;ndash;&amp;gt;--&gt;</span></td></tr><tr><td class="line-number" value="314"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="315"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="316"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="317"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\begin{align*}p(\boldsymbol x) &amp;= \int p(\boldsymbol x | \boldsymbol z)p(\boldsymbol z) \mathrm{d}\boldsymbol z = \mathcal{N}(\boldsymbol x | \boldsymbol \mu, \boldsymbol C) \hspace*{2em} \text{ where } \boldsymbol C=\boldsymbol W \boldsymbol W^T + \sigma^2 \boldsymbol I\end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="318"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="319"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;The Woodbury matrix inversion identity helps us invert \(\boldsymbol C\)&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="320"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\boldsymbol C^{-1} = \sigma^{-2}\boldsymbol I - \sigma^{-2}\boldsymbol W \boldsymbol M^{-1} \boldsymbol W^T \hspace*{2em} \text{ where } \boldsymbol M=\boldsymbol W^T \boldsymbol W + \sigma^2 \boldsymbol I\]--&gt;</span></td></tr><tr><td class="line-number" value="321"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="322"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;The posterior, mapping from \(\boldsymbol x \rightarrow \boldsymbol z\) can now also be evaluated directly&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="323"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="324"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\begin{align*}p(\boldsymbol z | \boldsymbol x) = \mathcal{N}(\boldsymbol z | \boldsymbol M^{-1}W^T(\boldsymbol x - \boldsymbol \mu), \sigma^2 \boldsymbol M^{-1}) \hspace*{2em} \end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="325"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="326"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="327"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="328"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="329"></td><td class="line-content">				<span class="html-tag">&lt;section&gt;</span></td></tr><tr><td class="line-number" value="330"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="331"></td><td class="line-content">					<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="332"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Everything is nice about PPCA<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="333"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="334"></td><td class="line-content">					<span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="335"></td><td class="line-content">						<span class="html-tag">&lt;li&gt;</span>The joint \(p(\boldsymbol x, \boldsymbol z)\) is Gaussian.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="336"></td><td class="line-content">						<span class="html-tag">&lt;li&gt;</span>The marginal \(p(\boldsymbol x)\) is Gaussian.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="337"></td><td class="line-content">						<span class="html-tag">&lt;li&gt;</span>The posterior \(p(\boldsymbol z |\boldsymbol x)\) is Gaussian<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="338"></td><td class="line-content">						<span class="html-tag">&lt;li&gt;</span>Maximum likelihood estimation leads to standard PCA solution.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="339"></td><td class="line-content">					<span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="340"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="341"></td><td class="line-content">					(for details, see slides below)</td></tr><tr><td class="line-number" value="342"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="343"></td><td class="line-content">					<span class="html-tag">&lt;div  <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:1em</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="344"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow:2;</span>"&gt;</span></td></tr><tr><td class="line-number" value="345"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Q: But what if we want a more expressive mapping from \(z\) to \(x\)? <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="346"></td><td class="line-content">							\[p(\boldsymbol x | \boldsymbol z) = \mathcal{N}(\boldsymbol x | f_{\boldsymbol w_{\mu}}(\boldsymbol z), f_{\boldsymbol w_{\sigma^2}}(\boldsymbol z))\]</td></tr><tr><td class="line-number" value="347"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>A: Just as with the Bayesian Mixture model, we cannot use the EM algorithm, and will have to use approximate inference. We will again rely on variational inference, but with a few additional tricks.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="348"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span>	</td></tr><tr><td class="line-number" value="349"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align: center; margin-left:0.5em; margin-top:0.5em</span>"&gt;</span></td></tr><tr><td class="line-number" value="350"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:25%; padding:0.5em</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder prml</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/prmlfigs-svg/Figure9.4.svg" rel="noreferrer noopener">../prmlfigs-svg/Figure9.4.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="351"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span>						</td></tr><tr><td class="line-number" value="352"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="353"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="354"></td><td class="line-content">					<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="355"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="356"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="357"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>PPCA: The joint is Gaussian<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="358"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="359"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>A special property of the PPCA model is that the joint is Gaussian.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="360"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="361"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Consider the joint \(p(x,z) = p(x|z)p(z)\)&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="362"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="363"></td><td class="line-content">					\[\begin{align*} &amp;\ln p(\boldsymbol x, \boldsymbol z) = \ln (p(\boldsymbol x| \boldsymbol z)p(\boldsymbol z)) \\ &amp;= \ln p(\boldsymbol x | \boldsymbol z) + \ln p(\boldsymbol z) = \ln \mathcal{N}(\boldsymbol x | \boldsymbol W \boldsymbol z + \boldsymbol \mu, \sigma^2 \boldsymbol I) + \ln \mathcal{N}(\boldsymbol z| 0, \boldsymbol I) \\</td></tr><tr><td class="line-number" value="364"></td><td class="line-content">					&amp;=-\left (\frac{1}{2\sigma^2} (\boldsymbol x - \boldsymbol W \boldsymbol z - \boldsymbol \mu )^T(\boldsymbol x - \boldsymbol W \boldsymbol z - \boldsymbol \mu )  + \frac{1}{2}\boldsymbol z^T \boldsymbol z \right. \\ &amp; \hspace{8em} + \left.\frac{D}{2} \ln(2\pi\sigma^2) + \frac{M}{2} \ln (2\pi) \right)\end{align*}\]</td></tr><tr><td class="line-number" value="365"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="366"></td><td class="line-content">					\[\begin{align*}</td></tr><tr><td class="line-number" value="367"></td><td class="line-content">						&amp;=-\frac{1}{2\sigma^2} \bigg(\color{blue}\underbrace{\color{black}\boldsymbol x^T \boldsymbol x -  \boldsymbol x^T\boldsymbol W \boldsymbol z - \boldsymbol z^T \boldsymbol W^T \boldsymbol x + \boldsymbol z^T\boldsymbol W^T \boldsymbol W \boldsymbol z + \sigma^2\boldsymbol z^T \boldsymbol z}_{\color{blue}{=\begin{pmatrix}\boldsymbol z \\ \boldsymbol x\end{pmatrix}^T\begin{pmatrix}\boldsymbol W^T \boldsymbol W + \sigma^2 \boldsymbol I&amp; -\boldsymbol W^T \\-\boldsymbol W &amp; \boldsymbol I \end{pmatrix}\begin{pmatrix}\boldsymbol z \\ \boldsymbol x\end{pmatrix}}}        \\</td></tr><tr><td class="line-number" value="368"></td><td class="line-content">					&amp; \hspace*{4em}   {\color{blue}\underbrace{\color{black}-~\boldsymbol x^T \boldsymbol \mu + \boldsymbol z^T\boldsymbol W^T\boldsymbol \mu -\boldsymbol \mu^T\boldsymbol x + \boldsymbol \mu^T \boldsymbol W \boldsymbol z}_{=-2\begin{pmatrix}\boldsymbol z \\ \boldsymbol x\end{pmatrix}^T\begin{pmatrix}-\boldsymbol W^T\boldsymbol \mu\\\boldsymbol \mu\end{pmatrix} }} + \boldsymbol \mu^T \boldsymbol \mu\bigg)  -\frac{D}{2} \ln(2\pi\sigma^2) - \frac{M}{2} \ln (2\pi) \\</td></tr><tr><td class="line-number" value="369"></td><td class="line-content">					\end{align*}\]</td></tr><tr><td class="line-number" value="370"></td><td class="line-content">						<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="371"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="372"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="373"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="374"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="375"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>PPCA: The joint is Gaussian (2)<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="376"></td><td class="line-content">					\[\begin{align*} \ln p(\boldsymbol x, \boldsymbol z) &amp;= -\frac{1}{2\sigma^2} \begin{pmatrix}\boldsymbol z \\ \boldsymbol x\end{pmatrix}^T\begin{pmatrix}\boldsymbol W^T \boldsymbol W + \sigma^2 \boldsymbol I&amp; -\boldsymbol W^T \\-\boldsymbol W &amp; \boldsymbol I \end{pmatrix}\begin{pmatrix}\boldsymbol z \\ \boldsymbol x\end{pmatrix} + \frac{1}{\sigma^2}\begin{pmatrix}\boldsymbol z \\ \boldsymbol x\end{pmatrix}^T\begin{pmatrix}-\boldsymbol W^T\boldsymbol \mu\\\boldsymbol \mu\end{pmatrix} + \text{const}\end{align*}\]</td></tr><tr><td class="line-number" value="377"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="378"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="379"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>In general, we can write the exponent of a Gaussian as<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="380"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="381"></td><td class="line-content">					\[-\frac{1}{2}(\boldsymbol x- \boldsymbol \mu)^T\boldsymbol \Sigma^{-1}(\boldsymbol x- \boldsymbol \mu) = -\frac{1}{2}\boldsymbol x^T\boldsymbol \Sigma^{-1}\boldsymbol x + \boldsymbol x^T\boldsymbol \Sigma^{-1}\boldsymbol \mu + \text{const} \]</td></tr><tr><td class="line-number" value="382"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="383"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="384"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="385"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>We thus recognize \(\ln p(\boldsymbol x, \boldsymbol z)\) as a Gaussian log density \(\mathcal{N}(\mu_{z,x}, \Sigma_{z,x})\) with:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="386"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="387"></td><td class="line-content">					\[\boldsymbol \Sigma_{z,x}^{-1} = \begin{pmatrix}\frac{1}{\sigma^2}\boldsymbol W^T \boldsymbol W + \boldsymbol I &amp; -\frac{1}{\sigma^2}\boldsymbol W^T\\-\frac{1}{\sigma^2}\boldsymbol W &amp; \frac{1}{\sigma^2}\boldsymbol I \end{pmatrix} \hspace{1em}\Rightarrow\hspace*{1em} \underbrace{\boldsymbol \Sigma_{z,x} = \begin{pmatrix}\boldsymbol I &amp; \boldsymbol W^T \\ \boldsymbol W &amp; \sigma^2 \boldsymbol I + \boldsymbol W \boldsymbol W^T\end{pmatrix}}_{\text{Matrix Cookbook eq 399-400)}}\]</td></tr><tr><td class="line-number" value="388"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="389"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>and<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="390"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="391"></td><td class="line-content">					\[\boldsymbol \Sigma_{z,x}^{-1}\boldsymbol \mu_{z,x} = \frac{1}{\sigma^2}\begin{pmatrix}-\boldsymbol W^T\boldsymbol \mu\\\boldsymbol \mu\end{pmatrix}  \hspace{1em}\Rightarrow\hspace*{1em} \boldsymbol \mu_{z,x} = \begin{pmatrix}\boldsymbol 0\\ \boldsymbol \mu\end{pmatrix}\]</td></tr><tr><td class="line-number" value="392"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="393"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="394"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="395"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>"&gt;</span></td></tr><tr><td class="line-number" value="396"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="397"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>PPCA: marginal \(p(\boldsymbol x)\) is also Gaussian<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="398"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="399"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>We now know that \(p(\boldsymbol x, \boldsymbol z)\) is jointly Gaussian<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="400"></td><td class="line-content">					\[p(\boldsymbol x, \boldsymbol z) = \mathcal{N}(\boldsymbol \mu_{z,x}, \boldsymbol \Sigma_{z,x}) \hspace{2em}\boldsymbol \mu_{z,x} = \begin{pmatrix}\boldsymbol 0\\ \boldsymbol \mu\end{pmatrix} \hspace*{2em}\boldsymbol \Sigma_{z,x} = \begin{pmatrix}\boldsymbol I &amp; \boldsymbol W^T \\ \boldsymbol W &amp; \sigma^2 \boldsymbol I + \boldsymbol W \boldsymbol W^T\end{pmatrix}\]</td></tr><tr><td class="line-number" value="401"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="402"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>That means that the marginal \(p(\boldsymbol x)\) is also Gaussian. We can actually read off its parameters directly from \(\boldsymbol \mu_{z,x}\) and \(\boldsymbol \Sigma_{z,x}\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="403"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="404"></td><td class="line-content">					\[p(\boldsymbol x) = \mathcal{N}(\boldsymbol \mu_{x}, \boldsymbol \Sigma_{x}) \hspace{2em}\boldsymbol \mu_{x} = \boldsymbol \mu \hspace*{2em}\boldsymbol \Sigma_{x} = \sigma^2 \boldsymbol I + \boldsymbol W \boldsymbol W^T\]</td></tr><tr><td class="line-number" value="405"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="406"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span class="fragment"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="407"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;The Woodbury matrix inversion identity helps us invert \(\boldsymbol \Sigma_x\)&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="408"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\boldsymbol \Sigma_x^{-1} = \sigma^{-2}\boldsymbol I - \sigma^{-2}\boldsymbol W \boldsymbol M^{-1} \boldsymbol W^T \hspace*{2em} \text{ where } \boldsymbol M=\boldsymbol W^T \boldsymbol W + \sigma^2 \boldsymbol I\]--&gt;</span></td></tr><tr><td class="line-number" value="409"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="410"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="411"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="412"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="413"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="414"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>PPCA: the posterior is also Gaussian<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="415"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="416"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">border:1px solid lightgrey; padding:0.5em;</span>"&gt;</span></td></tr><tr><td class="line-number" value="417"></td><td class="line-content">						Remember - joint is gaussian:</td></tr><tr><td class="line-number" value="418"></td><td class="line-content">						<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%; </span>"&gt;</span></td></tr><tr><td class="line-number" value="419"></td><td class="line-content">					\[p(\boldsymbol x, \boldsymbol z) = \mathcal{N}(\boldsymbol \mu_{z,x}, \boldsymbol \Sigma_{z,x}) \hspace{2em}\boldsymbol \mu_{z,x} = \begin{pmatrix}\boldsymbol 0\\ \boldsymbol \mu\end{pmatrix} \hspace*{2em}\boldsymbol \Sigma_{z,x} = \begin{pmatrix}\boldsymbol I &amp; \boldsymbol W^T \\ \boldsymbol W &amp; \sigma^2 \boldsymbol I + \boldsymbol W \boldsymbol W^T\end{pmatrix}\]</td></tr><tr><td class="line-number" value="420"></td><td class="line-content">							<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="421"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="422"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="423"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Since the joint is Gaussian, we can evaluate the conditional \(p(\boldsymbol z |\boldsymbol x)\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="424"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="425"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Using eq 353 from the matrix cookbook, we have:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="426"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="427"></td><td class="line-content">					\[\begin{align*}p(\boldsymbol z | \boldsymbol x) = \mathcal{N}\big(\boldsymbol z |&amp; \boldsymbol 0 + \boldsymbol W^T (\sigma^2 \boldsymbol I + \boldsymbol W \boldsymbol W^T)^{-1}(\boldsymbol x - \boldsymbol \mu), \\&amp; \boldsymbol I - \boldsymbol W^T(\sigma^2 \boldsymbol I + \boldsymbol W \boldsymbol W^T)^{-1}\boldsymbol W \big)\end{align*}\]</td></tr><tr><td class="line-number" value="428"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="429"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>We can use the Woodbury identity (cookbook eq 159) for the inversion:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="430"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="431"></td><td class="line-content">					\[(\sigma^2 \boldsymbol I + \boldsymbol W \boldsymbol W^T)^{-1} = \sigma^{-2}\boldsymbol I - \sigma^{-2}\boldsymbol W \boldsymbol M^{-1} \boldsymbol W^T \hspace*{2em} \text{ where } \boldsymbol M=\boldsymbol W^T \boldsymbol W + \sigma^2 \boldsymbol I\]</td></tr><tr><td class="line-number" value="432"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="433"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;we have&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="434"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="435"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\begin{align*}p(\boldsymbol z | \boldsymbol x) = \mathcal{N}\big(\boldsymbol z |&amp; \boldsymbol 0 + \boldsymbol W^T (\sigma^2 \boldsymbol I + \boldsymbol W \boldsymbol W^T)^{-1}(\boldsymbol x - \boldsymbol \mu), \\&amp; \boldsymbol I - \boldsymbol W^T(\sigma^2 \boldsymbol I + \boldsymbol W \boldsymbol W^T)^{-1}\boldsymbol W \big)\end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="436"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="437"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="438"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="439"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="440"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>Parameter estimation - Maximum likelihood (1)<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="441"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="442"></td><td class="line-content">					<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder prml</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:20%; float:right</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/prmlfigs-svg/Figure12.10.svg" rel="noreferrer noopener">../prmlfigs-svg/Figure12.10.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="443"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="444"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="445"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 3</span>"&gt;</span></td></tr><tr><td class="line-number" value="446"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="447"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Log likelihood function:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="448"></td><td class="line-content">							\[ \begin{align*} ll(\boldsymbol \mu, \boldsymbol W, \sigma^2) &amp;= \ln p(\boldsymbol X | \boldsymbol \mu, \boldsymbol W, \sigma^2)  \\</td></tr><tr><td class="line-number" value="449"></td><td class="line-content">							&amp;=\sum_{n=1}^{N} \ln p(\boldsymbol x_n | \boldsymbol W, \boldsymbol \mu, \sigma^2) \\</td></tr><tr><td class="line-number" value="450"></td><td class="line-content">							&amp;=-\frac{N}{2}\left(\frac{D}{2}\ln(2\pi) + \ln(\textrm{det}(\boldsymbol \Sigma_x))\right) - \frac{1}{2} \sum_{n=1}^{N} (\boldsymbol x_n - \boldsymbol \mu)^T \boldsymbol \Sigma_x^{-1} (\boldsymbol x_n - \boldsymbol \mu) \\</td></tr><tr><td class="line-number" value="451"></td><td class="line-content">							\end{align*}\]</td></tr><tr><td class="line-number" value="452"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="453"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="454"></td><td class="line-content">							Optimize wrt \(\boldsymbol \mu\):</td></tr><tr><td class="line-number" value="455"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="456"></td><td class="line-content">							\[\begin{align*}\frac{\partial ll}{\partial \boldsymbol \mu} &amp;= -\frac{1}{2} \sum_{n=1}^{N} \frac{\partial ll}{\partial \boldsymbol \mu} \left (\boldsymbol  x_n - \boldsymbol \mu)^T \boldsymbol \Sigma_x^{-1} (\boldsymbol x_n - \boldsymbol \mu \right ) \\</td></tr><tr><td class="line-number" value="457"></td><td class="line-content">							&amp;= -\frac{1}{2} \sum_{n=1}^{N} -2 \boldsymbol \Sigma_x (\boldsymbol x_n - \boldsymbol \mu) \hspace{2em} \text{Matrix cookbook eq 86}\\</td></tr><tr><td class="line-number" value="458"></td><td class="line-content">							&amp;= 0 \Rightarrow \boldsymbol \mu_{\text{ML}} = \frac{1}{N}\sum_{n=1}^{N}\boldsymbol x_n = \bar {\boldsymbol x}</td></tr><tr><td class="line-number" value="459"></td><td class="line-content">							\end{align*}\]</td></tr><tr><td class="line-number" value="460"></td><td class="line-content">							<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="461"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="462"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="463"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;img class="noborder center prml" style="width:100%" src="../prmlfigs-svg/Figure12.10.svg"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="464"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="465"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="466"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="467"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="468"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="469"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="470"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>Parameter estimation - Maximum likelihood (2)<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="471"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="472"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Optimizing \(ll(\boldsymbol \mu, \boldsymbol W, \sigma^2)\) wrt to \(\boldsymbol W\) and \(\sigma^2\) is more difficult.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="473"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="474"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Tipping and Bishop prove in a 1999 paper that the likelihood is optimized when<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="475"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="476"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="477"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="478"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%</span>"&gt;</span></td></tr><tr><td class="line-number" value="479"></td><td class="line-content">					\[W_{ML} = \boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2}\boldsymbol R\]</td></tr><tr><td class="line-number" value="480"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="481"></td><td class="line-content">					\[\sigma^{2}_{ML} = \frac{1}{D-M}\sum_{i=M+1}^D \lambda_i\]</td></tr><tr><td class="line-number" value="482"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="483"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="484"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow:1.5; margin-top:-0.5em</span>"&gt;</span></td></tr><tr><td class="line-number" value="485"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Where \(\boldsymbol U_M\) is a \(D \times M\) matrix containing the M eigen vectors with largest eigenvalues, and \(\boldsymbol L_{M}\) is a diagonal matrix with the corresponding eigenvalues.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="486"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="487"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="488"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="489"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>The \(\boldsymbol W\) thus behaves exactly as in regular PCA. We can therefore also estimate it in the same way.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="490"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="491"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="492"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>\(\boldsymbol R\) is an arbitrary orthogonal matrix, which does not affect the covariance matrix:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="493"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="494"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%</span>"&gt;</span></td></tr><tr><td class="line-number" value="495"></td><td class="line-content">					\[\boldsymbol \Sigma_{x} =\sigma^2 \boldsymbol I + \underbrace{\boldsymbol W \boldsymbol W^T}_{\begin{align*}= (\boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2}\boldsymbol R)&amp;(\boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2}\boldsymbol R)^T\\ =\boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2}&amp; \underbrace{\boldsymbol R\boldsymbol R^T}_{=\boldsymbol I}(\boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2})^T \end{align*}} \]</td></tr><tr><td class="line-number" value="496"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="497"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="498"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>i.e. an arbitrary rotation of latent space.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="499"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="500"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="501"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="502"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:70%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="503"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h4&gt;Parameter estimation - Maximum likelihood (2)&lt;/h4&gt;--&gt;</span></td></tr><tr><td class="line-number" value="504"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="505"></td><td class="line-content"><span class="html-comment">&lt;!--					\[ll(\boldsymbol W, \sigma^2) = -\frac{N}{2}\left(\frac{D}{2}\ln(2\pi) + \ln(\textrm{det}(\boldsymbol \Sigma_x))\right) - \frac{1}{2} \sum_{n=1}^{N} (\boldsymbol x_n - \boldsymbol \mu_{\mathrm{ML}})^T \boldsymbol \Sigma_x^{-1} (\boldsymbol x_n - \boldsymbol \mu_{\mathrm{ML}})\]--&gt;</span></td></tr><tr><td class="line-number" value="506"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="507"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Since \((\boldsymbol x_n - \boldsymbol \mu)^T \boldsymbol \Sigma_x^{-1} (\boldsymbol x_n - \boldsymbol \mu)\) is a scalar, we are allowed to take its trace without affecting its value. Furthermore, we have \(\mathrm{tr}(ABC)=\mathrm{tr}(CAB)=\mathrm{tr}(BCA)\), so:&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="508"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="509"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\begin{align*}ll(\boldsymbol \mu, \boldsymbol W, \sigma^2) &amp;= -\frac{N}{2}\left(\frac{D}{2}\ln(2\pi) + \ln(\textrm{det}(\boldsymbol \Sigma_x))\right) - \frac{1}{2} \sum_{n=1}^{N} \mathrm{tr}(\boldsymbol \Sigma_x^{-1} (\boldsymbol x_n - \boldsymbol \mu)(\boldsymbol x_n - \boldsymbol \mu)^T) \\--&gt;</span></td></tr><tr><td class="line-number" value="510"></td><td class="line-content"><span class="html-comment">&lt;!--					&amp;= -\frac{N}{2}\left(\frac{D}{2}\ln(2\pi) + \ln(\textrm{det}(\boldsymbol \Sigma_x)) + \mathrm{tr}(\boldsymbol \Sigma_x^{-1} \boldsymbol S) \right ) \\ &amp;\hspace{2em} \text{ where } \boldsymbol S = \frac{1}{N} \sum_{n=1}^{N} (\boldsymbol x_n - \bar {\boldsymbol x})(\boldsymbol x_n - \bar {\boldsymbol x})^T ) \hspace{2em} \text{ and using } \mu_{\text{ML}} = \bar {\boldsymbol x} \end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="511"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="512"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="513"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="514"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:70%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="515"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h4&gt;Parameter estimation - Maximum likelihood (3)&lt;/h4&gt;--&gt;</span></td></tr><tr><td class="line-number" value="516"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="517"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span style="font-size:90%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="518"></td><td class="line-content"><span class="html-comment">&lt;!--					\[ll(\boldsymbol W, \sigma^2) = -\frac{N}{2}\left(\frac{D}{2}\ln(2\pi) + \ln(\textrm{det}(\boldsymbol C)) + \mathrm{tr}(\boldsymbol C^{-1} \boldsymbol S) \right ) \hspace*{2em} \boldsymbol C= \boldsymbol W \boldsymbol W^T + \sigma^2 \boldsymbol I\]--&gt;</span></td></tr><tr><td class="line-number" value="519"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="520"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="521"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Bishop proves in his 1999 paper that the likelihood is optimized when&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="522"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="523"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;div class="container"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="524"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="525"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span style="font-size:90%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="526"></td><td class="line-content"><span class="html-comment">&lt;!--					\[W_{ML} = \boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2}\boldsymbol R\]--&gt;</span></td></tr><tr><td class="line-number" value="527"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="528"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\sigma^{2}_{ML} = \frac{1}{D-M}\sum_{i=M+1}^D \lambda_i\]--&gt;</span></td></tr><tr><td class="line-number" value="529"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="530"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="531"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div style="flex-grow:1.5"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="532"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Where \(\boldsymbol U_M\) is a \(D \times M\) matrix containing the M eigen vectors with largest eigenvalues, and \(\boldsymbol L_{M}\) is a diagonal matrix with the corresponding eigenvalues.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="533"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="534"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="535"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="536"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;\(\boldsymbol R\) is an arbitrary orthogonal matrix, which does not affect the covariance matrix:&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="537"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="538"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span style="font-size:90%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="539"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\boldsymbol C_{\text{ML}}=\sigma^2 \boldsymbol I + \underbrace{\boldsymbol W_\text{ML} \boldsymbol W_\text{ML}^T}_{\begin{align*}= (\boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2}\boldsymbol R)&amp;(\boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2}\boldsymbol R)^T\\ =\boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2}&amp; \underbrace{\boldsymbol R\boldsymbol R^T}_{=\boldsymbol I}(\boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2})^T \end{align*}} \]--&gt;</span></td></tr><tr><td class="line-number" value="540"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="541"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="542"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;i.e. an arbitrary rotation of latent space.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="543"></td><td class="line-content"><span class="html-comment">&lt;!--&amp;lt;!&amp;ndash;						of the eigen vectors as its columns, and \(\boldsymbol L_{M}\) is a diagonal matrix with the corresponding eigenvalues.&lt;/p&gt;&amp;ndash;&amp;gt;--&gt;</span></td></tr><tr><td class="line-number" value="544"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="545"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="546"></td><td class="line-content"><span class="html-comment">&lt;!--&amp;lt;!&amp;ndash;						all stationary points with respect to \(\boldsymbol W\) can be written in the form&lt;/p&gt;&amp;ndash;&amp;gt;--&gt;</span></td></tr><tr><td class="line-number" value="547"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="548"></td><td class="line-content"><span class="html-comment">&lt;!--&amp;lt;!&amp;ndash;					\[W_{ML} = \boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2}\boldsymbol R\]&amp;ndash;&amp;gt;--&gt;</span></td></tr><tr><td class="line-number" value="549"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="550"></td><td class="line-content"><span class="html-comment">&lt;!--&amp;lt;!&amp;ndash;					&lt;p&gt;Where \(\boldsymbol U_M\) is a \(D \times M\) matrix containing M of the eigen vectors as its columns, and \(\boldsymbol L_{M}\) is a diagonal matrix with the corresponding eigenvalues.&lt;/p&gt;&amp;ndash;&amp;gt;--&gt;</span></td></tr><tr><td class="line-number" value="551"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="552"></td><td class="line-content"><span class="html-comment">&lt;!--&amp;lt;!&amp;ndash;					&lt;p&gt;This likelihood is optimized when the columns of \(\boldsymbol W\) are chosen to be eigenvectors of \(\boldsymbol S\) with highest eigenvalues.&lt;/p&gt;&amp;ndash;&amp;gt;--&gt;</span></td></tr><tr><td class="line-number" value="553"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="554"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="555"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="556"></td><td class="line-content">					<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="557"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>Interpretation of Probabilistic PCA<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="558"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="559"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>Consider a direction in your output space, represented by unit vector \(\boldsymbol v\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="560"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="561"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>According to the PPCA model, the variance along this direction is \(\boldsymbol v^T \boldsymbol \Sigma_x \boldsymbol v\).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="562"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="563"></td><td class="line-content">						Consider two scenarios:</td></tr><tr><td class="line-number" value="564"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="565"></td><td class="line-content">						<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="566"></td><td class="line-content">							<span class="html-tag">&lt;dt&gt;</span>1. \(\boldsymbol v\) is orthogonal to the \(M\) selected principal component vectors<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="567"></td><td class="line-content">							<span class="html-tag">&lt;dd&gt;</span></td></tr><tr><td class="line-number" value="568"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="569"></td><td class="line-content">								\[\boldsymbol v^T \boldsymbol \Sigma_x \boldsymbol v = \boldsymbol v^T\sigma^2 \boldsymbol I \boldsymbol v + \underbrace{\boldsymbol v^T\boldsymbol U_M}_{=0}( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2}(\boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2})^T \boldsymbol v = \color{red}{\sigma^2}\]</td></tr><tr><td class="line-number" value="570"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="571"></td><td class="line-content">							<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="572"></td><td class="line-content">							<span class="html-tag">&lt;dt&gt;</span>2. \(\boldsymbol v\) points along the \(i\)th eigenvector<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="573"></td><td class="line-content">							<span class="html-tag">&lt;dd&gt;</span></td></tr><tr><td class="line-number" value="574"></td><td class="line-content">								\[\boldsymbol v^T \boldsymbol \Sigma \boldsymbol v = \boldsymbol v^T\sigma^2 \boldsymbol I \boldsymbol v + {\underbrace{\boldsymbol v^T\boldsymbol U_M( \boldsymbol L_M - \sigma^2 \boldsymbol I)}_{ (\lambda_i - \sigma^2)^{1/2}}}^{1/2}\underbrace{(( \boldsymbol L_M - \sigma^2 \boldsymbol I)^{1/2})^T\boldsymbol U_M^T \boldsymbol v}_{(\lambda_i - \sigma^2)^{1/2}} = \color{red}{\lambda_i}\]</td></tr><tr><td class="line-number" value="575"></td><td class="line-content">							<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="576"></td><td class="line-content">						<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="577"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="578"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>This is quite nice! For all the principal components that we have included, the model correctly captures the variance of the data. For those directions that we leave out, it uses \(\sigma^2 = \frac{1}{D-M}\sum_{i=M+1}^D \lambda_i\), i.e. the average variance of the left-out principal components.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="579"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="580"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="581"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>"&gt;</span></td></tr><tr><td class="line-number" value="582"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Application of PPCA<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="583"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="584"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>When modelling continuous data in \(D\) dimensions, you will often have to make the following choice:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="585"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="586"></td><td class="line-content">					<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="587"></td><td class="line-content">						<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Use a full covariance matrix<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="588"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span>For high dimensions, the \(D \times D\) can be difficult to estimate, requiring a lot of data.<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="589"></td><td class="line-content">						<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Use a diagonal covariance matrix<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="590"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span>Now, you only need to estimate \(D\) variance values - but you assume that there is no covariance among the dimensions, which is probably unrealistic.<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="591"></td><td class="line-content">					<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="592"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="593"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Probabilistic PCA provides an intermediate between these extremes - allowing you to include the most important covariances while summarizing the remaining variances with an average.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="594"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="595"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="596"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="597"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="598"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="599"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%</span>"&gt;</span></td></tr><tr><td class="line-number" value="600"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Factor analysis<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="601"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="602"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Factor analysis is similar to Probabilistic PCA, but with slightly more complex output covariance<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="603"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="604"></td><td class="line-content">					\(p(x|z) = \mathcal{N}(\boldsymbol x | \boldsymbol W \boldsymbol z + \mu, \boldsymbol I\boldsymbol \sigma^2)\)</td></tr><tr><td class="line-number" value="605"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="606"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Remember that in Probabilisic PCA we had simply:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="607"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="608"></td><td class="line-content">					\(p(x|z) = \mathcal{N}(\boldsymbol x | \boldsymbol W \boldsymbol z + \mu, \boldsymbol I \sigma^2)\)</td></tr><tr><td class="line-number" value="609"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="610"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>In Factor analysis, we thus estimate variances for all data dimensions separately.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="611"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="612"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>With this small change, the model no longer has a closed-form maximum likelihood solution. We can instead use EM.<span class="html-tag">&lt;/p&gt;</span> </td></tr><tr><td class="line-number" value="613"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="614"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="615"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="616"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>"&gt;</span></td></tr><tr><td class="line-number" value="617"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Probabilistic PCA - Summary<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="618"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="619"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Probabilistic PCA is a simple continuous latent variable model that brings PCA functionality into the rich framework of probabilistic modelling<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="620"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="621"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Due to the particular choice of output variance, there is a closed-form maximum likelihood solution to the \(\boldsymbol W, \boldsymbol \mu, \sigma\) parameters. We can also use EM, which can be more efficient in higher dimensions.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="622"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="623"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>In Factor Analysis, we change this assumption (now having separate variances for each dimension). This no longer has a closed form maximum likelihood solution.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="624"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="625"></td><td class="line-content">					<span class="html-comment">&lt;!-- &lt;p class="fragment"&gt;For both models, we should remember that the maximum likelihood only determines the latent space up to an arbitrary rotation.&lt;/p&gt; --&gt;</span></td></tr><tr><td class="line-number" value="626"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="627"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="628"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="629"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="630"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="631"></td><td class="line-content">				<span class="html-tag">&lt;section&gt;</span></td></tr><tr><td class="line-number" value="632"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>EM for Probabilistic PCA<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="633"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="634"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Can't we use EM to estimate the parameters of the PPCA model?<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="635"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="636"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="637"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>Yes we can! But why would we want to do that when we have a closed form solution?<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="638"></td><td class="line-content">					<span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="639"></td><td class="line-content">						<span class="html-tag">&lt;li <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Can be faster in higher dimensions.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="640"></td><td class="line-content">						<span class="html-tag">&lt;li <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Is necessary for other models, like Factor analysis.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="641"></td><td class="line-content">						<span class="html-tag">&lt;li <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Natural way to deal with missing data.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="642"></td><td class="line-content">					<span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="643"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="644"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="645"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="646"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="647"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="648"></td><td class="line-content">				<span class="html-tag">&lt;section&gt;</span></td></tr><tr><td class="line-number" value="649"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>EM for Probabilistic PCA (2)<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="650"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="651"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Same procedure as for mixture models<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="652"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="653"></td><td class="line-content">					In iteration \(t\):</td></tr><tr><td class="line-number" value="654"></td><td class="line-content">					<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="655"></td><td class="line-content">						<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Expectation step:<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="656"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span>Calculate the expectation of the complete-data likelihood \(p(\boldsymbol X, \boldsymbol Z | \boldsymbol \mu, \boldsymbol W, \sigma^2)\), under the distribution \(p(z|x, \boldsymbol \mu_{t-1}, \boldsymbol W_{t-1}, \sigma_{t-1}^2)\)<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="657"></td><td class="line-content">						<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Maximization step<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="658"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span>Optimize this completed likelihood to obtain new values \(\boldsymbol \mu_{t}, \boldsymbol W_{t}, \sigma_{t}^2\)<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="659"></td><td class="line-content">					<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="660"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="661"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="662"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="663"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="664"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>EM for Probabilistic PCA - E-step<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="665"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="666"></td><td class="line-content">					Complete-data log-likelihood:</td></tr><tr><td class="line-number" value="667"></td><td class="line-content">					\[\begin{align*} ll_c = \ln p(\boldsymbol X, \boldsymbol Z &amp;| \boldsymbol \mu, \boldsymbol W, \sigma^2) = \sum_{n=1}^N \left( \ln p(\boldsymbol x_n | z_n) + \ln p(z_n)\right) \\</td></tr><tr><td class="line-number" value="668"></td><td class="line-content">					&amp;= \sum_{n=1}^N \left (\ln \left(\mathcal{N}(\boldsymbol x_n | \boldsymbol W \boldsymbol z_n + \boldsymbol \mu, \sigma^2 \boldsymbol I) + \mathcal{N}(z| 0, \boldsymbol I)\right ) \right)\\</td></tr><tr><td class="line-number" value="669"></td><td class="line-content">					&amp;=-\sum_{n=1}^N \left (\frac{D}{2} \ln(2\pi\sigma^2) + \frac{1}{2\sigma^2}||\boldsymbol x_n - \boldsymbol W \boldsymbol z_n - \boldsymbol \mu ||^2  + \frac{M}{2} \ln (2\pi) + \frac{1}{2}\boldsymbol z_n^T \boldsymbol z_n\right)\\</td></tr><tr><td class="line-number" value="670"></td><td class="line-content">					&amp;=-\sum_{n=1}^N \bigg (\frac{D}{2} \ln(2\pi\sigma^2) + \frac{1}{2\sigma^2}||\boldsymbol x_n - \boldsymbol \mu ||^2 + \frac{1}{2\sigma^2}\underbrace{(\boldsymbol W \boldsymbol z_n)^T(\boldsymbol W \boldsymbol z_n)}_{=\boldsymbol z_n^T \boldsymbol W^T \boldsymbol W \boldsymbol z_n = \mathrm{tr}( \boldsymbol z_n \boldsymbol z_n^T \boldsymbol W^T \boldsymbol W)}  \\ &amp; \hspace{4em} - \frac{1}{\sigma^2}\underbrace{(\boldsymbol W \boldsymbol z_n)^T}_{=\boldsymbol z_n^T\boldsymbol W^T}(\boldsymbol x_n - \boldsymbol \mu) + \frac{M}{2} \ln (2\pi) + \frac{1}{2}\underbrace{\boldsymbol z_n^T \boldsymbol z_n}_{=\mathrm{tr}(\boldsymbol z_n \boldsymbol z_n^T)}\bigg)</td></tr><tr><td class="line-number" value="671"></td><td class="line-content">					\end{align*}\]</td></tr><tr><td class="line-number" value="672"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="673"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="674"></td><td class="line-content">					<span class="html-comment">&lt;!--				\mathbb{E}_{\boldsymbol Z}--&gt;</span></td></tr><tr><td class="line-number" value="675"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="676"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="677"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="678"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="679"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>EM for Probabilistic PCA - E-step (2)<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="680"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="681"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Taking the expectation wrt \(z\):<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="682"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="683"></td><td class="line-content">					\[\begin{align*}</td></tr><tr><td class="line-number" value="684"></td><td class="line-content">					\mathbb{E}_{\boldsymbol Z}[ll_c] = -\sum_{n=1}^N &amp;\bigg (\frac{D}{2} \ln(2\pi\sigma^2) + \frac{1}{2\sigma^2}||\boldsymbol x_n - \boldsymbol \mu ||^2 + \frac{1}{2\sigma^2}\mathrm{tr}(\mathbb{E}_{\boldsymbol Z}[\boldsymbol z_n \boldsymbol z_n^T] \boldsymbol W^T \boldsymbol W)  \\&amp;- \frac{1}{\sigma^2}(\mathbb{E}_{\boldsymbol Z}[\boldsymbol z_n]^T\boldsymbol W^T)(\boldsymbol x_n - \boldsymbol \mu) + \frac{M}{2} \ln (2\pi) + \frac{1}{2}\mathrm{tr}(\boldsymbol z_n \boldsymbol z_n^T)\bigg)</td></tr><tr><td class="line-number" value="685"></td><td class="line-content">					\end{align*}\]</td></tr><tr><td class="line-number" value="686"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="687"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Remember that all these expectations are taken wrt \[p(\boldsymbol z | \boldsymbol x) = \mathcal{N}(\boldsymbol z | \boldsymbol M_{t-1}^{-1}\boldsymbol W_{t-1}^T(\boldsymbol x - \boldsymbol \mu_{t-1}), \sigma_{t-1}^2 \boldsymbol M_{t-1}^{-1}) \hspace*{1em} \text{ where } \boldsymbol M_{t-1}=\boldsymbol W_{t-1}^T \boldsymbol W_{t-1} + \sigma_{t-1}^2 \boldsymbol I\]<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="688"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="689"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="690"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>So, in the E-step, all we need to calculate is:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="691"></td><td class="line-content">					\[\mathbb{E}_{\boldsymbol Z}[z_n] = \boldsymbol M_{t-1}^{-1} \boldsymbol W_{t-1}^T (\boldsymbol x - \boldsymbol \mu_{t-1}) \]</td></tr><tr><td class="line-number" value="692"></td><td class="line-content">					\[\mathbb{E}_{\boldsymbol Z}[z_nz_n^T] = \sigma_{t-1}^2\boldsymbol M_{t-1}^{-1} + \mathbb{E}_{\boldsymbol Z}[\boldsymbol z_n]\mathbb{E}_{\boldsymbol Z}[\boldsymbol z_n] \hspace{3em} \text{ since } \mathrm{cov}(z_n) = \mathbb{E}_{\boldsymbol Z}[z_n z_n^T] - \mathbb{E}_{\boldsymbol Z}[z_n]\mathbb{E}_{\boldsymbol Z}[z_n]\]</td></tr><tr><td class="line-number" value="693"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="694"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="695"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:2em</span>"&gt;</span>For the M-step, we can now differentiate \(ll_c\) wrt \(\boldsymbol W\) and \(\sigma^2\) and set to zero.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="696"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="697"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="698"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="699"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="700"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="701"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="702"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:center</span>"&gt;</span></td></tr><tr><td class="line-number" value="703"></td><td class="line-content">					<span class="html-tag">&lt;h2&gt;</span>Stochastic variational inference<span class="html-tag">&lt;/h2&gt;</span></td></tr><tr><td class="line-number" value="704"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="705"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="706"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="707"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Variational Inference: Where were we?<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="708"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="709"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="710"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow:2</span>"&gt;</span></td></tr><tr><td class="line-number" value="711"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>In the lecture on variational inference, we discussed the following recipe for variational inference:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="712"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="713"></td><td class="line-content">								<span class="html-tag">&lt;ol&gt;</span></td></tr><tr><td class="line-number" value="714"></td><td class="line-content">									<span class="html-tag">&lt;li&gt;</span>Specify model<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="715"></td><td class="line-content">									<span class="html-tag">&lt;li&gt;</span>Choose family for \(q\). Typically mean field family.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="716"></td><td class="line-content">									<span class="html-tag">&lt;li&gt;</span>Write up ELBO<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="717"></td><td class="line-content">								<span class="html-tag">&lt;/ol&gt;</span></td></tr><tr><td class="line-number" value="718"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="719"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="720"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div style="margin-left:2em;"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="721"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;img class="noborder" style="width:100%" src="hoffman_conditional_conjugate.svg" alt=""&gt;--&gt;</span></td></tr><tr><td class="line-number" value="722"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;div style="font-size:50%"&gt;Adapted from &lt;em&gt;Stochastic Variational Inference&lt;/em&gt;, Hoffman, Blei, Wang, Paisley, 2013&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="723"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="724"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="725"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="726"></td><td class="line-content">					<span class="html-tag">&lt;ol <span class="html-attribute-name">start</span>="<span class="html-attribute-value">4</span>"&gt;</span></td></tr><tr><td class="line-number" value="727"></td><td class="line-content">						<span class="html-tag">&lt;li&gt;</span>Derive re-estimation rule for local latent variables, \(z_n\)<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="728"></td><td class="line-content">						<span class="html-tag">&lt;li&gt;</span>Derive re-estimation rule for global latent variables, \(\beta\)<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="729"></td><td class="line-content">					<span class="html-tag">&lt;/ol&gt;</span></td></tr><tr><td class="line-number" value="730"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="731"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>We saw that the reestimation steps take on particularly nice forms when we limit ourselves to exponential families and <span class="html-tag">&lt;em&gt;</span>conditional conjugate<span class="html-tag">&lt;/em&gt;</span> models.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="732"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="733"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p class="fragment"&gt;To understand what this means, we'll now briefly revisit exponential families and conjugacy&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="734"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="735"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="736"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="737"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="738"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="739"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:75%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="740"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h3&gt;Exponential family distributions&lt;/h3&gt;--&gt;</span></td></tr><tr><td class="line-number" value="741"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="742"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;div class="container"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="743"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="744"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;p&gt;The pdf of Distributions from the exponential family can be written as (1D case):&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="745"></td><td class="line-content"><span class="html-comment">&lt;!--							\[p(x | \theta) = h(x)\exp\left[\eta(\theta) t(x) - \alpha(\theta) \right]\]--&gt;</span></td></tr><tr><td class="line-number" value="746"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="747"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;span class="fragment"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="748"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;p&gt;...or in multiple dimensions&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="749"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="750"></td><td class="line-content"><span class="html-comment">&lt;!--							\[p(\boldsymbol x | \boldsymbol \theta) = h(\boldsymbol x)\exp\left[\eta(\boldsymbol \theta) \cdot t(\boldsymbol x) - \alpha(\boldsymbol \theta) \right]\]--&gt;</span></td></tr><tr><td class="line-number" value="751"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="752"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="753"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="754"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div class="fragment" style="font-size:80%; padding:1em;"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="755"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;div style="border:1px solid lightgrey; background-color: #fafafa; padding:0.5em"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="756"></td><td class="line-content"><span class="html-comment">&lt;!--								&lt;dl&gt;--&gt;</span></td></tr><tr><td class="line-number" value="757"></td><td class="line-content"><span class="html-comment">&lt;!--									&lt;dt&gt;\(t(\boldsymbol x)\)&lt;/dt&gt;--&gt;</span></td></tr><tr><td class="line-number" value="758"></td><td class="line-content"><span class="html-comment">&lt;!--									&lt;dd&gt;Sufficient statistics. All information from the data required to determine parameters of interest&lt;/dd&gt;--&gt;</span></td></tr><tr><td class="line-number" value="759"></td><td class="line-content"><span class="html-comment">&lt;!--									&lt;dt&gt;\(\alpha(\boldsymbol \theta)\)&lt;/dt&gt;--&gt;</span></td></tr><tr><td class="line-number" value="760"></td><td class="line-content"><span class="html-comment">&lt;!--									&lt;dd&gt;Logarithm of a normalization constant&lt;/dd&gt;--&gt;</span></td></tr><tr><td class="line-number" value="761"></td><td class="line-content"><span class="html-comment">&lt;!--									&lt;dt&gt;\(\eta = \eta(\boldsymbol \theta)\)&lt;/dt&gt;--&gt;</span></td></tr><tr><td class="line-number" value="762"></td><td class="line-content"><span class="html-comment">&lt;!--									&lt;dd&gt;Transformation of parameters into &lt;em&gt;natural parameters&lt;/em&gt;. &lt;/dd&gt;--&gt;</span></td></tr><tr><td class="line-number" value="763"></td><td class="line-content"><span class="html-comment">&lt;!--								&lt;/dl&gt;--&gt;</span></td></tr><tr><td class="line-number" value="764"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="765"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="766"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="767"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="768"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="769"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="770"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:70%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="771"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h3&gt;Exponential family distributions (2)&lt;/h3&gt;--&gt;</span></td></tr><tr><td class="line-number" value="772"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="773"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;The exponential family form of a pdf factorizes specifically to highlight the dependence on the sufficient statistics. This means that the same distribution will have different forms depending on which parameters are considered unknown:&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="774"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="775"></td><td class="line-content"><span class="html-comment">&lt;!--					&amp;lt;!&amp;ndash;					Examples:&lt;br&gt;&amp;ndash;&amp;gt;--&gt;</span></td></tr><tr><td class="line-number" value="776"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;dl&gt;--&gt;</span></td></tr><tr><td class="line-number" value="777"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;dt&gt;Normal distribution with fixed \(\sigma\), unknown \(\mu\)&lt;/dt&gt;--&gt;</span></td></tr><tr><td class="line-number" value="778"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;dd style="font-size:90%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="779"></td><td class="line-content"><span class="html-comment">&lt;!--							\[\begin{align*}p(x|\mu) &amp;= \frac{1}{\sqrt{2\pi\sigma^2}}\exp(-(x-\mu)^2/2\sigma^2) \\&amp;= \underbrace{\frac{1}{\sqrt{2\pi\sigma^2}}\exp(-x^2/2\sigma^2)}_{h(x)}\exp\left(\underbrace{\frac{\mu}{\sigma}}_{\eta(\mu)}\underbrace{\frac{x}{\sigma}}_{t(x)} - \underbrace{\frac{\mu^2}{2\sigma^2}}_{\alpha(\mu)}      \right)\end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="780"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/dd&gt;--&gt;</span></td></tr><tr><td class="line-number" value="781"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;dt&gt;Normal distribution with unknown \(\sigma\) and unknown \(\mu\)&lt;/dt&gt;--&gt;</span></td></tr><tr><td class="line-number" value="782"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;dd  style="font-size:90%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="783"></td><td class="line-content"><span class="html-comment">&lt;!--							\[\begin{align*}p(x|\mu,\sigma) &amp;= \frac{1}{\sqrt{2\pi\sigma^2}}\exp(-(x-\mu)^2/2\sigma^2) \\&amp;= \underbrace{\frac{1}{\sqrt{2\pi}}}_{h(x)}\exp\left(\underbrace{\begin{bmatrix}\frac{\mu}{\sigma^2} \\ -\frac{1}{2\sigma^2}\end{bmatrix}}_{\eta(\mu, \sigma)}\cdot\underbrace{\begin{bmatrix}x\\x^2\end{bmatrix}\\}_{t(x)} - \underbrace{\frac{\mu^2}{2\sigma^2} + \ln \sigma}_{\alpha(\mu, \sigma)}      \right)\end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="784"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/dd&gt;--&gt;</span></td></tr><tr><td class="line-number" value="785"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/dl&gt;--&gt;</span></td></tr><tr><td class="line-number" value="786"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="787"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="788"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="789"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:75%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="790"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h3&gt;Conjugate priors&lt;/h3&gt;--&gt;</span></td></tr><tr><td class="line-number" value="791"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="792"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;div style="float:right; font-size:90%;border:1px solid lightgrey; padding-right:0.5em; padding-top:0.5em; padding-bottom:0.5em; margin:1em; background-color: #fafafa; "&gt;--&gt;</span></td></tr><tr><td class="line-number" value="793"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\underbrace{p(\boldsymbol z|\boldsymbol x)}_{\text{posterior}} = \frac{\overbrace{p(\boldsymbol x|\boldsymbol z)}^{\text{likelihood}}\overbrace{p(\boldsymbol z)}^{\text{prior}}}{\underbrace{p(\boldsymbol x)}_{\text{evidence / marginal log-likelihood}}}\]--&gt;</span></td></tr><tr><td class="line-number" value="794"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="795"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;A conjugate prior is a prior distribution chosen such that the prior and the posterior are in the same probability distribution family.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="796"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="797"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;For distributions in the exponential family, we can always construct such conjugate priors.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="798"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="799"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="800"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="801"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:70%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="802"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="803"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;div style="margin-left:2em; float:right; width:30%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="804"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;img class="noborder" style="width:100%" src="hoffman_conditional_conjugate.svg" alt=""&gt;--&gt;</span></td></tr><tr><td class="line-number" value="805"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div style="font-size:50%"&gt;Adapted from &lt;em&gt;Stochastic Variational Inference&lt;/em&gt;, Hoffman, Blei, Wang, Paisley, 2013&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="806"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="807"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="808"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h3&gt;Conditional conjugate models&lt;/h3&gt;--&gt;</span></td></tr><tr><td class="line-number" value="809"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="810"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Model: global latent variable \(\beta\), and local latent variables \(z_n\) governing each \(x_n\). Joint:&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="811"></td><td class="line-content"><span class="html-comment">&lt;!--					\[p(\boldsymbol x, \boldsymbol z, \beta) = p(\beta)\prod_{i=1}^N p(z_n, x_n | \beta)\]--&gt;</span></td></tr><tr><td class="line-number" value="812"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="813"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span class="fragment"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="814"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;p&gt;Choose joint distribution of \(x_n,z_n\) conditioned on \(\beta\) to be from exponential family&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="815"></td><td class="line-content"><span class="html-comment">&lt;!--						\[p(x_n, z_n | \beta) = h(z_n, x_n)\exp(\beta^T t(z_n, x_n) - \alpha(\beta))\]--&gt;</span></td></tr><tr><td class="line-number" value="816"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="817"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="818"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span class="fragment"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="819"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;p&gt;Choose the prior on the global variable to be conjugate&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="820"></td><td class="line-content"><span class="html-comment">&lt;!--						\[p(\beta) = h(\beta)\exp\left(\begin{bmatrix}\alpha_1\\\alpha_2\end{bmatrix}^T\begin{bmatrix}\beta\\-a(\beta)\end{bmatrix} - a(\alpha)\right)\]--&gt;</span></td></tr><tr><td class="line-number" value="821"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="822"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="823"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span class="fragment"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="824"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;p&gt;This implies that the complete conditional is in the same family&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="825"></td><td class="line-content"><span class="html-comment">&lt;!--						\[p(\beta) = h(\beta)\exp(\alpha^T[\beta, -a(\beta)] - a(\alpha))\]--&gt;</span></td></tr><tr><td class="line-number" value="826"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="827"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="828"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span class="fragment"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="829"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;p&gt;Choose that the &lt;em&gt;complete conditional&lt;/em&gt; of \(z_n\) to be an exponential family&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="830"></td><td class="line-content"><span class="html-comment">&lt;!--						\[p(z_n | x_n, \beta) = h(z_n)\exp(\eta(\beta, x_n)^Tz_n - a(\eta(\beta, x_n)))\]--&gt;</span></td></tr><tr><td class="line-number" value="831"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="832"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="833"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span class="fragment"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="834"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;p&gt;This class of models gives rise to particularly simple variational inference. Many classic models like: Gaussian Bayesian mixture models, Latent Dirichlet allocation, matrix factorization, Bayesian linear regression belong to this class.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="835"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="836"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="837"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="838"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="839"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="840"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section  style="font-size:70%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="841"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h3&gt;Conditional conjugate models&lt;/h3&gt;--&gt;</span></td></tr><tr><td class="line-number" value="842"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="843"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;div class="container"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="844"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div style="flex-grow:2"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="845"></td><td class="line-content"><span class="html-comment">&lt;!--							Assumptions (assuming 1D \(z_i\) and \(\beta\) for simplicity):--&gt;</span></td></tr><tr><td class="line-number" value="846"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="847"></td><td class="line-content"><span class="html-comment">&lt;!--							\[\begin{align*}--&gt;</span></td></tr><tr><td class="line-number" value="848"></td><td class="line-content"><span class="html-comment">&lt;!--							p(\boldsymbol X, \boldsymbol Z, \beta) &amp;= p(\beta)\prod_{i=1}^N p(z_i, x_i | \beta) \\--&gt;</span></td></tr><tr><td class="line-number" value="849"></td><td class="line-content"><span class="html-comment">&lt;!--							p(\boldsymbol x_i, z_i | \beta) &amp;= h(z_i, x_i)\exp(\beta^T t(z_i, \boldsymbol x_i) - \alpha(\beta)) \\--&gt;</span></td></tr><tr><td class="line-number" value="850"></td><td class="line-content"><span class="html-comment">&lt;!--							p(\beta) &amp;= h(\beta)\exp(\boldsymbol \alpha^T[\beta, -a(\beta)] - a(\boldsymbol \alpha)) \\--&gt;</span></td></tr><tr><td class="line-number" value="851"></td><td class="line-content"><span class="html-comment">&lt;!--							p(z_i | \boldsymbol x_i, \beta) &amp;= h(z_i)\exp(\eta(\beta, \boldsymbol x_i)^T z_i - a(\eta(\beta, \boldsymbol x_i))) \hspace{2em} \text{complete conditional}--&gt;</span></td></tr><tr><td class="line-number" value="852"></td><td class="line-content"><span class="html-comment">&lt;!--							\end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="853"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="854"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;p&gt;Consequence from conjugacy:&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="855"></td><td class="line-content"><span class="html-comment">&lt;!--							\[p(\beta | \boldsymbol Z) = h(\beta)\exp(\hat {\boldsymbol \alpha}^T[\beta, -a(\beta)] - a(\hat {\boldsymbol \alpha})) \hspace{2em} \hat {\boldsymbol \alpha} = \begin{bmatrix}\alpha_1 + \sum_{i=1}^Nt(z_i, \boldsymbol x_i) \\ \alpha_2 + N\end{bmatrix} \]--&gt;</span></td></tr><tr><td class="line-number" value="856"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="857"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="858"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="859"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="860"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;The update rules turn out to become the expected parameters of the complete conditional. For variational distributions \(q( z_i | \phi_i)\) and \(q(\beta | \theta)\):&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="861"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="862"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;div class="container"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="863"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="864"></td><td class="line-content"><span class="html-comment">&lt;!--							\[\begin{align*}\phi_i &amp;= \mathbb{E}_{q(\beta |\theta)}\left[ \eta(\beta, x_i)\right] \hspace{2em}  \\--&gt;</span></td></tr><tr><td class="line-number" value="865"></td><td class="line-content"><span class="html-comment">&lt;!--							\theta &amp;= \mathbb{E}_{q(\boldsymbol Z | \boldsymbol \phi)}\left[ \hat {\boldsymbol \alpha}\right] = \begin{bmatrix}\alpha_1 + \sum_{i=1}^N \mathbb{E}_{q(\boldsymbol z | \boldsymbol \phi)}[ t(z_i, x_i)] \\ \alpha_2 + N\end{bmatrix}--&gt;</span></td></tr><tr><td class="line-number" value="866"></td><td class="line-content"><span class="html-comment">&lt;!--							\end{align*}--&gt;</span></td></tr><tr><td class="line-number" value="867"></td><td class="line-content"><span class="html-comment">&lt;!--							\]--&gt;</span></td></tr><tr><td class="line-number" value="868"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="869"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div style="font-size:70%; margin-left:1em;"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="870"></td><td class="line-content"><span class="html-comment">&lt;!--							Note that the general case with higher dimensional \(z_i\) and \(\beta\) the expectation must be calculated with respect to the other dimensions, making it slightly more involved. See &lt;a href="https://jmlr.org/papers/volume14/hoffman13a/hoffman13a.pdf"&gt;Hoffman et al&lt;/a&gt; for details.--&gt;</span></td></tr><tr><td class="line-number" value="871"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="872"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="873"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="874"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="875"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="876"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="877"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="878"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Problems with classic VI<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="879"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="880"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>So, the math for conjugate conditional models works out very nicely...<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="881"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="882"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>...but classic variational inference has a number of issues:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="883"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="884"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"  <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span></td></tr><tr><td class="line-number" value="885"></td><td class="line-content">					<span class="html-tag">&lt;dl <span class="html-attribute-name">class</span>="<span class="html-attribute-value">list</span>"&gt;</span></td></tr><tr><td class="line-number" value="886"></td><td class="line-content">						<span class="html-tag">&lt;dt&gt;</span>Coordinate Ascent Variational Inference (CAVI) doesn't scale well<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="887"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span>Remember that each latent variable (for each datapoint) has its own variational distribution. In each round, we must re-estimate the parameters for each of them.<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="888"></td><td class="line-content">						<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>"&gt;</span>We are bound to specific model classes<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="889"></td><td class="line-content">						<span class="html-tag">&lt;dd <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>"&gt;</span>Only conditional conjugate models have nice re-estimation expressions. Others require model-specific considerations. <span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="890"></td><td class="line-content">					<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="891"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="892"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p class="fragment"&gt;We'll consider these in turn.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="893"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Can we do better?<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="894"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="895"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="896"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="897"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="898"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:70%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="899"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h3&gt;CAVI: Scaling with data set size&lt;/h3&gt;--&gt;</span></td></tr><tr><td class="line-number" value="900"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="901"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;div style="font-size:90%; border:1px solid lightgrey; background-color:#fafafa;"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="902"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\begin{align*}--&gt;</span></td></tr><tr><td class="line-number" value="903"></td><td class="line-content"><span class="html-comment">&lt;!--						&amp;~\text{\textbf{CAVI algorithm} (with } q(\boldsymbol \beta|\boldsymbol \theta) \text{ and } q(\boldsymbol z|\boldsymbol \phi) \text{)} \\--&gt;</span></td></tr><tr><td class="line-number" value="904"></td><td class="line-content"><span class="html-comment">&lt;!--					\htmlStyle{color:#aaa;}{1. }&amp;~\text{initialize global variational variables}~\boldsymbol \theta^{(0)}\text{ randomly} \\--&gt;</span></td></tr><tr><td class="line-number" value="905"></td><td class="line-content"><span class="html-comment">&lt;!--					\htmlStyle{color:#aaa;}{2. }&amp;~t \leftarrow 0 \\--&gt;</span></td></tr><tr><td class="line-number" value="906"></td><td class="line-content"><span class="html-comment">&lt;!--					\htmlStyle{color:#aaa;}{3. }&amp;~\text{while}~\text{not}~\mathit{converged}: \\--&gt;</span></td></tr><tr><td class="line-number" value="907"></td><td class="line-content"><span class="html-comment">&lt;!--					\htmlStyle{color:#aaa;}{4. }&amp;~\hspace*{1em}t \leftarrow t+1\\--&gt;</span></td></tr><tr><td class="line-number" value="908"></td><td class="line-content"><span class="html-comment">&lt;!--					\htmlStyle{color:#aaa;}{5. }&amp;~\hspace*{1em}\text{foreach local variational variable } \phi_{i}:\\--&gt;</span></td></tr><tr><td class="line-number" value="909"></td><td class="line-content"><span class="html-comment">&lt;!--					\htmlStyle{color:#aaa;}{6. }&amp;~\hspace*{2em}\text{Update local variable: } \phi_{i}^{(t)} = \mathbb{E}_{q(\beta |\theta^{(t-1)})}\left[ \eta_{j}(x_i, \beta) \right]\\--&gt;</span></td></tr><tr><td class="line-number" value="910"></td><td class="line-content"><span class="html-comment">&lt;!--					\htmlStyle{color:#aaa;}{7. }&amp;~\hspace*{1em}\text{Update global variable: } \theta^{(t)} = \mathbb{E}_{q(\boldsymbol Z | \boldsymbol \phi^{(t)})}\left[ \hat {\boldsymbol \alpha}  \right]--&gt;</span></td></tr><tr><td class="line-number" value="911"></td><td class="line-content"><span class="html-comment">&lt;!--					\end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="912"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="913"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="914"></td><td class="line-content"><span class="html-comment">&lt;!--&amp;lt;!&amp;ndash;					&lt;p&gt;Note that line 6 only uses information from the global variable \(\beta\) and from the local variables for the same \(n\).&lt;/p&gt;&amp;ndash;&amp;gt;--&gt;</span></td></tr><tr><td class="line-number" value="915"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="916"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Problem: CAVI dictates that we need to iterate over all the data points in each iteration, to re-estimate their respective variational distributions.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="917"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="918"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;This is silly. Look at the first iteration. In each iteration of the inner loop, we're calculating expectations based on random choices of \(\theta\).&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="919"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="920"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span class="fragment"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="921"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Intuition: get rough estimates of the global parameters from subsets of the data.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="922"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="923"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Perhaps gradient-based optimization will help get us there...&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="924"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="925"></td><td class="line-content"><span class="html-comment">&lt;!--&amp;lt;!&amp;ndash;						Can't we get a rough estimate for \(\theta\) by looking at a subset of our data?&lt;/p&gt;&amp;ndash;&amp;gt;--&gt;</span></td></tr><tr><td class="line-number" value="926"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="927"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="928"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="929"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="930"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Gradient-based optimization <span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="931"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="932"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Idea: just optimize the ELBO by taking gradient-based steps<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="933"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="934"></td><td class="line-content">					\[\nabla \mathcal{L} = \nabla \left(\mathbb{E}_{q}\left[\ln \left( \frac{p(x,z)}{q(z)}\right)\right]\right)\]</td></tr><tr><td class="line-number" value="935"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="936"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>What can we do with this expression?<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="937"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="938"></td><td class="line-content">					<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="939"></td><td class="line-content">						<span class="html-tag">&lt;dt&gt;</span>conditional conjugate models<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="940"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span>Special class of models where conditional distributions are chosen to be from exponential families and conjugate. For these models, the gradients expression wrt to the global variable turns out to be nice. You can do stochastic gradient descent in these models. See <span class="html-tag">&lt;em&gt;</span>Variational Inference: A Review for Statisticians<span class="html-tag">&lt;/em&gt;</span> for details.<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="941"></td><td class="line-content">						<span class="html-tag">&lt;dt&gt;</span>any other model?<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="942"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span>This challenge is called "black-box VI". This is what we will focus on here.<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="943"></td><td class="line-content">					<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="944"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="945"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="946"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="947"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:70%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="948"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h3&gt;Gradient-based optimization (conditional conjugate models)&lt;/h3&gt;--&gt;</span></td></tr><tr><td class="line-number" value="949"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="950"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;div style="margin-left:2em; width:25%; float:right"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="951"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;img class="noborder" style="width:100%" src="hoffman_conditional_conjugate.svg" alt=""&gt;--&gt;</span></td></tr><tr><td class="line-number" value="952"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div style="font-size:50%"&gt;Adapted from &lt;em&gt;Stochastic Variational Inference&lt;/em&gt;, Hoffman, Blei, Wang, Paisley, 2013&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="953"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="954"></td><td class="line-content"><span class="html-comment">&lt;!--					--&gt;</span></td></tr><tr><td class="line-number" value="955"></td><td class="line-content"><span class="html-comment">&lt;!--					Task is to solve:--&gt;</span></td></tr><tr><td class="line-number" value="956"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\nabla \mathcal{L} = \nabla \left(\mathbb{E}_{q}\left[\ln \left( \frac{p(x,z,\beta)}{q(z,\beta)}\right)\right]\right)\]--&gt;</span></td></tr><tr><td class="line-number" value="957"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="958"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Focusing on \(q(\boldsymbol \beta | \boldsymbol \theta)\), we can write the ELBO&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="959"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\begin{align*}\mathcal{L}(\boldsymbol \theta) &amp;= \mathbb{E}_{q}\left[\ln p(\boldsymbol x,\boldsymbol z,\boldsymbol \beta)\right] - \mathbb{E}_{q}\left[\ln q(\boldsymbol z, \boldsymbol \beta)\right] \\--&gt;</span></td></tr><tr><td class="line-number" value="960"></td><td class="line-content"><span class="html-comment">&lt;!--					&amp;= \mathbb{E}_{q}\left[\ln p(\boldsymbol \beta|\boldsymbol x,\boldsymbol z)p(\boldsymbol x,\boldsymbol z)\right] - \mathbb{E}_{q}[\ln \underbrace{q(\boldsymbol z)q(\boldsymbol \beta)}_{\text{mean field}}] \\--&gt;</span></td></tr><tr><td class="line-number" value="961"></td><td class="line-content"><span class="html-comment">&lt;!--					&amp;= \mathbb{E}_{q}\left[\ln p(\boldsymbol \beta|\boldsymbol x,\boldsymbol z)\right] - \mathbb{E}_{q}[\ln q(\boldsymbol \beta)] + \text{const}--&gt;</span></td></tr><tr><td class="line-number" value="962"></td><td class="line-content"><span class="html-comment">&lt;!--					\end{align*}--&gt;</span></td></tr><tr><td class="line-number" value="963"></td><td class="line-content"><span class="html-comment">&lt;!--					\]--&gt;</span></td></tr><tr><td class="line-number" value="964"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="965"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;&lt;a href="https://jmlr.org/papers/volume14/hoffman13a/hoffman13a.pdf"&gt;Hoffman et al&lt;/a&gt; show that the gradient takes the form:&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="966"></td><td class="line-content"><span class="html-comment">&lt;!--&amp;lt;!&amp;ndash;					\[\nabla_{\boldsymbol \theta} \mathcal{L} = \nabla^2_{\boldsymbol \theta}a_g(\boldsymbol \theta)\left(\mathbb{E}_{q}\begin{bmatrix}\alpha_1 + \sum_{i=1}^Nt(z_i, x_i) \\ \alpha_2 + N\end{bmatrix} - \boldsymbol \theta\right)\]&amp;ndash;&amp;gt;--&gt;</span></td></tr><tr><td class="line-number" value="967"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\nabla_{\boldsymbol \theta} \mathcal{L} = \nabla^2_{\boldsymbol \theta}a(\boldsymbol \theta)\left(\mathbb{E}_{q}[\hat {\boldsymbol \alpha}] - \boldsymbol \theta\right)\]--&gt;</span></td></tr><tr><td class="line-number" value="968"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="969"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p clas="fragment"&gt;(continued on next slide)&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="970"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="971"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="972"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:80%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="973"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span style="font-size:85%"&gt;&lt;h3&gt;Gradient-based optimization (conditional conjugate models)&lt;/h3&gt;&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="974"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="975"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;We have&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="976"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\nabla_{\boldsymbol \theta} \mathcal{L} = \nabla^2_{\boldsymbol \theta}a(\boldsymbol \theta)\left(\mathbb{E}_{q}[\hat {\boldsymbol \alpha}] - \boldsymbol \theta\right)\]--&gt;</span></td></tr><tr><td class="line-number" value="977"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="978"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;If you use natural gradients, this simplifies to:&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="979"></td><td class="line-content"><span class="html-comment">&lt;!--					\[g(\theta) = \mathbb{E}_{q}[\hat {\boldsymbol \alpha}] - \boldsymbol \theta\]--&gt;</span></td></tr><tr><td class="line-number" value="980"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="981"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span class="fragment"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="982"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Doing a gradient step therefore takes a very simple form&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="983"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\theta^{(t)} = \theta^{(t-1)} + \lambda g(\theta^{(t-1)}) = (1-\lambda)\theta^{(t-1)} + \lambda g(\theta^{(t-1)})\]--&gt;</span></td></tr><tr><td class="line-number" value="984"></td><td class="line-content"><span class="html-comment">&lt;!--					(i.e., a linear combination of the old value and the update).--&gt;</span></td></tr><tr><td class="line-number" value="985"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="986"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="987"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p class="fragment"&gt;We can now speed up the optimization using &lt;em&gt;stochastic gradients&lt;/em&gt; (similar to what we do in deep learning)&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="988"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="989"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="990"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="991"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:70%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="992"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h3&gt;Gradient-based optimization (conditional conjugate models)&lt;/h3&gt;--&gt;</span></td></tr><tr><td class="line-number" value="993"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="994"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;div style="border: 1px solid lightgrey; background-color:#fafafa; padding:1em;padding-top:0em;"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="995"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;p&gt;Take home messages:&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="996"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;ol&gt;--&gt;</span></td></tr><tr><td class="line-number" value="997"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;li&gt;If we limit ourselves to conditional conjugate models, the gradient of the ELBO has a nice closed form solution&lt;/li&gt;--&gt;</span></td></tr><tr><td class="line-number" value="998"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;li style="margin-top:1em"&gt;So we can now scale VI methods by using stochastic optimization (i.e. noisy estimates of the gradients)&lt;/li&gt;--&gt;</span></td></tr><tr><td class="line-number" value="999"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/ol&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1000"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1001"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1002"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1003"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1004"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1005"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section style="font-size:90%"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1006"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h3&gt;Gradient-based optimization - other models?&lt;/h3&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1007"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1008"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;What can we do for other models?&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1009"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1010"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\nabla \mathcal{L} = \nabla \left(\mathbb{E}_{q}\left[\ln \left( \frac{p(x,z)}{q(z)}\right)\right]\right)\]--&gt;</span></td></tr><tr><td class="line-number" value="1011"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1012"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Can we derive a black box optimization strategy that doesn't require knowledge about the specific model?&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1013"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1014"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1015"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1016"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1017"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Black box variational inference<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1018"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1019"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="1020"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 3</span>"&gt;</span></td></tr><tr><td class="line-number" value="1021"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>If we don't want to make any assumptions about \(p(x,z)\), we will have to figure out how to calculate gradients of expectations.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1022"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1023"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;p&gt;For variational distribution \(q(\boldsymbol z | \theta)\):&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1024"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1025"></td><td class="line-content">							\[\begin{align*}\nabla_{\boldsymbol \theta} \mathcal{L} &amp;= \nabla_{\boldsymbol \theta} \left(\mathbb{E}_{q}\left[\ln \left( \frac{p(\boldsymbol x, \boldsymbol z)}{q(\boldsymbol z | \boldsymbol \theta)}\right)\right]\right)  \end{align*}\]</td></tr><tr><td class="line-number" value="1026"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1027"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1028"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1029"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%; border:1px solid lightgrey; margin:0.5em;padding:1em; background-color: #fafafa; </span>"&gt;</span></td></tr><tr><td class="line-number" value="1030"></td><td class="line-content">							<span class="html-tag">&lt;h3&gt;</span>log-derivative "trick":<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1031"></td><td class="line-content">							\[\frac{d}{dx} \ln f(x) = \frac{1}{f(x)}\frac{d}{dx}f(x)\]</td></tr><tr><td class="line-number" value="1032"></td><td class="line-content">							\[\Rightarrow f(x)\frac{d}{dx} \ln f(x) = \frac{d}{dx}f(x)\]</td></tr><tr><td class="line-number" value="1033"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1034"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1035"></td><td class="line-content"><span class="html-comment">&lt;!--					(alternative notation: \(q(\boldsymbol z ; \theta)\)):&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1036"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1037"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1038"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>" &gt;</span></td></tr><tr><td class="line-number" value="1039"></td><td class="line-content">						\[\begin{align*}\htmlStyle{visibility:hidden;}{\nabla_{\boldsymbol \theta} \mathcal{L}}</td></tr><tr><td class="line-number" value="1040"></td><td class="line-content">					&amp;= \nabla_{\boldsymbol \theta} \bigg(\mathbb{E}_{q}[ \underbrace{\ln p(\boldsymbol x,\boldsymbol z) - \ln q(\boldsymbol z| \boldsymbol \theta)}_{\coloneqq f(\boldsymbol z, \boldsymbol \theta)} ] \bigg) = \nabla_{\boldsymbol \theta} \int f(\boldsymbol z, \boldsymbol \theta)q(\boldsymbol z | \boldsymbol \theta)d\boldsymbol z\\</td></tr><tr><td class="line-number" value="1041"></td><td class="line-content">						\end{align*}\]</td></tr><tr><td class="line-number" value="1042"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1043"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" &gt;</span></td></tr><tr><td class="line-number" value="1044"></td><td class="line-content">						\[\begin{align*}\htmlStyle{visibility:hidden;}{\nabla_{\boldsymbol \theta} \mathcal{L}}</td></tr><tr><td class="line-number" value="1045"></td><td class="line-content">					&amp;= \int \nabla_{\boldsymbol \theta} \left(f(\boldsymbol z, \boldsymbol \theta)q(\boldsymbol z | \boldsymbol \theta)\right)d\boldsymbol z  \hspace*{2em} \text{\footnotesize OK for well-behaved functions}\\</td></tr><tr><td class="line-number" value="1046"></td><td class="line-content">						\end{align*}\]</td></tr><tr><td class="line-number" value="1047"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1048"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>" &gt;</span></td></tr><tr><td class="line-number" value="1049"></td><td class="line-content">						\[\begin{align*}\htmlStyle{visibility:hidden;}{\nabla_{\boldsymbol \theta} \mathcal{L}}</td></tr><tr><td class="line-number" value="1050"></td><td class="line-content">					&amp;= \int \nabla_{\boldsymbol \theta}(f(\boldsymbol z, \boldsymbol \theta))q(\boldsymbol z | \boldsymbol \theta) + f(\boldsymbol z, \boldsymbol \theta)\underbrace{\nabla_{\boldsymbol \theta}(q(\boldsymbol z | \boldsymbol \theta))}_{\underset{\text{log-derivative "trick"}}{q(\boldsymbol z | \boldsymbol \theta)\nabla_{\boldsymbol \theta}(\ln q(\boldsymbol z | \boldsymbol \theta))}}d\boldsymbol z \hspace{2em}\text{\footnotesize product rule}\\</td></tr><tr><td class="line-number" value="1051"></td><td class="line-content">						\end{align*}\]</td></tr><tr><td class="line-number" value="1052"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1053"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="1054"></td><td class="line-content">						\[\begin{align*}\htmlStyle{visibility:hidden;}{\nabla_{\boldsymbol \theta} \mathcal{L}}</td></tr><tr><td class="line-number" value="1055"></td><td class="line-content">					&amp;= \mathbb{E}_{q} \left[\nabla_{\boldsymbol \theta}f(\boldsymbol z, \boldsymbol \theta) + f(\boldsymbol z, \boldsymbol \theta) \nabla_{\boldsymbol \theta}(\ln q(\boldsymbol z | \boldsymbol \theta))\right]</td></tr><tr><td class="line-number" value="1056"></td><td class="line-content">						\end{align*}\]</td></tr><tr><td class="line-number" value="1057"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1058"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1059"></td><td class="line-content">					<span class="html-tag">&lt;aside <span class="html-attribute-name">class</span>="<span class="html-attribute-value">notes</span>"&gt;</span></td></tr><tr><td class="line-number" value="1060"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>Key observation: log-derivative trick allows us to turn the first term into an expectation.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1061"></td><td class="line-content">					<span class="html-tag">&lt;/aside&gt;</span></td></tr><tr><td class="line-number" value="1062"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1063"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1064"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1065"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1066"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Gradients of expectations - score function approach<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1067"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1068"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:-0.5em</span>"&gt;</span></td></tr><tr><td class="line-number" value="1069"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="1070"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>We have<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1071"></td><td class="line-content">							\[\nabla_{\boldsymbol \theta} \mathcal{L} = \mathbb{E}_{q} \left[\nabla_{\boldsymbol \theta}f(\boldsymbol z, \boldsymbol \theta) + f(\boldsymbol z, \boldsymbol \theta) \nabla_{\boldsymbol \theta}(\ln q(\boldsymbol z | \boldsymbol \theta))\right]\]</td></tr><tr><td class="line-number" value="1072"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1073"></td><td class="line-content">							The first term</td></tr><tr><td class="line-number" value="1074"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1075"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%; border:1px solid lightgrey; margin:0.5em;padding:1em; background-color: #fafafa; </span>"&gt;</span></td></tr><tr><td class="line-number" value="1076"></td><td class="line-content">							The gradient of the log-likelihood function wrt to its parameters is called the <span class="html-tag">&lt;em&gt;</span>score function<span class="html-tag">&lt;/em&gt;</span>.</td></tr><tr><td class="line-number" value="1077"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1078"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1079"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1080"></td><td class="line-content">					\[ \mathbb{E}_{q} \left[\nabla_{\boldsymbol \theta}f(\boldsymbol z, \boldsymbol \theta)\right] = \mathbb{E}_{q} \left[\nabla_{\boldsymbol \theta} \ln p(\boldsymbol x,\boldsymbol z) - \nabla_{\boldsymbol \theta}\ln q(\boldsymbol z| \boldsymbol \theta) \right] = - \mathbb{E}_{q} \left[\nabla_{\boldsymbol \theta}\ln q(\boldsymbol z| \boldsymbol \theta) \right]\]</td></tr><tr><td class="line-number" value="1081"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1082"></td><td class="line-content">					is known as a <span class="html-tag">&lt;em&gt;</span>score function<span class="html-tag">&lt;/em&gt;</span>. This quantity is known to have expectation \(0\).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1083"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1084"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="1085"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>We therefore have:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1086"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1087"></td><td class="line-content">					\[\begin{align*}\nabla_{\boldsymbol \theta} \mathcal{L} &amp;= \mathbb{E}_{q} \left[ f(\boldsymbol z, \boldsymbol \theta) \nabla_{\boldsymbol \theta}(\ln q(\boldsymbol z | \boldsymbol \theta)) \right] \hspace*{2em} \text{\footnotesize setting 1st term to zero}\\</td></tr><tr><td class="line-number" value="1088"></td><td class="line-content">					&amp;= \mathbb{E}_{q} \left[(\ln p(\boldsymbol x,\boldsymbol z) - \ln q(\boldsymbol z| \boldsymbol \theta))\underbrace{\nabla_{\boldsymbol \theta}(\ln q(\boldsymbol z | \boldsymbol \theta))}_{\text{score function}} \right] \\</td></tr><tr><td class="line-number" value="1089"></td><td class="line-content">						&amp;\underbrace{\approx \frac{1}{L}\sum_{l=1}^L \left((\ln p(\boldsymbol x,\boldsymbol z^{(l)}) - \ln q(\boldsymbol z^{(l)}| \boldsymbol \theta))\underbrace{\nabla_{\boldsymbol \theta}(\ln q(\boldsymbol z | \boldsymbol \theta))}_{\text{score function}}|_{z=z^{(l)}} \right)}_{\text{Monte Carlo estimate}}\hspace{2em}z^{(l)} \sim q(z|\theta)</td></tr><tr><td class="line-number" value="1090"></td><td class="line-content">					\end{align*}\]</td></tr><tr><td class="line-number" value="1091"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1092"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1093"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:-0.25em</span>"&gt;</span>This estimator is called the <span class="html-tag">&lt;em&gt;</span>score-function<span class="html-tag">&lt;/em&gt;</span> estimator or <span class="html-tag">&lt;em&gt;</span>REINFORCE<span class="html-tag">&lt;/em&gt;</span> gradients. <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Unfortunately, this estimator has rather large variance &amp;#128542;<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1094"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1095"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p class="fragment"&gt;(unfortunately this estimator turns out to have rather large variance &amp;#128542;)&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1096"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1097"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1098"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1099"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1100"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Gradients of expectations - path approach<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1101"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1102"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;The second approach uses the fact that samples from distributions can be written as transformations of a simpler form, such that the parameters of interest only appear in the transformation.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1103"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1104"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>The second approach uses the fact that samples from a distribution can often be generated by the following recipe:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1105"></td><td class="line-content">					<span class="html-tag">&lt;ol&gt;</span></td></tr><tr><td class="line-number" value="1106"></td><td class="line-content">						<span class="html-tag">&lt;li&gt;</span>Generate a sample from a base distribution, which is <span class="html-tag">&lt;em&gt;</span>independent<span class="html-tag">&lt;/em&gt;</span> of the parameters<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="1107"></td><td class="line-content">						<span class="html-tag">&lt;li&gt;</span>Transform the sample using a deterministic mapping that depends on the parameters.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="1108"></td><td class="line-content">					<span class="html-tag">&lt;/ol&gt;</span></td></tr><tr><td class="line-number" value="1109"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1110"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="1111"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>For instance, for a Normal distribution, we can sample by transforming samples from a (0,1) Normal:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1112"></td><td class="line-content">					\[z \sim \mathcal{N}(\mu, \sigma^2) \hspace{1em}\text{ is equivalent to } \hspace{1em} z = \mu + \sigma*\epsilon\hspace{0.5em}\text{where } \epsilon \sim \mathcal{N(0,1)}\]</td></tr><tr><td class="line-number" value="1113"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1114"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1115"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1116"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1117"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1118"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Intermezzo - Law of the unconcious statistician (LOTUS)<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1119"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1120"></td><td class="line-content">					To calculate an expectation of a function \(g\) of a random variable \(\boldsymbol x\), we can either </td></tr><tr><td class="line-number" value="1121"></td><td class="line-content">					<span class="html-tag">&lt;dl <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1122"></td><td class="line-content">						<span class="html-tag">&lt;dt&gt;</span>1. Calculate the pmf/pdf of \(\boldsymbol y= g(\boldsymbol x)\), and then use the definition<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="1123"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span>\[\mathbb{E}_{p(\boldsymbol y)}[\boldsymbol y] = \int \boldsymbol y p(\boldsymbol y)d\boldsymbol y\]<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="1124"></td><td class="line-content">						<span class="html-tag">&lt;dt&gt;</span>2. Use LOTUS:<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="1125"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span>\[\mathbb{E}_{p(\boldsymbol y)}[\boldsymbol y] = \mathbb{E}_{p(\boldsymbol x)}[ g(\boldsymbol x)] = \int g(\boldsymbol x)p(\boldsymbol x)d\boldsymbol x\]<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="1126"></td><td class="line-content">					<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="1127"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1128"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>We've used LOTUS before, but consider what we are actually doing here: we are calculating an expectation of a stochastic variable \(g(\boldsymbol x)\) without knowing its distribution.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1129"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1130"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>We can use this to rewrite the expectation of our transformed variable.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1131"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1132"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1133"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1134"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Gradients of expectations - path approach (2)<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1135"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1136"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>We will assume that a transformation \(t(\boldsymbol \epsilon, \boldsymbol \theta)\) exists that maps an original value \(\boldsymbol \epsilon \sim q(\boldsymbol \epsilon)\) to \(\boldsymbol z \sim q(\boldsymbol z | \boldsymbol \theta)\):<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1137"></td><td class="line-content">					<span class="html-comment">&lt;!-- \[\epsilon \sim q(\boldsymbol \epsilon) \hspace{2em} \boldsymbol z = t(\boldsymbol \epsilon, \boldsymbol \theta)  \] --&gt;</span></td></tr><tr><td class="line-number" value="1138"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1139"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>" &gt;</span></td></tr><tr><td class="line-number" value="1140"></td><td class="line-content">						\[\begin{align*}\nabla_{\boldsymbol \theta} \mathcal{L}</td></tr><tr><td class="line-number" value="1141"></td><td class="line-content">						&amp;= \nabla_{\boldsymbol \theta} \bigg(\mathbb{E}_{q}[ \underbrace{\ln p(\boldsymbol x,\boldsymbol z) - \ln q(\boldsymbol z| \boldsymbol \theta)}_{\coloneqq f(\boldsymbol z, \boldsymbol \theta)} ] \bigg) = \nabla_{\boldsymbol \theta} \int f(\boldsymbol z, \boldsymbol \theta)q(\boldsymbol z | \boldsymbol \theta)d\boldsymbol z\\</td></tr><tr><td class="line-number" value="1142"></td><td class="line-content">						\end{align*}\]</td></tr><tr><td class="line-number" value="1143"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1144"></td><td class="line-content">					</td></tr><tr><td class="line-number" value="1145"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" &gt;</span></td></tr><tr><td class="line-number" value="1146"></td><td class="line-content">						\[\begin{align*}\htmlStyle{visibility:hidden;}{\nabla_{\boldsymbol \theta} \mathcal{L}}					</td></tr><tr><td class="line-number" value="1147"></td><td class="line-content">					&amp;= \nabla_{\boldsymbol \theta} \int f(t(\boldsymbol \epsilon, \boldsymbol \theta), \boldsymbol \theta)q(\boldsymbol \epsilon)d\boldsymbol \epsilon \hspace*{2em} \text{\footnotesize using LOTUS}</td></tr><tr><td class="line-number" value="1148"></td><td class="line-content">					\end{align*}\]</td></tr><tr><td class="line-number" value="1149"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1150"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1151"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>" &gt;</span></td></tr><tr><td class="line-number" value="1152"></td><td class="line-content">						\[\begin{align*}\htmlStyle{visibility:hidden;}{\nabla_{\boldsymbol \theta} \mathcal{L}}					</td></tr><tr><td class="line-number" value="1153"></td><td class="line-content">					&amp;= \int \nabla_{\boldsymbol \theta} \left(f(t(\boldsymbol \epsilon, \boldsymbol \theta), \boldsymbol \theta)q(\boldsymbol \epsilon)\right)d\boldsymbol \epsilon = \mathbb{E}_{q(\boldsymbol \epsilon)} \left[\nabla_{\boldsymbol \theta}f(t(\boldsymbol \epsilon, \boldsymbol \theta), \boldsymbol \theta)\right] \\</td></tr><tr><td class="line-number" value="1154"></td><td class="line-content">					\end{align*}\]</td></tr><tr><td class="line-number" value="1155"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1156"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1157"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">4</span>" &gt;</span></td></tr><tr><td class="line-number" value="1158"></td><td class="line-content">						\[\begin{align*}\htmlStyle{visibility:hidden;}{\nabla_{\boldsymbol \theta} \mathcal{L}}					</td></tr><tr><td class="line-number" value="1159"></td><td class="line-content">					&amp;= \mathbb{E}_{q(\boldsymbol \epsilon)} \left[\nabla_{\boldsymbol \theta} \left( \ln p(\boldsymbol x, t(\boldsymbol \epsilon, \boldsymbol \theta)) - \ln q(t(\boldsymbol \epsilon, \boldsymbol \theta)| \boldsymbol \theta)\right)\right] \\</td></tr><tr><td class="line-number" value="1160"></td><td class="line-content">					\end{align*}\]</td></tr><tr><td class="line-number" value="1161"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1162"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1163"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">5</span>" &gt;</span></td></tr><tr><td class="line-number" value="1164"></td><td class="line-content">						\[\begin{align*}\htmlStyle{visibility:hidden;}{\nabla_{\boldsymbol \theta} \mathcal{L}}					</td></tr><tr><td class="line-number" value="1165"></td><td class="line-content">					&amp;\approx \frac{1}{L}\sum_{l=1}^L \left( \nabla_{\boldsymbol \theta} \left(\ln p(\boldsymbol x,t(\boldsymbol \epsilon^{(l)}, \boldsymbol \theta)) - \ln q(t(\boldsymbol \epsilon^{(l)}, \boldsymbol \theta)| \boldsymbol \theta)\right)\right) \hspace{2em} \boldsymbol \epsilon^{(l)} \sim q(\boldsymbol \epsilon)</td></tr><tr><td class="line-number" value="1166"></td><td class="line-content">						\end{align*}\]</td></tr><tr><td class="line-number" value="1167"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1168"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1169"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1170"></td><td class="line-content">					<span class="html-comment">&lt;!-- &lt;p&gt;We can now rewrite our gradient expression: &lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1171"></td><td class="line-content"><span class="html-comment">					\[\begin{align*}\nabla_{\boldsymbol \theta} \mathcal{L} &amp;= \mathbb{E}_{q(\boldsymbol z|\boldsymbol \theta)} \left[\nabla_{\boldsymbol \theta}f(\boldsymbol z, \boldsymbol \theta) + f(\boldsymbol z, \boldsymbol \theta) \nabla_{\boldsymbol \theta}(\underbrace{\ln q(\boldsymbol z | \boldsymbol \theta)}_{\text{likelihood}})\right] \\</span></td></tr><tr><td class="line-number" value="1172"></td><td class="line-content"><span class="html-comment">					&amp;=\mathbb{E}_{q(\boldsymbol \epsilon)} \left[\nabla_{\boldsymbol \theta}f(\underbrace{t(\boldsymbol \epsilon, \boldsymbol \theta)}_{\text{map }\boldsymbol \epsilon \text { to } \boldsymbol z}, \boldsymbol \theta) + f(\underbrace{t(\boldsymbol \epsilon, \boldsymbol \theta)}_{\text{map }\boldsymbol \epsilon \text { to } \boldsymbol z}, \boldsymbol \theta) \nabla_{\boldsymbol \theta}(\ln \underbrace{q(\epsilon)}_{\text{likelihood}})\right]</span></td></tr><tr><td class="line-number" value="1173"></td><td class="line-content"><span class="html-comment">					\end{align*}\]</span></td></tr><tr><td class="line-number" value="1174"></td><td class="line-content"><span class="html-comment">					&lt;span class="fragment"&gt;</span></td></tr><tr><td class="line-number" value="1175"></td><td class="line-content"><span class="html-comment">					&lt;p&gt;\(\nabla_{\boldsymbol \theta}(\ln q(\epsilon))\) is now zero, because it has no dependency on \(\boldsymbol \theta\), so&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1176"></td><td class="line-content"><span class="html-comment">					\[\begin{align*}\nabla_{\boldsymbol \theta} \mathcal{L} &amp;= \mathbb{E}_{q(\boldsymbol \epsilon)} \left[\nabla_{\boldsymbol \theta}f(t(\boldsymbol \epsilon, \boldsymbol \theta), \boldsymbol \theta) \right]</span></td></tr><tr><td class="line-number" value="1177"></td><td class="line-content"><span class="html-comment">					\end{align*}\]</span></td></tr><tr><td class="line-number" value="1178"></td><td class="line-content"><span class="html-comment">					&lt;/span&gt; --&gt;</span></td></tr><tr><td class="line-number" value="1179"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1180"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1181"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1182"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Gradients of expectations - path approach (3)<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1183"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1184"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%; border:1px solid lightgrey; margin:0.5em;padding:1em; background-color: #fafafa;</span>"&gt;</span></td></tr><tr><td class="line-number" value="1185"></td><td class="line-content">						\[\nabla_{\boldsymbol \theta} \mathcal{L} \approx \frac{1}{L}\sum_{l=1}^L \left( \nabla_{\boldsymbol \theta} \left(\ln p(\boldsymbol x,t(\boldsymbol \epsilon^{(l)}, \boldsymbol \theta)) - \ln q(t(\boldsymbol \epsilon^{(l)}, \boldsymbol \theta)| \boldsymbol \theta)\right)\right) \hspace{2em} \boldsymbol \epsilon^{(l)} \sim q(\boldsymbol \epsilon)\]</td></tr><tr><td class="line-number" value="1186"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1187"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1188"></td><td class="line-content">					<span class="html-comment">&lt;!-- &lt;div style="float:right; font-size:80%; border:1px solid lightgrey; margin:0.5em;padding:1em; background-color: #fafafa; width:40%"&gt;</span></td></tr><tr><td class="line-number" value="1189"></td><td class="line-content"><span class="html-comment">						The path-approach gives us the following expression for the gradient of an expectation:</span></td></tr><tr><td class="line-number" value="1190"></td><td class="line-content"><span class="html-comment">					\[\begin{align*}\nabla_{\boldsymbol \theta} \mathcal{L} &amp;= \mathbb{E}_{q(\boldsymbol \epsilon)} \left[\nabla_{\boldsymbol \theta}f(t(\boldsymbol \epsilon, \boldsymbol \theta), \boldsymbol \theta) \right] \end{align*}\]</span></td></tr><tr><td class="line-number" value="1191"></td><td class="line-content"><span class="html-comment">					&lt;/div&gt;	</span></td></tr><tr><td class="line-number" value="1192"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="1193"></td><td class="line-content"><span class="html-comment">					&lt;div style="margin-top:2em; font-size:85%"&gt;</span></td></tr><tr><td class="line-number" value="1194"></td><td class="line-content"><span class="html-comment">					Using the chain rule:</span></td></tr><tr><td class="line-number" value="1195"></td><td class="line-content"><span class="html-comment">						\[\frac{df}{d\theta}=\frac{df}{dz}\frac{dz}{d\theta}\]</span></td></tr><tr><td class="line-number" value="1196"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="1197"></td><td class="line-content"><span class="html-comment">					&lt;p style="margin-top:1.5em;  font-size:85%"&gt;</span></td></tr><tr><td class="line-number" value="1198"></td><td class="line-content"><span class="html-comment">					\[\begin{align*}\nabla_{\boldsymbol \theta} \mathcal{L} &amp;= \mathbb{E}_{q(\boldsymbol \epsilon)} \left[\nabla_{\boldsymbol \theta}f(\boldsymbol z, \boldsymbol \theta) \right] \\</span></td></tr><tr><td class="line-number" value="1199"></td><td class="line-content"><span class="html-comment">					&amp;=\mathbb{E}_{q(\boldsymbol \epsilon)} \left[\nabla_{\boldsymbol z}(\ln p(\boldsymbol x,\boldsymbol z) - \ln q(\boldsymbol z| \boldsymbol \theta))|_{z=t(\epsilon)}\nabla_{\boldsymbol \theta}t(\boldsymbol \epsilon, \boldsymbol \theta)\right] \\</span></td></tr><tr><td class="line-number" value="1200"></td><td class="line-content"><span class="html-comment">					&amp;\approx \frac{1}{L}\sum_{l=1}^L \left(\nabla_{\boldsymbol z}(\ln p(\boldsymbol x,\boldsymbol z) - \ln q(\boldsymbol z| \boldsymbol \theta))|_{z=t(\epsilon^{(l)})}\nabla_{\boldsymbol \theta}t(\boldsymbol \epsilon, \boldsymbol \theta)|_{\epsilon=\epsilon^{(l)}}\right) \hspace{2em} \boldsymbol \epsilon \sim q(\boldsymbol \epsilon)</span></td></tr><tr><td class="line-number" value="1201"></td><td class="line-content"><span class="html-comment">					\end{align*}\]</span></td></tr><tr><td class="line-number" value="1202"></td><td class="line-content"><span class="html-comment">				&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1203"></td><td class="line-content"><span class="html-comment">			&lt;/div&gt; --&gt;</span></td></tr><tr><td class="line-number" value="1204"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="1205"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:0; padding-top:0</span>"&gt;</span></td></tr><tr><td class="line-number" value="1206"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:0</span>"&gt;</span>We have thus converted \(\boldsymbol z\) from being a stochastic node to being a deterministic node, and can now backprop through it.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1207"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1208"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>This is called the <span class="html-tag">&lt;em&gt;</span>reparameterization<span class="html-tag">&lt;/em&gt;</span> gradient estimator. <span class="html-tag">&lt;span&gt;</span>It has substantially lower variance than the score function estimator.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1209"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1210"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1211"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 1.5</span>"&gt;</span></td></tr><tr><td class="line-number" value="1212"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:90%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/kingma_welling_vae_fig2_3.svg" rel="noreferrer noopener">kingma_welling_vae_fig2_3.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="1213"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:60%; width:60%; margin: 0 auto; text-align:right</span>"&gt;</span>Adapted from <span class="html-tag">&lt;em&gt;</span>An Introduction to Variational Autoencoders<span class="html-tag">&lt;/em&gt;</span>, Kingma, Welling, 2019<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1214"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1215"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1216"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1217"></td><td class="line-content">					<span class="html-comment">&lt;!-- \[\begin{align*}\nabla_{\boldsymbol \theta} \mathcal{L} &amp;= \mathbb{E}_{q(\boldsymbol \epsilon)} \left[\nabla_{\boldsymbol \theta}f(t(\boldsymbol \epsilon, \boldsymbol \theta), \boldsymbol \theta) \right] \\ --&gt;</span></td></tr><tr><td class="line-number" value="1218"></td><td class="line-content">					<span class="html-comment">&lt;!--					&amp;=\mathbb{E}_{q(\boldsymbol \epsilon)} \left[\nabla_{\boldsymbol \theta} \left(\ln p(\boldsymbol x,\boldsymbol z) - \ln q(\boldsymbol z| \boldsymbol \theta)\right)    \right]\\--&gt;</span></td></tr><tr><td class="line-number" value="1219"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1220"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1221"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;For simple transformations (like the shift of the mean of a Normal), the last factor is 1, so we end up with a simpler expression.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1222"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1223"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p class="fragment"&gt;The variance of this estimator is substantially lower than that of the score function estimator.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1224"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1225"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1226"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1227"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Score function vs pathwise gradient estimators<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1228"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1229"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:60%; position:relative; left:20%; font-size:100%; border:1px solid lightgrey; margin:0.5em;padding:1em; background-color: #fafafa;</span>"&gt;</span></td></tr><tr><td class="line-number" value="1230"></td><td class="line-content">						\(\nabla_{\boldsymbol \theta} \mathcal{L} = \nabla_{\boldsymbol \theta} \bigg(\mathbb{E}_{q}[ \underbrace{\ln p(\boldsymbol x,\boldsymbol z) - \ln q(\boldsymbol z| \boldsymbol \theta)}_{\coloneqq f(\boldsymbol z, \boldsymbol \theta)} ] \bigg) \)</td></tr><tr><td class="line-number" value="1231"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1232"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1233"></td><td class="line-content">					<span class="html-tag">&lt;table <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1234"></td><td class="line-content">						<span class="html-tag">&lt;tr&gt;</span></td></tr><tr><td class="line-number" value="1235"></td><td class="line-content">							<span class="html-tag">&lt;th&gt;</span><span class="html-tag">&lt;/th&gt;</span></td></tr><tr><td class="line-number" value="1236"></td><td class="line-content">							<span class="html-tag">&lt;th <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:50%</span>"&gt;</span>Score-function<span class="html-tag">&lt;/th&gt;</span></td></tr><tr><td class="line-number" value="1237"></td><td class="line-content">							<span class="html-tag">&lt;th <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:50%</span>"&gt;</span>Pathwise<span class="html-tag">&lt;/th&gt;</span></td></tr><tr><td class="line-number" value="1238"></td><td class="line-content">						<span class="html-tag">&lt;/tr&gt;</span></td></tr><tr><td class="line-number" value="1239"></td><td class="line-content">						<span class="html-tag">&lt;tr&gt;</span></td></tr><tr><td class="line-number" value="1240"></td><td class="line-content">							<span class="html-tag">&lt;th&gt;</span>Idea<span class="html-tag">&lt;/th&gt;</span></td></tr><tr><td class="line-number" value="1241"></td><td class="line-content">							<span class="html-tag">&lt;td&gt;</span>\(\mathbb{E}_{q(\boldsymbol z)}[ f(\boldsymbol z, \boldsymbol \theta)\nabla_{\boldsymbol \theta}(\ln q(\boldsymbol z | \boldsymbol \theta))]\)<span class="html-tag">&lt;/td&gt;</span></td></tr><tr><td class="line-number" value="1242"></td><td class="line-content">							<span class="html-tag">&lt;td&gt;</span>\(\mathbb{E}_{q(\boldsymbol \epsilon)}[\nabla_{\boldsymbol \theta}f(\underbrace{\boldsymbol z}_{=t(\boldsymbol \epsilon, \boldsymbol \theta)}, \boldsymbol \theta)]\)<span class="html-tag">&lt;/td&gt;</span></td></tr><tr><td class="line-number" value="1243"></td><td class="line-content">						<span class="html-tag">&lt;/tr&gt;</span></td></tr><tr><td class="line-number" value="1244"></td><td class="line-content">						<span class="html-tag">&lt;tr&gt;</span></td></tr><tr><td class="line-number" value="1245"></td><td class="line-content">							<span class="html-tag">&lt;th&gt;</span>Requirement on model<span class="html-tag">&lt;/th&gt;</span></td></tr><tr><td class="line-number" value="1246"></td><td class="line-content">							<span class="html-tag">&lt;td&gt;</span><span class="html-tag">&lt;/td&gt;</span></td></tr><tr><td class="line-number" value="1247"></td><td class="line-content">							<span class="html-tag">&lt;td&gt;</span>Model must be differentiable<span class="html-tag">&lt;/td&gt;</span></td></tr><tr><td class="line-number" value="1248"></td><td class="line-content">						<span class="html-tag">&lt;/tr&gt;</span></td></tr><tr><td class="line-number" value="1249"></td><td class="line-content">						<span class="html-tag">&lt;tr&gt;</span></td></tr><tr><td class="line-number" value="1250"></td><td class="line-content">							<span class="html-tag">&lt;th&gt;</span>Requirement on \(q\)<span class="html-tag">&lt;/th&gt;</span></td></tr><tr><td class="line-number" value="1251"></td><td class="line-content">							<span class="html-tag">&lt;td&gt;</span><span class="html-tag">&lt;/td&gt;</span></td></tr><tr><td class="line-number" value="1252"></td><td class="line-content">							<span class="html-tag">&lt;td&gt;</span>\(q\) must be reparameterizable<span class="html-tag">&lt;/td&gt;</span></td></tr><tr><td class="line-number" value="1253"></td><td class="line-content">						<span class="html-tag">&lt;/tr&gt;</span></td></tr><tr><td class="line-number" value="1254"></td><td class="line-content">						<span class="html-tag">&lt;tr&gt;</span></td></tr><tr><td class="line-number" value="1255"></td><td class="line-content">							<span class="html-tag">&lt;th&gt;</span>Variance<span class="html-tag">&lt;/th&gt;</span></td></tr><tr><td class="line-number" value="1256"></td><td class="line-content">							<span class="html-tag">&lt;td&gt;</span>high (variance-reduction tricks can be used to mitigate this)<span class="html-tag">&lt;/td&gt;</span></td></tr><tr><td class="line-number" value="1257"></td><td class="line-content">							<span class="html-tag">&lt;td&gt;</span>low<span class="html-tag">&lt;/td&gt;</span></td></tr><tr><td class="line-number" value="1258"></td><td class="line-content">						<span class="html-tag">&lt;/tr&gt;</span></td></tr><tr><td class="line-number" value="1259"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1260"></td><td class="line-content">					<span class="html-tag">&lt;/table&gt;</span></td></tr><tr><td class="line-number" value="1261"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1262"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1263"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1264"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1265"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Amortized VI<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1266"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1267"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;div class="fragment" data-fragment-index="1" style="margin-left:2em; width:30%; float:right"&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1268"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;img class="noborder" style="width:100%" src="hoffman_conditional_conjugate.svg" alt=""&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1269"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;div style="font-size:40%"&gt;Adapted from &lt;em&gt;Stochastic Variational Inference&lt;/em&gt;, Hoffman, Blei, Wang, Paisley, 2013&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1270"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/div&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1271"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1272"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>One last trick to make it possible to scale to even larger datasets.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1273"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1274"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>In classic VI, we estimate a distribution per datapoint. E.g. in our mixture model example:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1275"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1276"></td><td class="line-content">					\[q(\boldsymbol Z | \boldsymbol \Phi) = \prod_n^N q(\boldsymbol z_n | \boldsymbol \phi_n) \]</td></tr><tr><td class="line-number" value="1277"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1278"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Remember that these \(q(\boldsymbol z_n)\) approximate \(p(\boldsymbol z_n|\boldsymbol x_n)\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1279"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1280"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span class="fragment"  data-fragment-index="1" &gt;--&gt;</span></td></tr><tr><td class="line-number" value="1281"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;As an example, let's consider the model type from before one more time&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1282"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1283"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\begin{align*}\mathcal{L}(\boldsymbol \theta) &amp;= \mathbb{E}_{q}\left[\ln p(\boldsymbol \beta, \boldsymbol X,\boldsymbol Z)\right] - \mathbb{E}_{q}\left[\ln q(\boldsymbol \beta, \boldsymbol Z)\right] \\--&gt;</span></td></tr><tr><td class="line-number" value="1284"></td><td class="line-content"><span class="html-comment">&lt;!--					&amp;= \mathbb{E}_{q}\left[\ln p(\boldsymbol X,\boldsymbol Z,\boldsymbol \beta)\right] - \mathbb{E}_{q}\left[\ln q(\boldsymbol \beta | \boldsymbol \theta) + \sum_{n=1}^N\ln q(\boldsymbol z_n | \boldsymbol \phi_n))\right]--&gt;</span></td></tr><tr><td class="line-number" value="1285"></td><td class="line-content"><span class="html-comment">&lt;!--					\end{align*}--&gt;</span></td></tr><tr><td class="line-number" value="1286"></td><td class="line-content"><span class="html-comment">&lt;!--					\]--&gt;</span></td></tr><tr><td class="line-number" value="1287"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1288"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1289"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"  <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" &gt;</span></td></tr><tr><td class="line-number" value="1290"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Idea: rather than having a dedicated variational distribution for each data point, let's learn a neural network \(f_\psi\) that maps from \(x_n\) to the parameters of the variational distribution.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1291"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1292"></td><td class="line-content">					\[q(\boldsymbol Z | \boldsymbol X, \boldsymbol \psi) = \prod_n^N q(\boldsymbol z_n | f_\psi(x_n)) \]</td></tr><tr><td class="line-number" value="1293"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1294"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\begin{align*}\mathcal{L}(\boldsymbol \theta) &amp;= \mathbb{E}_{q}\left[\ln p(\boldsymbol X,\boldsymbol Z,\boldsymbol \beta)\right] - \mathbb{E}_{q}\left[\ln q(\boldsymbol \beta) + \sum_{n=1}^N\ln q(\boldsymbol z_n | f_\psi(x_n)))\right]--&gt;</span></td></tr><tr><td class="line-number" value="1295"></td><td class="line-content"><span class="html-comment">&lt;!--					\end{align*}--&gt;</span></td></tr><tr><td class="line-number" value="1296"></td><td class="line-content"><span class="html-comment">&lt;!--					\]--&gt;</span></td></tr><tr><td class="line-number" value="1297"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1298"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1299"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>This is called <span class="html-tag">&lt;em&gt;</span>amortized variational inference<span class="html-tag">&lt;/em&gt;</span>.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1300"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1301"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1302"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1303"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1304"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Black box VI achieved!<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1305"></td><td class="line-content">					<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:80%; margin-top:2em</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/black_box_vi.svg" rel="noreferrer noopener">black_box_vi.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="1306"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:50%; width:50%; float:right; margin-top:1em</span>"&gt;</span>From Variational Inference: Foundations and Modern Methods, NeurIPS tutorial, Blei, Ranganath, Mohamed<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1307"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1308"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1309"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1310"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:center</span>"&gt;</span></td></tr><tr><td class="line-number" value="1311"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Variational autoencoders <span class="html-tag">&lt;br&gt;</span> (aka Deep latent variable models)<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1312"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1313"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1314"></td><td class="line-content">				<span class="html-comment">&lt;!-- &lt;section style="font-size:75%"&gt;</span></td></tr><tr><td class="line-number" value="1315"></td><td class="line-content"><span class="html-comment">					&lt;h3&gt;Remember Probabilistic PCA?&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1316"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="1317"></td><td class="line-content"><span class="html-comment">					&lt;div class="container"&gt;</span></td></tr><tr><td class="line-number" value="1318"></td><td class="line-content"><span class="html-comment">						&lt;div data-fragment-index="2" style="flex-grow: 3.5"&gt;</span></td></tr><tr><td class="line-number" value="1319"></td><td class="line-content"><span class="html-comment">							Ingredients:&lt;br&gt;</span></td></tr><tr><td class="line-number" value="1320"></td><td class="line-content"><span class="html-comment">							&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="1321"></td><td class="line-content"><span class="html-comment">								&lt;dt class="spaced"&gt;Prior distribution over \(\boldsymbol z\)&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="1322"></td><td class="line-content"><span class="html-comment">								&lt;dd&gt;\(p(\boldsymbol z) = \mathcal{N}(\boldsymbol z | 0, {\boldsymbol I)}\)&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="1323"></td><td class="line-content"><span class="html-comment">								&lt;dt class="spaced"&gt;Distribution over output variable - conditioned on \(\boldsymbol z\)&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="1324"></td><td class="line-content"><span class="html-comment">								&lt;dd&gt;\(p(\boldsymbol x | \boldsymbol z) = \mathcal{N}(\boldsymbol x | \boldsymbol W \boldsymbol z + \boldsymbol \mu, \sigma^2 \boldsymbol I)\)&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="1325"></td><td class="line-content"><span class="html-comment">							&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="1326"></td><td class="line-content"><span class="html-comment">							&lt;p&gt;The latent \(\boldsymbol z\) is \(M\)-dimensional, and \(\boldsymbol W\) is a \(D \times M\) matrix mapping linearly from \(\boldsymbol z\) to \(\boldsymbol x\).&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1327"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="1328"></td><td class="line-content"><span class="html-comment">						&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1329"></td><td class="line-content"><span class="html-comment">						&lt;div data-fragment-index="2" style="text-align: center; margin-left:0.5em; margin-top:0em"&gt;</span></td></tr><tr><td class="line-number" value="1330"></td><td class="line-content"><span class="html-comment">							&lt;img style="width:30%; padding:0.5em" class="noborder prml" src="../prmlfigs-svg/Figure9.4.svg"&gt;</span></td></tr><tr><td class="line-number" value="1331"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="1332"></td><td class="line-content"><span class="html-comment">							&lt;p style="font-size:60%"&gt;(same graphical model as for the discrete case)&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1333"></td><td class="line-content"><span class="html-comment">						&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1334"></td><td class="line-content"><span class="html-comment">					&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1335"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="1336"></td><td class="line-content"><span class="html-comment">					&lt;p class="fragment"&gt;Due to the linear mapping and Gaussian output node, maximizing the likelihood had a closed form solution.&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1337"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="1338"></td><td class="line-content"><span class="html-comment">					&lt;span class="fragment"&gt;</span></td></tr><tr><td class="line-number" value="1339"></td><td class="line-content"><span class="html-comment">					&lt;p&gt;What would happen if we plugged in a complex non-linear mapping?&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1340"></td><td class="line-content"><span class="html-comment">					\[p(\boldsymbol x | \boldsymbol z) = \mathcal{N}(\boldsymbol x | f_{\boldsymbol w_{\mu}}(\boldsymbol z), f_{\boldsymbol w_{\sigma^2}}(\boldsymbol z))\]</span></td></tr><tr><td class="line-number" value="1341"></td><td class="line-content"><span class="html-comment">					&lt;p&gt;How could we estimate something so complex? &lt;span class="fragment"&gt;VI!&lt;/span&gt; &lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1342"></td><td class="line-content"><span class="html-comment">						&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1343"></td><td class="line-content"><span class="html-comment">				&lt;/section&gt; --&gt;</span></td></tr><tr><td class="line-number" value="1344"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1345"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1346"></td><td class="line-content">					<span class="html-tag">&lt;h2&gt;</span>Deep latent variable models<span class="html-tag">&lt;/h2&gt;</span></td></tr><tr><td class="line-number" value="1347"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1348"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="1349"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 3</span>"&gt;</span></td></tr><tr><td class="line-number" value="1350"></td><td class="line-content">							<span class="html-tag">&lt;div&gt;</span>Model:<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1351"></td><td class="line-content">							<span class="html-tag">&lt;dl <span class="html-attribute-name">class</span>="<span class="html-attribute-value">list</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1352"></td><td class="line-content">								<span class="html-tag">&lt;dt&gt;</span>Prior: \(p(\boldsymbol z)\). Typically just a diagonal Normal. Same as for PPCA.<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="1353"></td><td class="line-content">								<span class="html-tag">&lt;dt&gt;</span>\(p_{\boldsymbol \theta}(\boldsymbol x|\boldsymbol z)\). Often chosen to be diagonal Gaussian \(\mathcal{N}\left(\boldsymbol x | \begin{bmatrix}\boldsymbol \mu_{\boldsymbol x}\\ \ln \boldsymbol \sigma_{\boldsymbol x}\end{bmatrix} = f_{\boldsymbol \theta}(\boldsymbol z)\right)\)<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="1354"></td><td class="line-content">								<span class="html-tag">&lt;dd&gt;</span></td></tr><tr><td class="line-number" value="1355"></td><td class="line-content">									where \(f_{\boldsymbol \theta}\) is a network parameterized by \(\boldsymbol \theta.\) <span class="html-tag">&lt;br&gt;</span>Sometimes called a <span class="html-tag">&lt;em&gt;</span>decoder<span class="html-tag">&lt;/em&gt;</span>.<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="1356"></td><td class="line-content">							<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="1357"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1358"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span></td></tr><tr><td class="line-number" value="1359"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:1em</span>"&gt;</span>For inference:<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1360"></td><td class="line-content">							<span class="html-tag">&lt;dl <span class="html-attribute-name">class</span>="<span class="html-attribute-value">list</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1361"></td><td class="line-content">								<span class="html-tag">&lt;dt&gt;</span>\(q_{\boldsymbol \phi}(\boldsymbol z | \boldsymbol x)\). Often also chosen to be a diagonal Gaussian \(\mathcal{N}\left(\boldsymbol z | \begin{bmatrix}\boldsymbol \mu_{\boldsymbol z}\\ \ln \boldsymbol \sigma_{\boldsymbol z}\end{bmatrix} = f_{\boldsymbol \phi}(\boldsymbol x)\right)\)<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="1362"></td><td class="line-content">								<span class="html-tag">&lt;dd&gt;</span></td></tr><tr><td class="line-number" value="1363"></td><td class="line-content">									where \(f_{\boldsymbol \phi}(\boldsymbol x)\) is a neural network with parameters \(\boldsymbol \phi\) (for amortized VI). Sometimes called an <span class="html-tag">&lt;em&gt;</span>encoder<span class="html-tag">&lt;/em&gt;</span>. <span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="1364"></td><td class="line-content">							<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="1365"></td><td class="line-content">							<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1366"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1367"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1368"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="1369"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:35%; padding:0.5em;</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder prml center</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/prmlfigs-svg/Figure9.4.svg" rel="noreferrer noopener">../prmlfigs-svg/Figure9.4.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="1370"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1371"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span></td></tr><tr><td class="line-number" value="1372"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%; padding:0.5em;</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/vae_model.svg" rel="noreferrer noopener">vae_model.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="1373"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">float:right; width:100%; font-size:60%</span>"&gt;</span>Auto-Encoding Variational Bayes, Kingma, Welling, 2014<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1374"></td><td class="line-content">								<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1375"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1376"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1377"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1378"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Note that the encoder is not part of the model. This is our variational approximation. It's only there to make inference tractable.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1379"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1380"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1381"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1382"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1383"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Deep latent variable models - ELBO<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1384"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1385"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>We write up the ELBO:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1386"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\begin{align*}\mathcal{L}(\boldsymbol \theta, \boldsymbol \phi, \boldsymbol X) &amp;= \sum_{n=1}^N \mathcal{L}(\boldsymbol \theta, \boldsymbol \phi, \boldsymbol x_n) \\--&gt;</span></td></tr><tr><td class="line-number" value="1387"></td><td class="line-content"><span class="html-comment">&lt;!--					&amp;= \mathbb{E}_{q_{\phi}(\boldsymbol z_n|\boldsymbol x_n)}\left[\ln p_{\theta}(x_n | \boldsymbol z_n)\right] - \text{KL}\left(q_{\phi}(\boldsymbol z_n|\boldsymbol x_n) || p_{\boldsymbol \theta}(\boldsymbol z_n)\right)--&gt;</span></td></tr><tr><td class="line-number" value="1388"></td><td class="line-content"><span class="html-comment">&lt;!--					\end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="1389"></td><td class="line-content">					\[\begin{align*}\mathcal{L}(\boldsymbol \theta, \boldsymbol \phi, \boldsymbol X) &amp;= \mathbb{E}_{q_{\phi}(\boldsymbol Z|\boldsymbol X)}\left[\ln p_{\boldsymbol \theta}(X | \boldsymbol Z)\right] - \text{KL}\left(q_{\phi}(\boldsymbol Z|\boldsymbol X) || p_{\boldsymbol \theta}(\boldsymbol Z)\right)</td></tr><tr><td class="line-number" value="1390"></td><td class="line-content">					\end{align*}\]</td></tr><tr><td class="line-number" value="1391"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1392"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Both are terms expectations over \(q_{\boldsymbol \phi}(\boldsymbol Z|\boldsymbol X)\), which we can approximate using Monte Carlo estimates.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1393"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1394"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Note that for the specific case where \(p(\boldsymbol z)\) and \(q_{\phi}(\boldsymbol z|\boldsymbol x)\) are diagonal Gaussians, a closed form expression exists for the \(\text{KL}\). In particular, when \(p(\boldsymbol z)\) is standard Normal:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1395"></td><td class="line-content">					\[\begin{align*}\text{KL}&amp;\left(\mathcal{N}\left(\begin{bmatrix}\mu_1\\ \vdots\\ \mu_D\end{bmatrix}, \text{diag}(\sigma^2_1, \ldots, \sigma_D^2)\right) || \mathcal{N}\left(\boldsymbol 0, \boldsymbol I)\right)\right) \\ &amp;= \frac{1}{2}\sum_{d=1}^D \left(\sigma^2_d + \mu_d^2 - 1 - \ln (\sigma_d^2)\right)\end{align*}\]</td></tr><tr><td class="line-number" value="1396"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1397"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1398"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;As usual, we can evaluate this expectation using a Monte Carlo estimate&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1399"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\mathbb{E}_{q_{\phi}(\boldsymbol Z|\boldsymbol X)}\left[\ln p_{\theta}(X | \boldsymbol Z)\right] \approx \frac{1}{L}\sum_{l=1}^L(\ln p_{\theta}(X | \boldsymbol Z^{(l)}) \hspace{1em} Z^{(l)} \sim q_{\phi}(\boldsymbol Z|\boldsymbol X)\]--&gt;</span></td></tr><tr><td class="line-number" value="1400"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1401"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;How do we evaluate the expectation? Monte Carlo estimate:&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1402"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;As usual, we can evaluate this expectation using a Monte Carlo estimate&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1403"></td><td class="line-content"><span class="html-comment">&lt;!--					\[\mathbb{E}_{q_{\phi}(\boldsymbol z_n|\boldsymbol x_n)}\left[\ln p_{\theta}(x_n | \boldsymbol z_n)\right] \approx \frac{1}{L}\sum_{l=1}^L(\ln p_{\theta}(x_n | \boldsymbol z^{(l)}_n) \hspace{1em} z^{(l)}_n \sim q_{\phi}(\boldsymbol z_n|\boldsymbol x_n)\]--&gt;</span></td></tr><tr><td class="line-number" value="1404"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1405"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Typically only one sample is used!&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1406"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1407"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;How do we evaluate the KL term? We can estimate it using a Monte Carlo estimate. But if both \(q_{\phi}(\boldsymbol z_n|\boldsymbol x_n)\) and \(p_{\boldsymbol \theta}(\boldsymbol z_n)\) are Normal distributions, there is a convenient closed form.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1408"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1409"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span style="color:red"&gt;STATE CLOSED FORM&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1410"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1411"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1412"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1413"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1414"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Deep latent variable models - Inference<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1415"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1416"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Optimization strategy: calculate stochastic gradients of the ELBO with respect to all parameters: \(\boldsymbol \phi\) and \(\boldsymbol \theta\) using the path approach (reparameterization trick).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1417"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1418"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>We can do this using standard backpropagation in an autodiff framework like torch (<span class="html-tag">&lt;code <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%</span>"&gt;</span>torch.distributions<span class="html-tag">&lt;/code&gt;</span> implements this through <span class="html-tag">&lt;code  <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%</span>"&gt;</span>.rsample()<span class="html-tag">&lt;/code&gt;</span> methods).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1419"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1420"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Note that when optimizing the network like this, we are optimizing both the inference network and the model at the same time.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1421"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1422"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1423"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Strategy: calculate stochastic gradients and optimize.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1424"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1425"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span style="color:red"&gt;FORMULA&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1426"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1427"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Note that both the model parameters, and the inference network parameters are optimized at the same time.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1428"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1429"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span style="color:red"&gt;FIGURE OF VAE WITH PARAMS&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1430"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1431"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;The reparameterization gradient estimator is used to provide gradient estimates with reasonable variance.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1432"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1433"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span style="color:red"&gt;EXAMPLE: Gaussian VAE&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1434"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1435"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>No model specific derivations necessary. Black-box Variational Inference in action!<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1436"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1437"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1438"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1439"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1440"></td><td class="line-content">					<span class="html-tag">&lt;h2&gt;</span>VAE - why is it called an "autoencoder"?<span class="html-tag">&lt;/h2&gt;</span></td></tr><tr><td class="line-number" value="1441"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1442"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>If we draw the full model we are optimizing, it looks similar to an autoencoder. This is why it is referred to as <span class="html-tag">&lt;em&gt;</span>variational autoencoder<span class="html-tag">&lt;/em&gt;</span>.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1443"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1444"></td><td class="line-content">					<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:70%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/VAE_Basic.png" rel="noreferrer noopener">VAE_Basic.png</a>"&gt;</span></td></tr><tr><td class="line-number" value="1445"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1446"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1447"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1448"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:60%; width:50%; float:right; margin-top:0em</span>"&gt;</span>Source: <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://en.m.wikipedia.org/wiki/File:VAE_Basic.png" rel="noreferrer noopener">https://en.m.wikipedia.org/wiki/File:VAE_Basic.png</a>"&gt;</span>https://en.m.wikipedia.org/wiki/File:VAE_Basic.png<span class="html-tag">&lt;/a&gt;</span><span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1449"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1450"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:-0.5em; clear:both</span>"&gt;</span>Key differences:<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1451"></td><td class="line-content">					<span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="1452"></td><td class="line-content">						<span class="html-tag">&lt;li <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>" &gt;</span>The encoder is not deterministic - it has a variance. It is vaguely similar to <span class="html-tag">&lt;em&gt;</span>denoising autoencoders<span class="html-tag">&lt;/em&gt;</span>, but there noise is injected in the input rather than in the latent representation.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="1453"></td><td class="line-content">						<span class="html-tag">&lt;li <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>We place a prior on \(p(\boldsymbol z)\), thus regularizing the representation space to a particular scale.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="1454"></td><td class="line-content">						<span class="html-tag">&lt;li <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>The VAE is a generative model which is trained to fit a density.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="1455"></td><td class="line-content">					<span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="1456"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1457"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1458"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1459"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1460"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Extension: Importance Weighted Auto Encoder (IWAE) <span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1461"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1462"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Interestingly, there is a tighter lower bound for VAEs than the ELBO.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1463"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1464"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="1465"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">border:1px solid lightgrey; margin:0.2em; margin-top:0; padding:0.5em; font-size:90% </span>"&gt;</span></td></tr><tr><td class="line-number" value="1466"></td><td class="line-content">							<span class="html-tag">&lt;h4&gt;</span>ELBO<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="1467"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1468"></td><td class="line-content">					\[\begin{align*}\ln p(x) &amp;= \ln \int p(x,z)dz\end{align*}\]</td></tr><tr><td class="line-number" value="1469"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1470"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1471"></td><td class="line-content">							\[\begin{align*}\htmlStyle{visibility:hidden;}{\ln p(x)} &amp;= \ln \int \frac{p(x,z)}{q(z)}q(z)dz \end{align*}\]</td></tr><tr><td class="line-number" value="1472"></td><td class="line-content">							<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1473"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1474"></td><td class="line-content">							\[\begin{align*}\htmlStyle{visibility:hidden;}{\ln p(x)} &amp;= \ln \left (\mathbb{E}_{q(\boldsymbol z)} \left [ \frac{p(x,z)}{q(z)}\right ]\right) \end{align*}\]</td></tr><tr><td class="line-number" value="1475"></td><td class="line-content">							<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1476"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1477"></td><td class="line-content">							\[\begin{align*}\htmlStyle{visibility:hidden;}{\ln p(x)} &amp;\ge  \underbrace{\mathbb{E}_{q(\boldsymbol z)} \left [\ln \left (\frac{p(x,z)}{q(z)} \right )\right ]}_{\mathcal{L}_{\text{ELBO}}} \end{align*}\]</td></tr><tr><td class="line-number" value="1478"></td><td class="line-content">							<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1479"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1480"></td><td class="line-content"><span class="html-comment">&lt;!--							\[\begin{align*}\htmlStyle{visibility:visible;}{\mathcal{L}_{\text{ELBO}}} &amp;\coloneqq  \mathbb{E}_{q(\boldsymbol z)} \left [\ln \left (\frac{p(x,z)}{q(z)} \right )\right ] \end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="1481"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1482"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1483"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1484"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">border:1px solid lightgrey; margin:0.2em; margin-top:0; padding:0.5em; font-size:90% </span>"&gt;</span></td></tr><tr><td class="line-number" value="1485"></td><td class="line-content">							<span class="html-tag">&lt;h4&gt;</span>IWAE<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="1486"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1487"></td><td class="line-content"><span class="html-comment">&lt;!--							\[\begin{align*}\ln p(x) &amp;= \ln \int p(x,z)dz\end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="1488"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1489"></td><td class="line-content">							\[\begin{align*}\ln p(x) &amp;= \ln \bigg( \mathbb{E}_{z_1, \ldots, z_K \sim q(\boldsymbol z)} \bigg [ \underbrace{\frac{1}{K}\sum_{k=1}^K \frac{p(x,z^{(k)})}{q(z^{(k)})}}_{\substack{\text{importance sampling} \\ \text{estimator of }p(x)}}  \bigg] \bigg) \end{align*}\]</td></tr><tr><td class="line-number" value="1490"></td><td class="line-content">							<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1491"></td><td class="line-content">							<span class="html-tag">&lt;spanstyle="font-size:90%"&gt;</span></td></tr><tr><td class="line-number" value="1492"></td><td class="line-content">							\[\begin{align*}\htmlStyle{visibility:hidden;}{\ln p(x)} &amp;\ge \underbrace{\mathbb{E}_{z_1, \ldots, z_K \sim q(\boldsymbol z)} \bigg[\ln \bigg(\frac{1}{K}\sum_{k=1}^K \frac{p(x,z^{(k)})}{q(z^{(k)})} \bigg) \bigg]}_{\mathcal{L}_{\text{IWAE}}}\end{align*}\]</td></tr><tr><td class="line-number" value="1493"></td><td class="line-content"><span class="html-comment">&lt;!--							\[\begin{align*}\htmlStyle{visibility:hidden;}{\ln p(x)} &amp;= \ln \int \frac{p(x,z)}{q(z)}q(z)dz \end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="1494"></td><td class="line-content"><span class="html-comment">&lt;!--							\[\begin{align*}\htmlStyle{visibility:hidden;}{\ln p(x)} &amp;= \ln \left( \mathbb{E}_{z_1, \ldots, z_K \sim q(\boldsymbol z)} \left [ \frac{1}{K}\sum_{k=1}^K \frac{p(x,z^{(k)})}{q(z^{(k)})}  \right] \right) \end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="1495"></td><td class="line-content">							<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1496"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1497"></td><td class="line-content"><span class="html-comment">&lt;!--							\[\begin{align*}\htmlStyle{visibility:hidden;}{\ln p(x)} &amp;= \ln \left (\mathbb{E}_{q(\boldsymbol z)} \left [ \frac{p(x,z)}{q(z)}\right ]\right) \end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="1498"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1499"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1500"></td><td class="line-content"><span class="html-comment">&lt;!--							\[\begin{align*}\htmlStyle{visibility:hidden;}{\ln p(x)} &amp;\approx \ln \bigg(\underbrace{\frac{1}{K}\sum_{k=1}^K\left [ \frac{p(x,z_k)}{q(z_k)}\right ]}_{\text{importance sampling}}\bigg) \end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="1501"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1502"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1503"></td><td class="line-content"><span class="html-comment">&lt;!--							\[\begin{align*}\htmlStyle{visibility:visible;}{\mathcal{L}_{\text{IWAE}}} &amp;\coloneqq  \mathbb{E}_{z_1, \ldots, z_K \sim q(\boldsymbol z)} \left [\ln \left (\frac{1}{K}\sum_{k=1}^K\left [ \frac{p(x,z_k)}{q(z_k)}\right ] \right )\right ] \end{align*}\]--&gt;</span></td></tr><tr><td class="line-number" value="1504"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;/span&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1505"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>By increasing K, the entries in the expectation will be distributed more closely around \(p(x)\), giving us a tighter bound.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1506"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1507"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1508"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1509"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1510"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1511"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1512"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1513"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Importance Weighted Auto Encoder (IWAE) (2) <span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1514"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1515"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;The bound is the expectation of the importance sampler estimate with \(k\) samples.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1516"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1517"></td><td class="line-content">					\[\htmlStyle{visibility:visible;}{\mathcal{L}_{\text{IWAE}}} \coloneqq  \mathbb{E}_{z_1, \ldots, z_K \sim q(\boldsymbol z)} \bigg[\ln \bigg(\frac{1}{K}\sum_{k=1}^K \frac{p(x,z_k)}{q(z_k)} \bigg)\bigg]\]</td></tr><tr><td class="line-number" value="1518"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1519"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>As usual, the expectation is approximated with a Monte Carlo estimate:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1520"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1521"></td><td class="line-content">					\[\begin{align*}\htmlStyle{visibility:visible;}{\mathcal{L}_{\text{IWAE}}} &amp;\approx \underbrace{\frac{1}{L} \sum_{i=1}^L}_{\substack{\text{increasing L} \\ \text{reduces the variance}}} \bigg( \ln \bigg(\underbrace{\frac{1}{K}\sum_{k=1}^K \frac{p(x,z_{i,k})}{q(z_{i,k})}}_{\substack{\text{increasing K} \\ \text{tightens the gap}}} \bigg) \bigg) \end{align*}\]</td></tr><tr><td class="line-number" value="1522"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1523"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Typically, you would use \(L \approx 1\) and \(K \approx 10\).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1524"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1525"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Note that for \(K=1\), \(\mathcal{L}_{\text{IWAE}}=\mathcal{L}_{\text{ELBO}}\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1526"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1527"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%; margin-top:3em; padding-left:5em; padding-right:0em; font-size:70%; text-align:right; box-sizing:border-box</span>"&gt;</span></td></tr><tr><td class="line-number" value="1528"></td><td class="line-content">						Burda, Grosse, Salakhutdinov. Importance Weighted Autoencoders. <span class="html-tag">&lt;em&gt;</span>ICLR<span class="html-tag">&lt;/em&gt;</span>, 2016.<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="1529"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1530"></td><td class="line-content">						See also: <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://borea17.github.io/paper_summaries/iwae/" rel="noreferrer noopener">https://borea17.github.io/paper_summaries/iwae/</a>"&gt;</span>https://borea17.github.io/paper_summaries/iwae/<span class="html-tag">&lt;/a&gt;</span></td></tr><tr><td class="line-number" value="1531"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1532"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1533"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1534"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1535"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1536"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Extension: hierarchical VAEs<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1537"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1538"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>You can also use VAEs to generate images.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1539"></td><td class="line-content">					</td></tr><tr><td class="line-number" value="1540"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>To get crisp images, it turned out to be necessary to design more complex VAE architectures, with multiple latent variables.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1541"></td><td class="line-content">					</td></tr><tr><td class="line-number" value="1542"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="1543"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="1544"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:65%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/nvae_figure.svg" rel="noreferrer noopener">nvae_figure.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="1545"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1546"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="1547"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:65%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/nvae_examples.png" rel="noreferrer noopener">nvae_examples.png</a>"&gt;</span></td></tr><tr><td class="line-number" value="1548"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1549"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1550"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1551"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>In such more architectures, the challenge is to design powerful enough inference networks.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1552"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1553"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%; margin-top:0em; padding-left:5em; padding-right:0em; font-size:70%; text-align:right; box-sizing:border-box</span>"&gt;</span></td></tr><tr><td class="line-number" value="1554"></td><td class="line-content">						Vahdat, Kautz. NVAE: A Deep Hierarchical Variational Autoencoder. <span class="html-tag">&lt;em&gt;</span>NeurIPS<span class="html-tag">&lt;/em&gt;</span>, 2020.</td></tr><tr><td class="line-number" value="1555"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1556"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1557"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1558"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1559"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font:90%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1560"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>VAEs for representation learning<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1561"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1562"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Autoencoders are often used for representation learning (i.e. dimensionality reduction).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1563"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1564"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>We can use VAEs in the same way - by encoding inputs \(\boldsymbol x\) to their corresponding latent variables \(\boldsymbol z\).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1565"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1566"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1567"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1568"></td><td class="line-content">				<span class="html-tag">&lt;section&gt;</span></td></tr><tr><td class="line-number" value="1569"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>VAEs for representation learning - example<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1570"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1571"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="1572"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="1573"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:2em;</span>"&gt;</span></td></tr><tr><td class="line-number" value="1574"></td><td class="line-content">								<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">r-stack</span>"&gt;</span></td></tr><tr><td class="line-number" value="1575"></td><td class="line-content">									<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/geodesic_plot_embedding.png" rel="noreferrer noopener">geodesic_plot_embedding.png</a>"&gt;</span></td></tr><tr><td class="line-number" value="1576"></td><td class="line-content">									<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment noborder</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/geodesic_plot_embedding_tree.png" rel="noreferrer noopener">geodesic_plot_embedding_tree.png</a>"&gt;</span></td></tr><tr><td class="line-number" value="1577"></td><td class="line-content">								<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1578"></td><td class="line-content">							<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1579"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1580"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1581"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">r-stack</span>"&gt;</span></td></tr><tr><td class="line-number" value="1582"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center fragment</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:95%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/geodesic_map_new_no_geodesic.png" rel="noreferrer noopener">geodesic_map_new_no_geodesic.png</a>"&gt;</span></td></tr><tr><td class="line-number" value="1583"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center fragment</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:95%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/geodesic_map_new.png" rel="noreferrer noopener">geodesic_map_new.png</a>"&gt;</span></td></tr><tr><td class="line-number" value="1584"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1585"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1586"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1587"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1588"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%; padding-left:5em; padding-right:0em; font-size:50%; box-sizing:border-box</span>"&gt;</span></td></tr><tr><td class="line-number" value="1589"></td><td class="line-content">						Detlefsen, N.S., Hauberg, S. and Boomsma, W., 2022. Learning meaningful representations of protein sequences. <span class="html-tag">&lt;em&gt;</span>Nature communications<span class="html-tag">&lt;/em&gt;</span>, 13(1), pp.1-12.</td></tr><tr><td class="line-number" value="1590"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1591"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1592"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1593"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1594"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1595"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1596"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Deep latent variable models - conclusion<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1597"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1598"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>Black-box variational inference has made VI mainstream - and has made the VAE a very popular model<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1599"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1600"></td><td class="line-content">					<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/google_trends_variational_autoencoder.png" rel="noreferrer noopener">google_trends_variational_autoencoder.png</a>"&gt;</span></td></tr><tr><td class="line-number" value="1601"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1602"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Compared to the derivations we did for classic VI, very little is required to implement a VAE.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1603"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1604"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>We'll see this in action during the exercise session.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1605"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1606"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1607"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1608"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:center</span>"&gt;</span></td></tr><tr><td class="line-number" value="1609"></td><td class="line-content">					<span class="html-tag">&lt;h2&gt;</span>Other approximate inference techniques?<span class="html-tag">&lt;/h2&gt;</span></td></tr><tr><td class="line-number" value="1610"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1611"></td><td class="line-content">					<span class="html-tag">&lt;h3 <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span> - the Laplace approximation<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1612"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1613"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1614"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1615"></td><td class="line-content">					<span class="html-tag">&lt;h2&gt;</span>Laplace approximation<span class="html-tag">&lt;/h2&gt;</span> </td></tr><tr><td class="line-number" value="1616"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1617"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="1618"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="1619"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Goal: approximate (potentially unnormalized) density \(\tilde p(z)\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1620"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1621"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Idea: approximate by a Normal distribution at one of its modes<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1622"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1623"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1624"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="1625"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:65%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/prmlfigs-svg/Figure4.14a.svg" rel="noreferrer noopener">../prmlfigs-svg/Figure4.14a.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="1626"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1627"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1628"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1629"></td><td class="line-content">					<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="1630"></td><td class="line-content">						<span class="html-tag">&lt;dt&gt;</span>How do we do this?<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="1631"></td><td class="line-content">						<span class="html-tag">&lt;dd <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Taylor expansion up to 2nd order at mode \(z_0\)</td></tr><tr><td class="line-number" value="1632"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1633"></td><td class="line-content">						\[\ln \tilde p(z) \approx \ln \tilde p(z_0) + \underbrace{(z-z_0)\frac{\partial \ln p(z)}{\partial z}\bigg\rvert_{z=z_0}}_{=0 \text{ since we are at a mode}} + \frac{1}{2}(z-z_0)^2\underbrace{\frac{\partial^2 \ln p(z)}{\partial z^2}\bigg\rvert_{z=z_0}}_{{\coloneqq}-\frac{1}{\sigma^2}}\]</td></tr><tr><td class="line-number" value="1634"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1635"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:1em</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>\[\text{so, }\tilde p(z) \approx \tilde p(z_0)\exp\left(-\frac{1}{2}\frac{(z-z_0)^2}{\sigma^2}\right) \propto \frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{1}{2}\frac{(z-z_0)^2}{\sigma^2}\right) = \mathcal{N}(z_0, \sigma^2)\]<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1636"></td><td class="line-content">						<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="1637"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1638"></td><td class="line-content">					<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="1639"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Note that \(\sigma &gt; 0\) implies that the second derivative must be negative (i.e. \(z_0\) must be a local <span class="html-tag">&lt;em&gt;</span>maximum<span class="html-tag">&lt;/em&gt;</span>)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1640"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1641"></td><td class="line-content">					<span class="html-tag">&lt;aside <span class="html-attribute-name">class</span>="<span class="html-attribute-value">notes</span>"&gt;</span></td></tr><tr><td class="line-number" value="1642"></td><td class="line-content">						The Laplace approximation thus finds the fit by ensuring that the first and second derivates match at point \(z_0\).</td></tr><tr><td class="line-number" value="1643"></td><td class="line-content">					<span class="html-tag">&lt;/aside&gt;</span></td></tr><tr><td class="line-number" value="1644"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1645"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1646"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1647"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1648"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Laplace approximation - example<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1649"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1650"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="1651"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="1652"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1653"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Approximating a mixture model with two components (Student-t distributed) with Laplace approximations at the two modes.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1654"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1655"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">4</span>"&gt;</span>Note that the approximation only summarizes the target distribution around one mode.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1656"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1657"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">5</span>"&gt;</span>Also note how easy it is to evaluate the 2nd derivative (i.e. hessian) with autodiff<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1658"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1659"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1660"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="1661"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1662"></td><td class="line-content">							<span class="html-tag">&lt;pre&gt;</span><span class="html-tag">&lt;code <span class="html-attribute-name">class</span>="<span class="html-attribute-value">python</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>"&gt;</span>import torch</td></tr><tr><td class="line-number" value="1663"></td><td class="line-content">import torch.distributions as D</td></tr><tr><td class="line-number" value="1664"></td><td class="line-content">from torch.autograd.functional import hessian</td></tr><tr><td class="line-number" value="1665"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1666"></td><td class="line-content">mix = D.Categorical(torch.tensor([0.6, 0.4]))</td></tr><tr><td class="line-number" value="1667"></td><td class="line-content">comp = D.StudentT(df=1,</td></tr><tr><td class="line-number" value="1668"></td><td class="line-content">                  loc=torch.tensor([1., 2.]),</td></tr><tr><td class="line-number" value="1669"></td><td class="line-content">                  scale=torch.tensor([.2, .5]))</td></tr><tr><td class="line-number" value="1670"></td><td class="line-content">mm = D.MixtureSameFamily(mix, comp)<span class="html-tag">&lt;/code&gt;</span><span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="1671"></td><td class="line-content"><span class="html-tag">&lt;pre <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" &gt;</span><span class="html-tag">&lt;code <span class="html-attribute-name">class</span>="<span class="html-attribute-value">python</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>"&gt;</span>x_mode = torch.tensor(1.)</td></tr><tr><td class="line-number" value="1672"></td><td class="line-content">sigma = (-hessian(mm.log_prob, x_mode))**(-1/2)</td></tr><tr><td class="line-number" value="1673"></td><td class="line-content">laplace_approx1 = D.Normal(x_mode, sigma)<span class="html-tag">&lt;/code&gt;</span><span class="html-tag">&lt;/pre&gt;</span></td></tr><tr><td class="line-number" value="1674"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1675"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">r-stack</span>"&gt;</span></td></tr><tr><td class="line-number" value="1676"></td><td class="line-content">								<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/laplace1.svg" rel="noreferrer noopener">laplace1.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="1677"></td><td class="line-content">								<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/laplace2.svg" rel="noreferrer noopener">laplace2.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="1678"></td><td class="line-content">								<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/laplace3.svg" rel="noreferrer noopener">laplace3.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="1679"></td><td class="line-content">							<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1680"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1681"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1682"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1683"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1684"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:95%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1685"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Laplace approximation in higher dimensions<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1686"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1687"></td><td class="line-content">					<span class="html-tag">&lt;dl <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%;</span>"&gt;</span></td></tr><tr><td class="line-number" value="1688"></td><td class="line-content">						<span class="html-tag">&lt;dt&gt;</span>Laplace works similarly in higher dimensions<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="1689"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span>A mode is now defined by the gradient being zero, \(\nabla \tilde p(\boldsymbol z)=0\), and the Hessian matrix defines the negative inverse covariance matrix \(\Sigma^{-1}\).</td></tr><tr><td class="line-number" value="1690"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1691"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1692"></td><td class="line-content">							\[\ln \tilde p(z) \approx \ln \tilde p(z_0) + \underbrace{(z-z_0)\nabla \ln p(z)\rvert_{\boldsymbol z=\boldsymbol z_0}}_{=0 \text{ since we are at a mode}} + \frac{1}{2}(\boldsymbol z-\boldsymbol z_0)^2\underbrace{\nabla\nabla \ln p(\boldsymbol z)\rvert_{\boldsymbol z=\boldsymbol z_0}}_{{\coloneqq}-\boldsymbol \Sigma^{-1}}\]</td></tr><tr><td class="line-number" value="1693"></td><td class="line-content">							<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="1694"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1695"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:1em; font-size:85%</span>"&gt;</span>\[\text{so, }\tilde p(z) \approx \tilde p(\boldsymbol z_0)\exp\left(-\frac{1}{2}(\boldsymbol z- \boldsymbol z_0)^T\Sigma^{-1}(\boldsymbol z-\boldsymbol z_0)\right) \propto \mathcal{N}(\boldsymbol z_0, \boldsymbol \Sigma)\]<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1696"></td><td class="line-content">						<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="1697"></td><td class="line-content">					<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="1698"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1699"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1700"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="1701"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Laplace approximation - conclusions<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="1702"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1703"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>The Laplace approximation is a simple technique to approximate a probability density.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1704"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1705"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>We have to pick a local maximum \(z_0\) at which to evaluate it. We would typically get this using some optimizer.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1706"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1707"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span>The main weakness of the method is that it uses information only from this single point \(z_0\), making it a very local procedure.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1708"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1709"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1710"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="1711"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span><span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>"&gt;</span>Despite its simplicity, the method has seen a revival in recent years<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1712"></td><td class="line-content">						</td></tr><tr><td class="line-number" value="1713"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"  <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:2em</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>"&gt;</span>For instance in the estimation of deep latent variable models<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="1714"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1715"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span><span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/laplace_redux_title.png" rel="noreferrer noopener">laplace_redux_title.png</a>"&gt;</span></td></tr><tr><td class="line-number" value="1716"></td><td class="line-content">							 <span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week2/variational_laplace_autoencoders_title.png" rel="noreferrer noopener">variational_laplace_autoencoders_title.png</a>"&gt;</span><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1717"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1718"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="1719"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1720"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1721"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1722"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1723"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h3&gt;VAEs are popular&lt;/h3&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1724"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1725"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1726"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1727"></td><td class="line-content">				<span class="html-comment">&lt;!--				&lt;section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1728"></td><td class="line-content"><span class="html-comment">&lt;!--					conditional VAEs--&gt;</span></td></tr><tr><td class="line-number" value="1729"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1730"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1731"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1732"></td><td class="line-content"><span class="html-comment">&lt;!--					Latent space interpolation--&gt;</span></td></tr><tr><td class="line-number" value="1733"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1734"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1735"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1736"></td><td class="line-content"><span class="html-comment">&lt;!--					DeepSequence--&gt;</span></td></tr><tr><td class="line-number" value="1737"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1738"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1739"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1740"></td><td class="line-content"><span class="html-comment">&lt;!--					https://magenta.tensorflow.org/music-vae--&gt;</span></td></tr><tr><td class="line-number" value="1741"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1742"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1743"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1744"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;h3&gt;Beyond mean-field?&lt;/h3&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1745"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1746"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Stay tuned. Oswin will talk about Flows later.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1747"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;/section&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1748"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1749"></td><td class="line-content">			<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1750"></td><td class="line-content">		<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="1751"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1752"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/dist/reveal.js" rel="noreferrer noopener">../reveal.js-4.5.0/dist/reveal.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="1753"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/plugin/notes/notes.js" rel="noreferrer noopener">../reveal.js-4.5.0/plugin/notes/notes.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="1754"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/plugin/markdown/markdown.js" rel="noreferrer noopener">../reveal.js-4.5.0/plugin/markdown/markdown.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="1755"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/plugin/highlight/highlight.js" rel="noreferrer noopener">../reveal.js-4.5.0/plugin/highlight/highlight.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="1756"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/plugin/math/math.js" rel="noreferrer noopener">../reveal.js-4.5.0/plugin/math/math.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="1757"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/plugin/zoom/zoom.js" rel="noreferrer noopener">../reveal.js-4.5.0/plugin/zoom/zoom.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="1758"></td><td class="line-content">		<span class="html-tag">&lt;script&gt;</span></td></tr><tr><td class="line-number" value="1759"></td><td class="line-content">			// More info about initialization &amp; config:</td></tr><tr><td class="line-number" value="1760"></td><td class="line-content">			// - https://revealjs.com/initialization/</td></tr><tr><td class="line-number" value="1761"></td><td class="line-content">			// - https://revealjs.com/config/</td></tr><tr><td class="line-number" value="1762"></td><td class="line-content">			Reveal.initialize({</td></tr><tr><td class="line-number" value="1763"></td><td class="line-content">				katex: {</td></tr><tr><td class="line-number" value="1764"></td><td class="line-content">					trust:true</td></tr><tr><td class="line-number" value="1765"></td><td class="line-content">				},</td></tr><tr><td class="line-number" value="1766"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1767"></td><td class="line-content">				hash: true,</td></tr><tr><td class="line-number" value="1768"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1769"></td><td class="line-content">				slideNumber: true,</td></tr><tr><td class="line-number" value="1770"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1771"></td><td class="line-content">				transitionSpeed: 'fast',</td></tr><tr><td class="line-number" value="1772"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1773"></td><td class="line-content">				// Learn about plugins: https://revealjs.com/plugins/</td></tr><tr><td class="line-number" value="1774"></td><td class="line-content">				// plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.MathJax2 ]</td></tr><tr><td class="line-number" value="1775"></td><td class="line-content">				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom, RevealMath.KaTeX() ]</td></tr><tr><td class="line-number" value="1776"></td><td class="line-content">			});</td></tr><tr><td class="line-number" value="1777"></td><td class="line-content">		<span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="1778"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1779"></td><td class="line-content"><span class="html-comment">&lt;!--		&lt;script src="../jquery-3.6.0.min.js"&gt;&lt;/script&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1780"></td><td class="line-content"><span class="html-comment">&lt;!--	  &lt;script&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1781"></td><td class="line-content"><span class="html-comment">&lt;!--			$(document).ready(function() {--&gt;</span></td></tr><tr><td class="line-number" value="1782"></td><td class="line-content"><span class="html-comment">&lt;!--				$(".prml.center").removeClass('center').wrap('&lt;div class="pmrlref" style="text-align: center"&gt;&lt;/div&gt;').parent().append('&lt;span style="writing-mode: vertical-rl; display: inline-block; font-size: 30%; margin-top:10%; vertical-align: top"&gt;Pattern Recognition and Machine Learning, Bishop&lt;/span&gt;');--&gt;</span></td></tr><tr><td class="line-number" value="1783"></td><td class="line-content"><span class="html-comment">&lt;!--			});--&gt;</span></td></tr><tr><td class="line-number" value="1784"></td><td class="line-content"><span class="html-comment">&lt;!--		&lt;/script&gt;--&gt;</span></td></tr><tr><td class="line-number" value="1785"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1786"></td><td class="line-content">				<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/jquery-3.6.0.min.js" rel="noreferrer noopener">../jquery-3.6.0.min.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="1787"></td><td class="line-content">			  <span class="html-tag">&lt;script&gt;</span></td></tr><tr><td class="line-number" value="1788"></td><td class="line-content">					$(document).ready(function() {</td></tr><tr><td class="line-number" value="1789"></td><td class="line-content">						$(".prml").wrap('&lt;a href="https://www.microsoft.com/en-us/research/people/cmbishop/prml-book" title="Figure from Pattern Recognition and Machine Learning, by Christopher Bishop."/&gt;&lt;/a&gt;');</td></tr><tr><td class="line-number" value="1790"></td><td class="line-content">					});</td></tr><tr><td class="line-number" value="1791"></td><td class="line-content">				<span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="1792"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="1793"></td><td class="line-content">	<span class="html-tag">&lt;/body&gt;</span></td></tr><tr><td class="line-number" value="1794"></td><td class="line-content"><span class="html-tag">&lt;/html&gt;</span></td></tr><tr><td class="line-number" value="1795"></td><td class="line-content"><span class="html-end-of-file"></span></td></tr></tbody></table></body></html>