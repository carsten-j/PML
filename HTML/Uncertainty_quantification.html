
<!-- saved from url=(0077)https://wouterboomsma.github.io/pml2024/week7/uncertainty_quantification.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="color-scheme" content="light dark"></head><body><div class="line-gutter-backdrop"></div><form autocomplete="off"><label class="line-wrap-control">Line wrap<input type="checkbox" aria-label="Line wrap"></label></form><table><tbody><tr><td class="line-number" value="1"></td><td class="line-content"><span class="html-doctype">&lt;!doctype html&gt;</span></td></tr><tr><td class="line-number" value="2"></td><td class="line-content"><span class="html-tag">&lt;html&gt;</span></td></tr><tr><td class="line-number" value="3"></td><td class="line-content">	<span class="html-tag">&lt;head&gt;</span></td></tr><tr><td class="line-number" value="4"></td><td class="line-content">		<span class="html-tag">&lt;meta <span class="html-attribute-name">charset</span>="<span class="html-attribute-value">utf-8</span>"&gt;</span></td></tr><tr><td class="line-number" value="5"></td><td class="line-content">		<span class="html-tag">&lt;meta <span class="html-attribute-name">name</span>="<span class="html-attribute-value">viewport</span>" <span class="html-attribute-name">content</span>="<span class="html-attribute-value">width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no</span>"&gt;</span></td></tr><tr><td class="line-number" value="6"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="7"></td><td class="line-content">		<span class="html-tag">&lt;title&gt;</span>Probabilistic Machine Learning<span class="html-tag">&lt;/title&gt;</span></td></tr><tr><td class="line-number" value="8"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="9"></td><td class="line-content">		<span class="html-tag">&lt;link <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/dist/reset.css" rel="noreferrer noopener">../reveal.js-4.5.0/dist/reset.css</a>"&gt;</span></td></tr><tr><td class="line-number" value="10"></td><td class="line-content">		<span class="html-tag">&lt;link <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/dist/reveal.css" rel="noreferrer noopener">../reveal.js-4.5.0/dist/reveal.css</a>"&gt;</span></td></tr><tr><td class="line-number" value="11"></td><td class="line-content">		<span class="html-tag">&lt;link <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/dist/theme/white-helv.css" rel="noreferrer noopener">../reveal.js-4.5.0/dist/theme/white-helv.css</a>"&gt;</span></td></tr><tr><td class="line-number" value="12"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="13"></td><td class="line-content">		<span class="html-comment">&lt;!-- Theme used for syntax highlighted code --&gt;</span></td></tr><tr><td class="line-number" value="14"></td><td class="line-content">		<span class="html-tag">&lt;link <span class="html-attribute-name">rel</span>="<span class="html-attribute-value">stylesheet</span>" <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/googlecode.css" rel="noreferrer noopener">../googlecode.css</a>"&gt;</span></td></tr><tr><td class="line-number" value="15"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="16"></td><td class="line-content">		<span class="html-tag">&lt;style&gt;</span></td></tr><tr><td class="line-number" value="17"></td><td class="line-content">			.reveal .slides {</td></tr><tr><td class="line-number" value="18"></td><td class="line-content">				text-align: left;</td></tr><tr><td class="line-number" value="19"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="20"></td><td class="line-content">			.reveal a {</td></tr><tr><td class="line-number" value="21"></td><td class="line-content">				color:DarkSlateBlue;</td></tr><tr><td class="line-number" value="22"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="23"></td><td class="line-content">			.reveal section img {</td></tr><tr><td class="line-number" value="24"></td><td class="line-content">				border: 1px solid lightgrey;</td></tr><tr><td class="line-number" value="25"></td><td class="line-content">				box-shadow: none;</td></tr><tr><td class="line-number" value="26"></td><td class="line-content">				margin:0;</td></tr><tr><td class="line-number" value="27"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="28"></td><td class="line-content">			.reveal section img.noborder {</td></tr><tr><td class="line-number" value="29"></td><td class="line-content">				border: none;</td></tr><tr><td class="line-number" value="30"></td><td class="line-content">				box-shadow: none;</td></tr><tr><td class="line-number" value="31"></td><td class="line-content">				margin:0</td></tr><tr><td class="line-number" value="32"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="33"></td><td class="line-content">			.reveal section img.center {</td></tr><tr><td class="line-number" value="34"></td><td class="line-content">				display: block;</td></tr><tr><td class="line-number" value="35"></td><td class="line-content">				margin: 0 auto;</td></tr><tr><td class="line-number" value="36"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="37"></td><td class="line-content">			.reveal section div.container{</td></tr><tr><td class="line-number" value="38"></td><td class="line-content">				display: flex;</td></tr><tr><td class="line-number" value="39"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="40"></td><td class="line-content">			.reveal section div.container div{</td></tr><tr><td class="line-number" value="41"></td><td class="line-content">				flex: 1;</td></tr><tr><td class="line-number" value="42"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="43"></td><td class="line-content">			.reveal dt.spaced {</td></tr><tr><td class="line-number" value="44"></td><td class="line-content">				margin-top:0.5em;</td></tr><tr><td class="line-number" value="45"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="46"></td><td class="line-content">			.MathJax_Display {</td></tr><tr><td class="line-number" value="47"></td><td class="line-content">				font-size: 75% !important;</td></tr><tr><td class="line-number" value="48"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="49"></td><td class="line-content">			.katex {</td></tr><tr><td class="line-number" value="50"></td><td class="line-content">				font-size: 100% !important;</td></tr><tr><td class="line-number" value="51"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="52"></td><td class="line-content">			.reveal .katex-display {</td></tr><tr><td class="line-number" value="53"></td><td class="line-content">				margin-top:0.25em;</td></tr><tr><td class="line-number" value="54"></td><td class="line-content">				margin-bottom:0.25em;</td></tr><tr><td class="line-number" value="55"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="56"></td><td class="line-content">			.reveal .katex-display&gt;.katex {</td></tr><tr><td class="line-number" value="57"></td><td class="line-content">				text-align:left;</td></tr><tr><td class="line-number" value="58"></td><td class="line-content">				margin-left:1em;</td></tr><tr><td class="line-number" value="59"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="60"></td><td class="line-content">			.reveal section dl.list dt {</td></tr><tr><td class="line-number" value="61"></td><td class="line-content">				display:list-item;</td></tr><tr><td class="line-number" value="62"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="63"></td><td class="line-content">			.reveal section dl.list dd {</td></tr><tr><td class="line-number" value="64"></td><td class="line-content">				margin-left:0;</td></tr><tr><td class="line-number" value="65"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="66"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="67"></td><td class="line-content">			.scrollable-slide {</td></tr><tr><td class="line-number" value="68"></td><td class="line-content">				height: 100%;</td></tr><tr><td class="line-number" value="69"></td><td class="line-content">				overflow-y: auto !important;</td></tr><tr><td class="line-number" value="70"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="71"></td><td class="line-content">			::-webkit-scrollbar {</td></tr><tr><td class="line-number" value="72"></td><td class="line-content">				width: 4px;</td></tr><tr><td class="line-number" value="73"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="74"></td><td class="line-content">			::-webkit-scrollbar-track {</td></tr><tr><td class="line-number" value="75"></td><td class="line-content">				-webkit-box-shadow: inset 0 0 6px rgba(255,255,255,0.3);</td></tr><tr><td class="line-number" value="76"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="77"></td><td class="line-content">			::-webkit-scrollbar-thumb {</td></tr><tr><td class="line-number" value="78"></td><td class="line-content">				background-color: #333;</td></tr><tr><td class="line-number" value="79"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="80"></td><td class="line-content">			::-webkit-scrollbar-corner {</td></tr><tr><td class="line-number" value="81"></td><td class="line-content">				background-color: #333;</td></tr><tr><td class="line-number" value="82"></td><td class="line-content">			}</td></tr><tr><td class="line-number" value="83"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="84"></td><td class="line-content">		<span class="html-tag">&lt;/style&gt;</span></td></tr><tr><td class="line-number" value="85"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="86"></td><td class="line-content">	<span class="html-tag">&lt;/head&gt;</span></td></tr><tr><td class="line-number" value="87"></td><td class="line-content">	<span class="html-tag">&lt;body&gt;</span></td></tr><tr><td class="line-number" value="88"></td><td class="line-content">		<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">reveal</span>"&gt;</span></td></tr><tr><td class="line-number" value="89"></td><td class="line-content">			<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">slides</span>"&gt;</span></td></tr><tr><td class="line-number" value="90"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="91"></td><td class="line-content">				<span class="html-tag">&lt;section&gt;</span></td></tr><tr><td class="line-number" value="92"></td><td class="line-content">					<span class="html-tag">&lt;br/&gt;</span></td></tr><tr><td class="line-number" value="93"></td><td class="line-content">					<span class="html-tag">&lt;h1&gt;</span>Probabilistic <span class="html-tag">&lt;br&gt;</span>Machine Learning<span class="html-tag">&lt;/h1&gt;</span></td></tr><tr><td class="line-number" value="94"></td><td class="line-content">					<span class="html-tag">&lt;h4&gt;</span>Week 7, Thursday<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="95"></td><td class="line-content">					<span class="html-comment">&lt;!-- &lt;dl&gt; --&gt;</span></td></tr><tr><td class="line-number" value="96"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:left; font-size:100%; border:1px solid lightgrey; background-color: #fafafa; padding:0.5em; display:inline-block; margin-top:0em</span>"&gt;</span></td></tr><tr><td class="line-number" value="97"></td><td class="line-content">						<span class="html-tag">&lt;h4 <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-bottom: 0.2em</span>"&gt;</span>Uncertainty quantification<span class="html-tag">&lt;/h4&gt;</span></td></tr><tr><td class="line-number" value="98"></td><td class="line-content">						<span class="html-tag">&lt;dl <span class="html-attribute-name">class</span>="<span class="html-attribute-value">list</span>"&gt;</span></td></tr><tr><td class="line-number" value="99"></td><td class="line-content">							<span class="html-tag">&lt;dt&gt;</span>Types of uncertainty<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="100"></td><td class="line-content">							<span class="html-tag">&lt;dt&gt;</span>Modelling uncertainty<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="101"></td><td class="line-content">						<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="102"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="103"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;span style="margin-left:-4em"&gt;Latent variable models:&lt;/span&gt;&lt;br&gt;--&gt;</span></td></tr><tr><td class="line-number" value="104"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;ul&gt;--&gt;</span></td></tr><tr><td class="line-number" value="105"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;li&gt;Discrete: Mixture models&lt;/li&gt;--&gt;</span></td></tr><tr><td class="line-number" value="106"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;li&gt;Continuous: Probabilistic PCA&lt;/li&gt;--&gt;</span></td></tr><tr><td class="line-number" value="107"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;/ul&gt;--&gt;</span></td></tr><tr><td class="line-number" value="108"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="109"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="110"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:center</span>"&gt;</span></td></tr><tr><td class="line-number" value="111"></td><td class="line-content">					<span class="html-tag">&lt;h2&gt;</span>Types of uncertainty<span class="html-tag">&lt;/h2&gt;</span></td></tr><tr><td class="line-number" value="112"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="113"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="114"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:90%</span>"&gt;</span></td></tr><tr><td class="line-number" value="115"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Why bother with uncertainties?<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="116"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="117"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>In the last decade, ML has made lots of progress, but focus has been on <span class="html-tag">&lt;em&gt;</span>performance<span class="html-tag">&lt;/em&gt;</span>: developing ML methods that outperform other methods in terms of accuracy.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="118"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="119"></td><td class="line-content">					Problems:</td></tr><tr><td class="line-number" value="120"></td><td class="line-content">					<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="121"></td><td class="line-content">						<span class="html-tag">&lt;dt &gt;</span>Many methods do not report the uncertainty associated with a prediction.<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="122"></td><td class="line-content">						<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>When uncertainties <span class="html-tag">&lt;em&gt;</span>are<span class="html-tag">&lt;/em&gt;</span> reported, methods frequently make wrong predictions with high certainty.<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="123"></td><td class="line-content">					<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="124"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Problem: current methods often make wrong predictions with high certainty&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="125"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="126"></td><td class="line-content"><span class="html-comment">&lt;!--						Predicting wrong answers with high probability--&gt;</span></td></tr><tr><td class="line-number" value="127"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="128"></td><td class="line-content"><span class="html-comment">&lt;!--					Classification: Predicted probability score and uncertainty in that prediction--&gt;</span></td></tr><tr><td class="line-number" value="129"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="130"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>ML methods should know what they don't know. E.g. if a self-driving car finds itself in a situation that is very different from the data it was trained on, it might make sense for it to slow down - or to signal to the human driver to take over.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="131"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="132"></td><td class="line-content"><span class="html-comment">&lt;!--					If a ML method predicts t--&gt;</span></td></tr><tr><td class="line-number" value="133"></td><td class="line-content"><span class="html-comment">&lt;!--					--&gt;</span></td></tr><tr><td class="line-number" value="134"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="135"></td><td class="line-content"><span class="html-comment">&lt;!--					Difference in Given your genetic background, we know that you have a 80% probability of developing breast cancer--&gt;</span></td></tr><tr><td class="line-number" value="136"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="137"></td><td class="line-content"><span class="html-comment">&lt;!--					If your GPS tells you that turning left or right is equally good, it is nice to know wheher it says this because--&gt;</span></td></tr><tr><td class="line-number" value="138"></td><td class="line-content"><span class="html-comment">&lt;!--					it has calculated both routes and found them to be equally long, or if it does so because it has lost its GPS--&gt;</span></td></tr><tr><td class="line-number" value="139"></td><td class="line-content"><span class="html-comment">&lt;!--					signal, and is therefore just giving your an arbitrary prediction (in which case you might want to fix your GPS before continuing)--&gt;</span></td></tr><tr><td class="line-number" value="140"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="141"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="142"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="143"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="144"></td><td class="line-content">				<span class="html-tag">&lt;section&gt;</span></td></tr><tr><td class="line-number" value="145"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Aleatoric vs epistemic uncertainty<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="146"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="147"></td><td class="line-content">					Two types of uncertainty:<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="148"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="149"></td><td class="line-content">					<span class="html-tag">&lt;dl <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:0.5em</span>"&gt;</span></td></tr><tr><td class="line-number" value="150"></td><td class="line-content">						<span class="html-tag">&lt;dt <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-style: italic; font-weight:normal</span>"&gt;</span>Epistemic uncertainty (aka <span class="html-tag">&lt;em&gt;</span>model uncertainty<span class="html-tag">&lt;/em&gt;</span>)<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="151"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span></td></tr><tr><td class="line-number" value="152"></td><td class="line-content">							<span class="html-tag">&lt;ul <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="153"></td><td class="line-content">								<span class="html-tag">&lt;li&gt;</span>Uncertainty arising as a consequence of imperfect modeling<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="154"></td><td class="line-content">								<span class="html-tag">&lt;li&gt;</span>The goal is to reduce this as much as possible<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="155"></td><td class="line-content">								<span class="html-tag">&lt;li&gt;</span>Specifically addressed in e.g. Bayesian modelling<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="156"></td><td class="line-content">							<span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="157"></td><td class="line-content">							<span class="html-comment">&lt;!--          Uncertainty arising as a consequence of imperfect modeling. The goal is to reduce this as much as possible.&lt;br&gt;--&gt;</span></td></tr><tr><td class="line-number" value="158"></td><td class="line-content">							<span class="html-comment">&lt;!--          Specifically addressed in e.g. Bayesian modelling--&gt;</span></td></tr><tr><td class="line-number" value="159"></td><td class="line-content">						<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="160"></td><td class="line-content">						<span class="html-tag">&lt;dt <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-style: italic; font-weight:normal</span>"&gt;</span>Aleatoric uncertainty (aka <span class="html-tag">&lt;em&gt;</span>data uncertainty<span class="html-tag">&lt;/em&gt;</span>)<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="161"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span></td></tr><tr><td class="line-number" value="162"></td><td class="line-content">							<span class="html-tag">&lt;ul <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="163"></td><td class="line-content">								<span class="html-tag">&lt;li&gt;</span>Inherent uncertainty in the data.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="164"></td><td class="line-content">								<span class="html-tag">&lt;li&gt;</span>This source of uncertainty is irreducible.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="165"></td><td class="line-content">							<span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="166"></td><td class="line-content">							<span class="html-comment">&lt;!--          Inherent uncertainty in the data. This source of uncertainty is irreducible.--&gt;</span></td></tr><tr><td class="line-number" value="167"></td><td class="line-content">						<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="168"></td><td class="line-content">					<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="169"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="170"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="171"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="172"></td><td class="line-content">				<span class="html-tag">&lt;section&gt;</span></td></tr><tr><td class="line-number" value="173"></td><td class="line-content">					<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig6.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig6.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="174"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="175"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%; font-size:60%; text-align:center</span>"&gt;</span></td></tr><tr><td class="line-number" value="176"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span>aleatoric uncertainty<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="177"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span>epistemic uncertainty<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="178"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="179"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:40%; float:right; margin-top:3em</span>"&gt;</span>Figure from Hüllermeier, Waegeman, Machine Learning, 2021, doi: 10.1007/s10994-021-05946-3<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="180"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="181"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="182"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="183"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="184"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"  <span class="html-attribute-name">data-auto-animate</span>&gt;</span></td></tr><tr><td class="line-number" value="185"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Uncertainty in supervised learning: notation<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="186"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="187"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="188"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;Given a hypothesis space \(\mathcal{H}\), the goal in supervised ML is to find the hypothesis \(h^* \in \mathcal{H}\) that minimises the expected loss:&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="189"></td><td class="line-content">					Given:<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="190"></td><td class="line-content">					<span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="191"></td><td class="line-content">						<span class="html-tag">&lt;li&gt;</span>Input space \(\mathcal{X}\) and output space \(\mathcal{Y}\)<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="192"></td><td class="line-content">						<span class="html-tag">&lt;li&gt;</span>hypothesis space \(\mathcal{H}\), containing hypotheses \(h: \mathcal{X} \rightarrow \mathcal{Y}\)<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="193"></td><td class="line-content">						<span class="html-tag">&lt;li&gt;</span>Data generating distribution \(p(\boldsymbol x, \boldsymbol y)\)<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="194"></td><td class="line-content">					<span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="195"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="196"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="197"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow:2; margin-right:1em</span>"<span class="html-attribute-name">"</span>&gt;</span></td></tr><tr><td class="line-number" value="198"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>The goal in supervised ML is to minimize the expected loss (the risk), \[ R(h) \coloneqq \mathbb{E}_{p(\boldsymbol x, \boldsymbol y)}\left [\mathcal{l}(h(\boldsymbol x), \boldsymbol y) \right ]\]<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="199"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="200"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>" &gt;</span></td></tr><tr><td class="line-number" value="201"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>In practice, we don't know \(p(\boldsymbol x, \boldsymbol y)\), so we instead minimize the <span class="html-tag">&lt;em&gt;</span>empirical<span class="html-tag">&lt;/em&gt;</span> risk \[R_{emp}(h) \coloneqq \frac{1}{N}\sum_{i=1}^{N}\mathcal{l}(h(\boldsymbol x_i), \boldsymbol y_i)\]<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="202"></td><td class="line-content">								<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="203"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="204"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="205"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:80%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig4.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig4.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="206"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="207"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:40%; float:right; margin-top:1em</span>"&gt;</span>Figure from Hüllermeier, Waegeman, Machine Learning, 2021, doi: 10.1007/s10994-021-05946-3<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="208"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="209"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="210"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="211"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="212"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" &gt;</span></td></tr><tr><td class="line-number" value="213"></td><td class="line-content">						We have limited data, so the optimal hypothesis, \(\hat h\), found by our learning algorithm will differ from the hypothesis \(h^*\) that minimizes the true risk.</td></tr><tr><td class="line-number" value="214"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="215"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="216"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="217"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"  <span class="html-attribute-name">data-auto-animate</span>&gt;</span></td></tr><tr><td class="line-number" value="218"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="219"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Uncertainty in supervised learning: notation<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="220"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="221"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="222"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow:2; margin-right:1em</span>"&gt;</span></td></tr><tr><td class="line-number" value="223"></td><td class="line-content">							<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="224"></td><td class="line-content">								<span class="html-tag">&lt;dt&gt;</span>Model uncertainty<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="225"></td><td class="line-content">								<span class="html-tag">&lt;dd&gt;</span>Uncertainty about the model class (e.g. linear regression vs random forest)<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="226"></td><td class="line-content">								<span class="html-tag">&lt;dt&gt;</span>Approximation uncertainty<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="227"></td><td class="line-content">								<span class="html-tag">&lt;dd&gt;</span>Related to the quality of the \(\hat h\) estimator. <span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="228"></td><td class="line-content">							<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="229"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="230"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Often, these two concepts are collectively referred to under the name <span class="html-tag">&lt;emph&gt;</span>model uncertainty<span class="html-tag">&lt;/emph&gt;</span> (or epistemic uncertainty).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="231"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="232"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="233"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="234"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:80%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig4.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig4.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="235"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="236"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:40%; float:right; margin-top:0em</span>"&gt;</span>Figure from Hüllermeier, Waegeman, Machine Learning, 2021, doi: 10.1007/s10994-021-05946-3<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="237"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="238"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="239"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="240"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="241"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="242"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow:1; margin-right:1em</span>"&gt;</span></td></tr><tr><td class="line-number" value="243"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">style</span>=""&gt;</span>In practice, we will often assume that the optimal model is in our hypothesis class (i.e., that the model uncertainty is zero)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="244"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="245"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow:1;</span>" &gt;</span></td></tr><tr><td class="line-number" value="246"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>For high capacity model classes, like deep neural networks, which are universal approximators, this assumption might be ok. <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="247"></td><td class="line-content"><span class="html-comment">&lt;!--								They model uncertainty (but potentially larger approximation uncertainty).&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="248"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="249"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="250"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="251"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="252"></td><td class="line-content">				<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="253"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Reducibility of uncertainty<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="254"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="255"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="256"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 1</span>"&gt;</span></td></tr><tr><td class="line-number" value="257"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Epistemic uncertainty is typically referred to as <span class="html-tag">&lt;emph&gt;</span>reducible<span class="html-tag">&lt;/emph&gt;</span> uncertainty. What do we mean by this?<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="258"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="259"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>We mean: If we fix \(\mathcal{X}\), \(\mathcal{Y}\), \(\mathcal{H}\) and \(p(\boldsymbol x, \boldsymbol y)\), then the epistemic uncertainty can be reduced by adding more data.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="260"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="261"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Q: What if we discover some new features and add them to \(\mathcal{X}\), leading to a new input space \(\mathcal{X}'\)?<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="262"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="263"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="264"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-left:1em; </span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="265"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="266"></td><td class="line-content">							<span class="html-tag">&lt;p <span class="html-attribute-name">style</span>=""&gt;</span>A: By increasing dimension, we can reduce actually reduce "aleatoric" uncertainty<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="267"></td><td class="line-content"><span class="html-comment">&lt;!--								- even with fewer data points.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="268"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="269"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">r-stack</span>"&gt;</span></td></tr><tr><td class="line-number" value="270"></td><td class="line-content">								<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:55%; margin-top:-0.5em; </span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig5a.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig5a.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="271"></td><td class="line-content">								<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center fragment</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:55%; margin-top:-0.5em; </span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig5.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig5.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="272"></td><td class="line-content">							<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="273"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="274"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="275"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:35%; float:right; margin-top:1em</span>"&gt;</span>Figure from Hüllermeier, Waegeman, Machine Learning, 2021, doi: 10.1007/s10994-021-05946-3<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="276"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="277"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="278"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="279"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="280"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="281"></td><td class="line-content">					<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>This demonstrates that the distinction between aleatoric/epistemic uncertainty makes sense only in the context of a fixed choice of \((\mathcal{X}, \mathcal{Y}, \mathcal{H}, p(\boldsymbol x, \boldsymbol y))\).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="282"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="283"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="284"></td><td class="line-content">					<span class="html-comment">&lt;!--					Adding more data--&gt;</span></td></tr><tr><td class="line-number" value="285"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="286"></td><td class="line-content"><span class="html-comment">&lt;!--					Model uncertainty and approximation uncertainty--&gt;</span></td></tr><tr><td class="line-number" value="287"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="288"></td><td class="line-content"><span class="html-comment">&lt;!--					In Deep Learning - model uncertainty is less of a problem (although approximation uncertainty is probably more of a problem)--&gt;</span></td></tr><tr><td class="line-number" value="289"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="290"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="291"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>" <span class="html-attribute-name">data-auto-animate</span>&gt;</span></td></tr><tr><td class="line-number" value="292"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Representing epistemic uncertainty: sets<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="293"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="294"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>To get an intuition about what epistemic uncertainty means, let's start by considering <span class="html-tag">&lt;em&gt;</span>sets<span class="html-tag">&lt;/em&gt;</span> of hypotheses<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="295"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="296"></td><td class="line-content">				Simplifying assumptions:<span class="html-tag">&lt;br&gt;</span></td></tr><tr><td class="line-number" value="297"></td><td class="line-content">				<span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="298"></td><td class="line-content">					<span class="html-tag">&lt;li&gt;</span>Assume that \(f^*: \mathcal{X} \rightarrow \mathcal{Y}\) is deterministic, and that the data is noise free<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="299"></td><td class="line-content">					<span class="html-tag">&lt;li&gt;</span>Assume a classification scenario.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="300"></td><td class="line-content">					<span class="html-tag">&lt;li&gt;</span>Assume that the optimal model is in our hypothesis class, \(f^* \in \mathcal{H}\)<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="301"></td><td class="line-content">				<span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="302"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="303"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>Idea (version space learning): We start with a set of hypotheses. As we observe data, we discard hypotheses that make incorrect predictions.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="304"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="305"></td><td class="line-content">				<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="306"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="307"></td><td class="line-content">						<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span>As we see more data, the size of this set will decrease.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="308"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="309"></td><td class="line-content">						<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>"&gt;</span>Our <span class="html-tag">&lt;em&gt;</span>predictive<span class="html-tag">&lt;/em&gt;</span> uncertainty for an input \(x\) is given by the size of the set of possible outcomes \(y\) produced by the hypotheses in the version space.<span class="html-tag">&lt;p&gt;</span></td></tr><tr><td class="line-number" value="310"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="311"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="312"></td><td class="line-content">						<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>"  <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:90%; margin-top:1em</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig7.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig7.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="313"></td><td class="line-content">						<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:35%; float:right; margin-top:1em</span>"&gt;</span>Figure from Hüllermeier, Waegeman, Machine Learning, 2021, doi: 10.1007/s10994-021-05946-3<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="314"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="315"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="316"></td><td class="line-content">				<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="317"></td><td class="line-content">				</td></tr><tr><td class="line-number" value="318"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="319"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="320"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="321"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="322"></td><td class="line-content"><span class="html-comment">&lt;!--					to the different outputs produ&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="323"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="324"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;p&gt;Observations&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="325"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;p&gt;Our uncertainty about the model is determined by the size of the remaining set of hypotheses&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="326"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;p&gt;Our uncertainty about the correct hypothesis translates into an uncertainty about the possible outcomes for a given input x&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="327"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="328"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;p&gt;If our hypothesis space is simply an enumeration of all possible class assignments, we cannot learn anything&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="329"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="330"></td><td class="line-content"><span class="html-comment">&lt;!--				&lt;p&gt;Our uncertainty about the hypothesis will depend on the initial size of the hypothesis space.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="331"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="332"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="333"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>" <span class="html-attribute-name">data-auto-animate</span>&gt;</span></td></tr><tr><td class="line-number" value="334"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Representing epistemic uncertainty: sets (2)<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="335"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="336"></td><td class="line-content">				<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="337"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="338"></td><td class="line-content">						Observations:</td></tr><tr><td class="line-number" value="339"></td><td class="line-content">						<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="340"></td><td class="line-content">							<span class="html-tag">&lt;dt&gt;</span>Our uncertainty about the model is determined by the size of the remaining set of hypotheses<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="341"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;dd&gt;As expected, epistemic uncertainty is reduced as we see more data.&lt;/dd&gt;--&gt;</span></td></tr><tr><td class="line-number" value="342"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="343"></td><td class="line-content">						<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="344"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;ul&gt;--&gt;</span></td></tr><tr><td class="line-number" value="345"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;li&gt;Our uncertainty about the model is determined by the size of the remaining set of hypotheses&lt;/li&gt;--&gt;</span></td></tr><tr><td class="line-number" value="346"></td><td class="line-content"><span class="html-comment">&lt;!--							&lt;li&gt;Our uncertainty about the hypothesis will depend on the initial size of the hypothesis space.&lt;/li&gt;--&gt;</span></td></tr><tr><td class="line-number" value="347"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;/ul&gt;--&gt;</span></td></tr><tr><td class="line-number" value="348"></td><td class="line-content"><span class="html-comment">&lt;!--										&lt;p&gt;Our uncertainty about the model is determined by the size of the remaining set of hypotheses&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="349"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;p class="fragment" data-fragment-index="1"&gt;As we see more data, the size of this set will decrease.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="350"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="351"></td><td class="line-content"><span class="html-comment">&lt;!--						&lt;p class="fragment" data-fragment-index="2"&gt;Our &lt;em&gt;predictive&lt;/em&gt; uncertainty for an input \(x\) is given by the size of the set of possible outcomes \(y\) produced by the hypotheses in the version space.&lt;p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="352"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="353"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="354"></td><td class="line-content">						<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:90%; margin-top:1em</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig7.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig7.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="355"></td><td class="line-content">						<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:35%; float:right; margin-top:1em</span>"&gt;</span>Figure from Hüllermeier, Waegeman, Machine Learning, 2021, doi: 10.1007/s10994-021-05946-3<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="356"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="357"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="358"></td><td class="line-content">				<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="359"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="360"></td><td class="line-content">				<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="361"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 2</span>"&gt;</span></td></tr><tr><td class="line-number" value="362"></td><td class="line-content">						<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="363"></td><td class="line-content">							<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>This uncertainty will also depend on the initial size of the hypothesis space (i.e. our inductive bias).<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="364"></td><td class="line-content">							<span class="html-tag">&lt;dd&gt;</span></td></tr><tr><td class="line-number" value="365"></td><td class="line-content">								<span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="366"></td><td class="line-content">									<span class="html-comment">&lt;!--									&lt;li&gt;This depends on our &lt;em&gt;inductive bias&lt;/em&gt;&lt;/li&gt;--&gt;</span></td></tr><tr><td class="line-number" value="367"></td><td class="line-content">									<span class="html-tag">&lt;li&gt;</span>If we have a large inductive bias, we can reduce model uncertainty with little data.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="368"></td><td class="line-content">									<span class="html-tag">&lt;li&gt;</span>If we have no inductive bias, we would not be able to <span class="html-tag">&lt;em&gt;</span>learn<span class="html-tag">&lt;/em&gt;</span> - we would need to observe the specific \(x\) in our training set in order to predict it.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="369"></td><td class="line-content">								<span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="370"></td><td class="line-content">							<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="371"></td><td class="line-content">							<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="372"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="373"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="374"></td><td class="line-content">						<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:60%; margin-top:2em</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig8.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig8.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="375"></td><td class="line-content">						<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:35%; width:70%; float:right; margin-top:1em</span>"&gt;</span>Figures from Hüllermeier, Waegeman, Machine Learning, 2021, doi: 10.1007/s10994-021-05946-3<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="376"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="377"></td><td class="line-content">				<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="378"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="379"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="380"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="381"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>" <span class="html-attribute-name">data-auto-animate</span>&gt;</span></td></tr><tr><td class="line-number" value="382"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Representing epistemic uncertainty: distributions<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="383"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="384"></td><td class="line-content">				<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="385"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="386"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="387"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>In the set description, hypotheses were either true or false, and all hypotheses in the version set were equally good.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="388"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="389"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>In Bayesian Machine Learning, we work with probability distributions over hypotheses<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="390"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="391"></td><td class="line-content">						<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span>Through the posterior predictive, the uncertainty about our hypothesis translates into a predictive uncertainty for a given input, through model averaging.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="392"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="393"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="394"></td><td class="line-content">						<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:90%; margin-top:1em</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig7.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig7.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="395"></td><td class="line-content">						<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:90%; margin-top:1em</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig9.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig9.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="396"></td><td class="line-content">						<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:35%; width:70%; float:right; margin-top:1em</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span>Figures from Hüllermeier, Waegeman, Machine Learning, 2021, doi: 10.1007/s10994-021-05946-3<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="397"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="398"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:2em</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span></td></tr><tr><td class="line-number" value="399"></td><td class="line-content">						\[p(\boldsymbol y | \boldsymbol x) = \int_{\mathcal{H}} p(\boldsymbol y|\boldsymbol x,h)p(h) dh \]</td></tr><tr><td class="line-number" value="400"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="401"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="402"></td><td class="line-content">				<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="403"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="404"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="405"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="406"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>" <span class="html-attribute-name">data-auto-animate</span>&gt;</span></td></tr><tr><td class="line-number" value="407"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Representing epistemic uncertainty: distributions<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="408"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="409"></td><td class="line-content">				<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="410"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="411"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="412"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>Note that when we do model averaging, we lose our ability to distinguish between epistemic and aleatoric uncertainty<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="413"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="414"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="415"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="416"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:2em</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span></td></tr><tr><td class="line-number" value="417"></td><td class="line-content">							\[p(\boldsymbol y | \boldsymbol x) = \int_{\mathcal{H}} p(\boldsymbol y|\boldsymbol x,h)p(h) dh \]</td></tr><tr><td class="line-number" value="418"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="419"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="420"></td><td class="line-content">				<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="421"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="422"></td><td class="line-content">				<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="423"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>For instance, consider the task of predicting coin flip outcomes. Both the following scenarios would lead to the same 50/50 prediction:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="424"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="425"></td><td class="line-content">				<span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="426"></td><td class="line-content">					<span class="html-tag">&lt;li&gt;</span>Uniform distribution over two models: one that predicts heads with 100% and one that predicts tails with 100%. (only epistemic uncertainty)<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="427"></td><td class="line-content">					<span class="html-tag">&lt;li&gt;</span>Delta function with 100% on the hypothesis of an unbiased coin (only aleatoric certainty)<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="428"></td><td class="line-content">				<span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="429"></td><td class="line-content">				<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="430"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="431"></td><td class="line-content">				<span class="html-tag">&lt;aside <span class="html-attribute-name">class</span>="<span class="html-attribute-value">notes</span>"&gt;</span></td></tr><tr><td class="line-number" value="432"></td><td class="line-content">					Coin flip example is not exactly "classification", because we have no input x. But if you want, think of multiple coins, where x is the identity of the coin.</td></tr><tr><td class="line-number" value="433"></td><td class="line-content">				<span class="html-tag">&lt;/aside&gt;</span></td></tr><tr><td class="line-number" value="434"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="435"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="436"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="437"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:82%</span>" &gt;</span></td></tr><tr><td class="line-number" value="438"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Frequentist quantifying of epistemic uncertainty<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="439"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="440"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>Often, models are estimated by optimizing a likelihood function \(\mathcal{L}(\theta) = \sum_{n=1}^{N}\ln p(\boldsymbol x_n)\)</td></tr><tr><td class="line-number" value="441"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="442"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>One way to reason about epistemic uncertainty is to look at the quality of the maximum likelihood estimator (MLE)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="443"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="444"></td><td class="line-content">				<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="445"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>Under regularity conditions, it can be shown that for i.i.d. data samples \(\boldsymbol x_1, \boldsymbol x_2, \ldots, \boldsymbol x_N\), for large $N$, the distribution of the MLE will become Normal, \(\mathcal{N}\mathcal(\theta_0, \mathcal{I}_N(\theta_0)^{-1})\)  <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="446"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="447"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>where \(\mathcal{I}_n(\theta_0)\) is the Fisher Information matrix: \(\mathcal{I}_N(\theta) = \left(\mathbb{E}\left[ \frac{-\partial^2 \mathcal{L}}{\partial\theta_i \partial\theta_j}\right]\right )_{i,j}\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="448"></td><td class="line-content">				<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="449"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="450"></td><td class="line-content">				<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Note that we are in a frequentist mode here: the "distribution over the MLE" and the "expectation" are over datasets \(\boldsymbol x_1, \boldsymbol x_2, \ldots, \boldsymbol x_N\) sampled from the data generating distribution.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="451"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="452"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="453"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="454"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>"&gt;</span></td></tr><tr><td class="line-number" value="455"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Frequentist quantifying epistemic uncertainty (2)<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="456"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="457"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>Summary: For large datasets, the distribution of MLE will become normally distributed, \(\hat \theta \sim \mathcal{N}\mathcal(\theta_0, \mathcal{I}_N(\theta_0)^{-1})\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="458"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="459"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>From this, we can define a <span class="html-tag">&lt;em&gt;</span>confidence region<span class="html-tag">&lt;/em&gt;</span>, which tells us the range in which we expect to find the true \(\theta\).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="460"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="461"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>The size of this confidence region reflects the epistemic uncertainty about the hypotheses found by MLE.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="462"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="463"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>This can thus be seen as a frequentist way of discussing probabilities over hypotheses.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="464"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="465"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="466"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="467"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="468"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:center</span>"&gt;</span></td></tr><tr><td class="line-number" value="469"></td><td class="line-content">					<span class="html-tag">&lt;h2&gt;</span>Methods for uncertainty quantification<span class="html-tag">&lt;/h2&gt;</span></td></tr><tr><td class="line-number" value="470"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="471"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="472"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:85%</span>"&gt;</span></td></tr><tr><td class="line-number" value="473"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Predicting probabilities<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="474"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="475"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>How do predictive uncertainties arise in different methods?<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="476"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="477"></td><td class="line-content"><span class="html-comment">&lt;!--				Methods predicting parameters of an output distribution--&gt;</span></td></tr><tr><td class="line-number" value="478"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="479"></td><td class="line-content">				<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="480"></td><td class="line-content">					<span class="html-tag">&lt;dt&gt;</span>Descriminative probabilistic models: \(p(y|x)\)<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="481"></td><td class="line-content">					<span class="html-tag">&lt;dd&gt;</span></td></tr><tr><td class="line-number" value="482"></td><td class="line-content">						<span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="483"></td><td class="line-content">							<span class="html-tag">&lt;li&gt;</span>Many classification methods are probabilistic, in the sense that they predict a probability for each of the classes.<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="484"></td><td class="line-content">							<span class="html-tag">&lt;li&gt;</span>Classic regression methods are often trained by maximum likelihood (often assuming a Gaussian error model). <span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="485"></td><td class="line-content">							<span class="html-tag">&lt;li&gt;</span>Methods covered in class: Bayesian linear regression, Gaussian Processes<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="486"></td><td class="line-content">						<span class="html-tag">&lt;/ul&gt;</span></td></tr><tr><td class="line-number" value="487"></td><td class="line-content">					<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="488"></td><td class="line-content">					<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Generative probabilistic models: \(p(x,y)\)<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="489"></td><td class="line-content">					<span class="html-tag">&lt;dd&gt;</span></td></tr><tr><td class="line-number" value="490"></td><td class="line-content">						<span class="html-tag">&lt;ul&gt;</span></td></tr><tr><td class="line-number" value="491"></td><td class="line-content">							<span class="html-tag">&lt;li&gt;</span>Density estimation: mixture models, VAEs, diffusion models<span class="html-tag">&lt;/li&gt;</span></td></tr><tr><td class="line-number" value="492"></td><td class="line-content">						<span class="html-tag">&lt;/ul&gt;</span><span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="493"></td><td class="line-content">					<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Ensembling, boosting, bagging<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="494"></td><td class="line-content">					<span class="html-tag">&lt;dd&gt;</span>Produce a set of predictors, from which we can estimate uncertainties<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="495"></td><td class="line-content">				<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="496"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="497"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="498"></td><td class="line-content">  			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="499"></td><td class="line-content">					<span class="html-tag">&lt;h3&gt;</span>Probability estimation: calibration<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="500"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="501"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>If models predict a probability/score alongside its prediction, can we use this to quantify the uncertainty of the prediction? <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Only if they are <span class="html-tag">&lt;emph&gt;</span>well-calibrated<span class="html-tag">&lt;/emph&gt;</span>.<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="502"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="503"></td><td class="line-content">					<span class="html-tag">&lt;dl <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="504"></td><td class="line-content">						<span class="html-tag">&lt;dt&gt;</span>Well-calibrated probabilities (binary classification)<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="505"></td><td class="line-content">						<span class="html-tag">&lt;dd&gt;</span>Among all inputs predicted to belong to the positive class with probability \([p-\epsilon, p+\epsilon]\), we expect that the frequency of correct predictions for these inputs in the test set is \(p\).<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="506"></td><td class="line-content">					<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="507"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="508"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="509"></td><td class="line-content">						<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="510"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>This can be depicted in a calibration plot:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="511"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="512"></td><td class="line-content">							<span class="html-tag">&lt;p&gt;</span>Models with poor calibration can be adjusted post-hoc <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://scikit-learn.org/stable/modules/calibration.html" rel="noreferrer noopener">https://scikit-learn.org/stable/modules/calibration.html</a>"&gt;</span>scikit-learn.org/stable/</td></tr><tr><td class="line-number" value="513"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="514"></td><td class="line-content">								modules/calibration.html<span class="html-tag">&lt;/a&gt;</span><span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="515"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="516"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow:2</span>"&gt;</span></td></tr><tr><td class="line-number" value="517"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:80%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/calibration_plot.svg" rel="noreferrer noopener">calibration_plot.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="518"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="519"></td><td class="line-content">							<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:40%; float:right; margin-top:1em</span>"&gt;</span>Plot by Jan Hendrik Metzen, <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://scikit-learn.org/stable/modules/calibration.html" rel="noreferrer noopener">https://scikit-learn.org/stable/modules/calibration.html</a>"&gt;</span>Scikit learn documentation<span class="html-tag">&lt;/a&gt;</span><span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="520"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="521"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="522"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="523"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="524"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="525"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="526"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="527"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="528"></td><td class="line-content">					<span class="html-comment">&lt;!--					Well-calibrated probabilities:--&gt;</span></td></tr><tr><td class="line-number" value="529"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="530"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="531"></td><td class="line-content"><span class="html-comment">&lt;!--					&lt;p&gt;If these probabilities are well-calibrated&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="532"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="533"></td><td class="line-content"><span class="html-comment">&lt;!--					Many methods output probabilities - or scores that can be translated into probabilities.--&gt;</span></td></tr><tr><td class="line-number" value="534"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="535"></td><td class="line-content"><span class="html-comment">&lt;!--					Calibration: convert scores into calibrated probabilities--&gt;</span></td></tr><tr><td class="line-number" value="536"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="537"></td><td class="line-content"><span class="html-comment">&lt;!--					Often, classification is done in two steps: 1) predict class scores, 2) decide on a class--&gt;</span></td></tr><tr><td class="line-number" value="538"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="539"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="540"></td><td class="line-content"><span class="html-comment">&lt;!--					What is calibration:--&gt;</span></td></tr><tr><td class="line-number" value="541"></td><td class="line-content"><span class="html-comment">&lt;!--					Consider all inputs x for which the maximum class $k$ was predicted with probability--&gt;</span></td></tr><tr><td class="line-number" value="542"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="543"></td><td class="line-content"><span class="html-comment">&lt;!--					If an input is predicted to belong to class k, with probability p(k), then we expect this probability to reflect how often this input is correctly--&gt;</span></td></tr><tr><td class="line-number" value="544"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="545"></td><td class="line-content"><span class="html-comment">&lt;!--					the probability of this being the correct assignment to be p(--&gt;</span></td></tr><tr><td class="line-number" value="546"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="547"></td><td class="line-content"><span class="html-comment">&lt;!--					Binary classification - prediction of probability \(p\):--&gt;</span></td></tr><tr><td class="line-number" value="548"></td><td class="line-content"><span class="html-comment">&lt;!--					Among all inputs predicted to belong to the positive class with probability [p-\epsilon, p+epsilon], we expect that we frequency of correct predictions in the test set is \(p\).--&gt;</span></td></tr><tr><td class="line-number" value="549"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="550"></td><td class="line-content"><span class="html-comment">&lt;!--					If an input is predicted to have probability p, then we expect--&gt;</span></td></tr><tr><td class="line-number" value="551"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="552"></td><td class="line-content">				<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="553"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="554"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%</span>"&gt;</span></td></tr><tr><td class="line-number" value="555"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Which types of uncertainty?<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="556"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="557"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>Q: In the classification example above, are we modelling aleatoric or epistemic uncertainty? <span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"  <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">0</span>"&gt;</span>A: It's complicated :)<span class="html-tag">&lt;/span&gt;</span><span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="558"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="559"></td><td class="line-content">				<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container fragment</span>"  <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span></td></tr><tr><td class="line-number" value="560"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="561"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 3;</span>"&gt;</span></td></tr><tr><td class="line-number" value="562"></td><td class="line-content">						<span class="html-tag">&lt;dl <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>"&gt;</span></td></tr><tr><td class="line-number" value="563"></td><td class="line-content">							<span class="html-tag">&lt;dt&gt;</span><span class="html-tag">&lt;em&gt;</span>Aleatoric<span class="html-tag">&lt;/em&gt;</span>: regions of overlap between classes.<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="564"></td><td class="line-content">							<span class="html-tag">&lt;dd&gt;</span>We would definitely expect the softmax to capture this.<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="565"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="566"></td><td class="line-content">						<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="567"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="568"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="569"></td><td class="line-content">						<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">center noborder</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:80%; margin-top:-1em</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig6a.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig6a.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="570"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="571"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="572"></td><td class="line-content">				<span class="html-tag">&lt;/div&gt;</span>		</td></tr><tr><td class="line-number" value="573"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="574"></td><td class="line-content">				<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">2</span>"&gt;</span></td></tr><tr><td class="line-number" value="575"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="576"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 2;</span>"&gt;</span></td></tr><tr><td class="line-number" value="577"></td><td class="line-content">						<span class="html-tag">&lt;dl <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>"&gt;</span></td></tr><tr><td class="line-number" value="578"></td><td class="line-content">							<span class="html-tag">&lt;dt&gt;</span><span class="html-tag">&lt;em&gt;</span>Epistemic<span class="html-tag">&lt;/em&gt;</span>: response to out-of-domain data<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="579"></td><td class="line-content">							<span class="html-tag">&lt;dd&gt;</span>Example: If a model trained on MNIST is presented with an image of a car, the softmax should produce ~50% probabilities.</td></tr><tr><td class="line-number" value="580"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="581"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="582"></td><td class="line-content">								<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>"&gt;</span>We can easily imagine cases where this would not work<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="583"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="584"></td><td class="line-content">								<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">4</span>"&gt;</span>But in practice, softmax output in deep neural networks do capture some epistemic effects as well.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="585"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="586"></td><td class="line-content">							<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="587"></td><td class="line-content">						<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="588"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="589"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="590"></td><td class="line-content">						<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">center noborder fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%; margin-left:1em; margin-top:0em</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/pearce_et_al_fig1a.png" rel="noreferrer noopener">pearce_et_al_fig1a.png</a>"&gt;</span></td></tr><tr><td class="line-number" value="591"></td><td class="line-content">						<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">center noborder fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">4</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%; margin-left:1em; margin-top:1em</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/pearce_et_al_fig1b.png" rel="noreferrer noopener">pearce_et_al_fig1b.png</a>"&gt;</span></td></tr><tr><td class="line-number" value="592"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">3</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:right; margin-top:1.5em; float:right; width:90%; font-size:50%</span>"&gt;</span>Pearce, Brintrup, Zhu, Understanding Softmax Confidence and Uncertainty, 2021, <span class="html-tag">&lt;a <span class="html-attribute-name">href</span>="<a class="html-attribute-value html-external-link" target="_blank" href="https://arxiv.org/abs/2106.04972" rel="noreferrer noopener">https://arxiv.org/abs/2106.04972</a>"&gt;</span>https://arxiv.org/abs/2106.04972<span class="html-tag">&lt;/a&gt;</span><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="593"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="594"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="595"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="596"></td><td class="line-content">				<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="597"></td><td class="line-content">				<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">5</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:0em</span>"&gt;</span>In conclusion, it is difficult to separate the two effects from a softmax output.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="598"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="599"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="600"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="601"></td><td class="line-content">				<span class="html-comment">&lt;!-- &lt;p&gt;&lt;em&gt;Aleatoric&lt;/em&gt; uncertainty would be regions of overlap between classes. So we would definitely expect the model to capture &lt;em&gt;aleatoric&lt;/em&gt; uncertainty.&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="602"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="603"></td><td class="line-content"><span class="html-comment">				&lt;p&gt;&lt;em&gt;Epistemic&lt;/em&gt; uncertainty would mean that we expect the probabilities from the softmax to be close to 50% if we evaluate our model on out-of-domain data. E.g. presenting an MNIST classification model with an image of a car.&lt;/p&gt; --&gt;</span></td></tr><tr><td class="line-number" value="604"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="605"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="606"></td><td class="line-content">				<span class="html-comment">&lt;!-- &lt;p&gt;We know that the softmax captures &lt;em&gt;aleatoric&lt;/em&gt; uncertainty.&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="607"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="608"></td><td class="line-content"><span class="html-comment">				&lt;span class="fragment"&gt;</span></td></tr><tr><td class="line-number" value="609"></td><td class="line-content"><span class="html-comment">				&lt;p&gt;A: If we optimize model parameters to find a single hypothesis \(\hat h\), we are effectively ignoring the epistemic uncertainty.&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="610"></td><td class="line-content"><span class="html-comment"><br></span></td></tr><tr><td class="line-number" value="611"></td><td class="line-content"><span class="html-comment">				&lt;p&gt;Such models thus primarily capture aleatoric uncertainty.&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="612"></td><td class="line-content"><span class="html-comment">				&lt;/span&gt; --&gt;</span></td></tr><tr><td class="line-number" value="613"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="614"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="615"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="616"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Aleatoric and epistemic uncertainty in Gaussian processes<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="617"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="618"></td><td class="line-content">				<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="619"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 2</span>"&gt;</span></td></tr><tr><td class="line-number" value="620"></td><td class="line-content">						Recall that in Gaussian Processes, we have two notions of variance</td></tr><tr><td class="line-number" value="621"></td><td class="line-content">						<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="622"></td><td class="line-content">							<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Posterior predictive (total uncertainty)<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="623"></td><td class="line-content">							<span class="html-tag">&lt;dd&gt;</span>The posterior predictive is Normally distributed. For any input \(x\), a GP will predict a mean value \(\mu\) and a variance \(\sigma^2\) around the mean.<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="624"></td><td class="line-content">							<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Observation noise (aleatoric)<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="625"></td><td class="line-content">							<span class="html-tag">&lt;dd&gt;</span>The aleatoric uncertainty is explicitly encoded in terms of the noise \(\epsilon_i\) of an observation \(y_i = f(x_i) + \epsilon_i\)<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="626"></td><td class="line-content">						<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="627"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="628"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span><span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig13.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig13.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="629"></td><td class="line-content">				<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="630"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="631"></td><td class="line-content">				<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>The epistemic uncertainty can thus be retrieved by subtracting the aleatoric uncertainty from the total uncertainty.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="632"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="633"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="634"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="635"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="636"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Quantifying epistemic uncertainty in neural networks<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="637"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="638"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>In neural networks, epistemic uncertainty is our uncertainty of the weights in the network.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="639"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="640"></td><td class="line-content">				As described above, we can follow different strategies:</td></tr><tr><td class="line-number" value="641"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="642"></td><td class="line-content">				<span class="html-tag">&lt;dl&gt;</span></td></tr><tr><td class="line-number" value="643"></td><td class="line-content">					<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Bayesian Neural Networks<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="644"></td><td class="line-content">					<span class="html-tag">&lt;dd&gt;</span>Place priors over the weights and then compute the posterior over the weights. This can be done either by sampling (MCMC) or variational inference.<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="645"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="646"></td><td class="line-content">					<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Approximations to the posterior<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="647"></td><td class="line-content">					<span class="html-tag">&lt;dd&gt;</span>E.g. Laplace. <span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="648"></td><td class="line-content">						<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="649"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="650"></td><td class="line-content">					<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Monte Carlo Dropout<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="651"></td><td class="line-content">					<span class="html-tag">&lt;dd&gt;</span>Create ensemble by sampling models using dropout.<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="652"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="653"></td><td class="line-content">					<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="654"></td><td class="line-content">					<span class="html-tag">&lt;dt <span class="html-attribute-name">class</span>="<span class="html-attribute-value">spaced</span>"&gt;</span>Variability of the MLE<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="655"></td><td class="line-content">					<span class="html-tag">&lt;dd&gt;</span>For instance through the Fisher information matrix. Jackknife.<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="656"></td><td class="line-content">					<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="657"></td><td class="line-content">				<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="658"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="659"></td><td class="line-content">				<span class="html-comment">&lt;!--				&lt;p&gt;As we saw before, we typically lose the ability to separate epistemic and aleatoric uncertainty when considering uncertainty of the predictions.&lt;/p&gt;--&gt;</span></td></tr><tr><td class="line-number" value="660"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="661"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="662"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="663"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="664"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%; height:100%</span>" <span class="html-attribute-name">data-auto-animate</span>&gt;</span></td></tr><tr><td class="line-number" value="665"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Separating aleatoric and epistemic uncertainty<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="666"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="667"></td><td class="line-content">				<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="668"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="669"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="670"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>We previously discussed that when doing Bayesian model averaging, we lose our ability to distinguish between aleatoric and epistemic uncertainty of an individual prediction<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="671"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="672"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="673"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="674"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:2em</span>" <span class="html-attribute-name">data-fragment-index</span>="<span class="html-attribute-value">1</span>"&gt;</span></td></tr><tr><td class="line-number" value="675"></td><td class="line-content">							\[p(\boldsymbol y | \boldsymbol x) = \int_{\mathcal{H}} p(\boldsymbol y|\boldsymbol x,h)p(h) dh \]</td></tr><tr><td class="line-number" value="676"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="677"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="678"></td><td class="line-content">				<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="679"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="680"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="681"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>Can we fix this?<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="682"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="683"></td><td class="line-content">				<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="684"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>As an example, consider a Bayesian neural network classifier, evaluated at input \(\boldsymbol x^*\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="685"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="686"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>For any fixed choice of weights \(\boldsymbol w\) in the network, the model produces a discrete output distribution \(p(\boldsymbol y^*|\boldsymbol x^*, \boldsymbol w)\) over the possible labels \(\mathcal{Y}\).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="687"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="688"></td><td class="line-content">				<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="689"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="690"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="691"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="692"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%; height:100%</span>"  <span class="html-attribute-name">data-auto-animate</span>&gt;</span></td></tr><tr><td class="line-number" value="693"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Separating aleatoric and epistemic uncertainty<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="694"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="695"></td><td class="line-content">				<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>=""&gt;</span></td></tr><tr><td class="line-number" value="696"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>As an example, consider a Bayesian neural network classifier, evaluated at input \(\boldsymbol x^*\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="697"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="698"></td><td class="line-content">					<span class="html-tag">&lt;p&gt;</span>For any fixed choice of weights \(\boldsymbol w\) in the network, the model produces a discrete output distribution \(p(\boldsymbol y^*|\boldsymbol x^*, \boldsymbol w)\) over the possible labels \(\mathcal{Y}\).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="699"></td><td class="line-content">				<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="700"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="701"></td><td class="line-content">				<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="702"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>We can use the entropy to reflect the uncertainty of this distribution: \(H[p(y^*|\boldsymbol x^*, \boldsymbol w)] = -\sum_{k=1}^{K}p(y^*_k|\boldsymbol x^*, \boldsymbol w)\ln(p(y^*_k|\boldsymbol x^*, \boldsymbol w))\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="703"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="704"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>This is (predominantly) an aleatoric uncertainty.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="705"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="706"></td><td class="line-content">				<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>The expectation of this entropy over \(p(\boldsymbol w)\) is definitely an estimate of the aleatoric uncertainty: \(\mathbb{E}_{p(\boldsymbol w)} \left[H[p(y^*_k|\boldsymbol x^*, \boldsymbol w)]\right]\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="707"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="708"></td><td class="line-content">				<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>We can get the <span class="html-tag">&lt;em&gt;</span>total<span class="html-tag">&lt;/em&gt;</span> uncertainty by considering the entropy of the posterior predictive, \[H[p(\boldsymbol y^*|\boldsymbol x^*)] = H \left[ \int p(\boldsymbol y^*|\boldsymbol x^*,\boldsymbol w)p(\boldsymbol w)d\boldsymbol w\right]\]<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="709"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="710"></td><td class="line-content">				<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="711"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="712"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="713"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%; height:100%</span>"  <span class="html-attribute-name">data-auto-animate</span>&gt;</span></td></tr><tr><td class="line-number" value="714"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Separating aleatoric and epistemic uncertainty<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="715"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="716"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>The expectation of this entropy over \(p(\boldsymbol w)\) is definitely an estimate of the aleatoric uncertainty: \(\mathbb{E}_{p(\boldsymbol w)} \left[H[p(y^*_k|\boldsymbol x^*, \boldsymbol w)]\right]\)<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="717"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="718"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>We can get the <span class="html-tag">&lt;em&gt;</span>total<span class="html-tag">&lt;/em&gt;</span> uncertainty by considering the entropy of the posterior predictive, \[H[p(\boldsymbol y^*|\boldsymbol x^*)] = H \left[ \int p(\boldsymbol y^*|\boldsymbol x^*,\boldsymbol w)p(\boldsymbol w)d\boldsymbol w\right]\]<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="719"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="720"></td><td class="line-content">				<span class="html-tag">&lt;span <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="721"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="722"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>The epistemic uncertainty can then be recovered as the difference between these two contributions:<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="723"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="724"></td><td class="line-content">				\[u_e(\boldsymbol x^*) \coloneqq H[p(\boldsymbol y^*|\boldsymbol x^*)] - \mathbb{E}_{p(\boldsymbol w)} \left[H[p(y^*|\boldsymbol x^*, \boldsymbol w)]\right]\]</td></tr><tr><td class="line-number" value="725"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="726"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>which turns out to be the mutual information between \(\boldsymbol y^*\) and \(\boldsymbol w\).<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="727"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="728"></td><td class="line-content">				For more information, see the original paper:</td></tr><tr><td class="line-number" value="729"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:70%;margin-top:0.5em</span>"&gt;</span>Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning, Depeweg, Hernandez-Lobato, Doshi-Velez, Udluft, ICML, 2018.<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="730"></td><td class="line-content">				<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="731"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="732"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="733"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="734"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="735"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:80%</span>"&gt;</span></td></tr><tr><td class="line-number" value="736"></td><td class="line-content">				<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:95%</span>"&gt;</span><span class="html-tag">&lt;h3&gt;</span>Quantifying epistemic uncertainty: generative models<span class="html-tag">&lt;/h3&gt;</span><span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="737"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="738"></td><td class="line-content">				<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="739"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">flex-grow: 2</span>"&gt;</span></td></tr><tr><td class="line-number" value="740"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>Intuition: our epistemic uncertainty is high in regions far away from our training data.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="741"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="742"></td><td class="line-content">						<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Idea: explicitly model the distribution \(p(x)\), to determine whether a data point is well represented by inputs from our training data, or whether it is "out-of-distribution".<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="743"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="744"></td><td class="line-content">						<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Models that include the distribution of the input data are called <span class="html-tag">&lt;em&gt;</span>generative<span class="html-tag">&lt;/em&gt;</span> models.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="745"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="746"></td><td class="line-content">						<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Since inputs are typically continuous, this requires models for density estimation. We've seen many examples of such models in the course: Mixture models, VAEs, DDPMs, ... <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="747"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="748"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="749"></td><td class="line-content">					<span class="html-tag">&lt;div&gt;</span></td></tr><tr><td class="line-number" value="750"></td><td class="line-content">						<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>"<span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:80%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/Hullermeier-Waegeman2021_fig12.svg" rel="noreferrer noopener">Hullermeier-Waegeman2021_fig12.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="751"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="752"></td><td class="line-content">				<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="753"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="754"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="755"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="756"></td><td class="line-content">			<span class="html-tag">&lt;section <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:75%</span>"&gt;</span></td></tr><tr><td class="line-number" value="757"></td><td class="line-content">				<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:95%</span>"&gt;</span><span class="html-tag">&lt;h3&gt;</span>Quantifying epistemic uncertainty: generative models<span class="html-tag">&lt;/h3&gt;</span><span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="758"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="759"></td><td class="line-content">				<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="760"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-right:1em</span>"&gt;</span></td></tr><tr><td class="line-number" value="761"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>Out-of-distribution (OOD) detection is difficult.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="762"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="763"></td><td class="line-content">						<span class="html-tag">&lt;p&gt;</span>Active area of research.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="764"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="765"></td><td class="line-content">						<span class="html-tag">&lt;dl <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-left:0</span>" <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span></td></tr><tr><td class="line-number" value="766"></td><td class="line-content">							<span class="html-tag">&lt;dt&gt;</span>Perhaps low \(p(x)\) is not the best criterion for OOD?<span class="html-tag">&lt;/dt&gt;</span></td></tr><tr><td class="line-number" value="767"></td><td class="line-content">							<span class="html-tag">&lt;dd <span class="html-attribute-name">style</span>="<span class="html-attribute-value">margin-top:0.5em</span>"&gt;</span>Example: In high dimensions, the mode of a Gaussian has highest \(p(x)\), but is a very unlikely sample.<span class="html-tag">&lt;/dd&gt;</span></td></tr><tr><td class="line-number" value="768"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="769"></td><td class="line-content">							<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder center</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:75%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/prmlfigs-svg/Figure1.23.svg" rel="noreferrer noopener">../prmlfigs-svg/Figure1.23.svg</a>"&gt;</span></td></tr><tr><td class="line-number" value="770"></td><td class="line-content">						<span class="html-tag">&lt;/dl&gt;</span></td></tr><tr><td class="line-number" value="771"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="772"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="773"></td><td class="line-content">					<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:center</span>"&gt;</span></td></tr><tr><td class="line-number" value="774"></td><td class="line-content">						<span class="html-tag">&lt;div <span class="html-attribute-name">class</span>="<span class="html-attribute-value">container</span>"&gt;</span></td></tr><tr><td class="line-number" value="775"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:center; font-size:60%;</span>"&gt;</span>Fashion MNIST<span class="html-tag">&lt;br&gt;</span><span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder</span>"  <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/fmnist.png" rel="noreferrer noopener">fmnist.png</a>" <span class="html-attribute-name">alt</span>=""&gt;</span><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="776"></td><td class="line-content">							<span class="html-tag">&lt;div <span class="html-attribute-name">style</span>="<span class="html-attribute-value">text-align:center; font-size:60%;</span>"&gt;</span>MNIST<span class="html-tag">&lt;br&gt;</span><span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:100%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/mnist.png" rel="noreferrer noopener">mnist.png</a>" <span class="html-attribute-name">alt</span>=""&gt;</span><span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="777"></td><td class="line-content">						<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="778"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="779"></td><td class="line-content">						<span class="html-tag">&lt;img <span class="html-attribute-name">class</span>="<span class="html-attribute-value">noborder</span>" <span class="html-attribute-name">style</span>="<span class="html-attribute-value">width:80%</span>" <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/week7/do_deep_generative_models_know_fig3b.svg" rel="noreferrer noopener">do_deep_generative_models_know_fig3b.svg</a>" <span class="html-attribute-name">alt</span>=""&gt;</span></td></tr><tr><td class="line-number" value="780"></td><td class="line-content">						<span class="html-tag">&lt;span <span class="html-attribute-name">style</span>="<span class="html-attribute-value">font-size:40%; float:right; margin-top:1em; width:70%; text-align:left;</span>"&gt;</span>Figure from Nalisnick et al, Do Deep Generative Models Know What They Don't Know?, ICLR 2019<span class="html-tag">&lt;/span&gt;</span></td></tr><tr><td class="line-number" value="781"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="782"></td><td class="line-content">					<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="783"></td><td class="line-content">				<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="784"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="785"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="786"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="787"></td><td class="line-content">			<span class="html-tag">&lt;section&gt;</span></td></tr><tr><td class="line-number" value="788"></td><td class="line-content">				<span class="html-tag">&lt;h3&gt;</span>Conclusion<span class="html-tag">&lt;/h3&gt;</span></td></tr><tr><td class="line-number" value="789"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="790"></td><td class="line-content">				<span class="html-tag">&lt;p&gt;</span>Proper uncertainty quantification is essential if we aim to deploy ML systems in the real world.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="791"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="792"></td><td class="line-content">				<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Probabilistic methods play a central role in uncertainty quantification.<span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="793"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="794"></td><td class="line-content">				<span class="html-tag">&lt;p <span class="html-attribute-name">class</span>="<span class="html-attribute-value">fragment</span>"&gt;</span>Many open questions remain - this is still a very active area of research. <span class="html-tag">&lt;/p&gt;</span></td></tr><tr><td class="line-number" value="795"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="796"></td><td class="line-content">			<span class="html-tag">&lt;/section&gt;</span></td></tr><tr><td class="line-number" value="797"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="798"></td><td class="line-content">		<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="799"></td><td class="line-content">		<span class="html-tag">&lt;/div&gt;</span></td></tr><tr><td class="line-number" value="800"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="801"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/dist/reveal.js" rel="noreferrer noopener">../reveal.js-4.5.0/dist/reveal.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="802"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/plugin/notes/notes.js" rel="noreferrer noopener">../reveal.js-4.5.0/plugin/notes/notes.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="803"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/plugin/markdown/markdown.js" rel="noreferrer noopener">../reveal.js-4.5.0/plugin/markdown/markdown.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="804"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/plugin/highlight/highlight.js" rel="noreferrer noopener">../reveal.js-4.5.0/plugin/highlight/highlight.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="805"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/plugin/math/math.js" rel="noreferrer noopener">../reveal.js-4.5.0/plugin/math/math.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="806"></td><td class="line-content">		<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/reveal.js-4.5.0/plugin/zoom/zoom.js" rel="noreferrer noopener">../reveal.js-4.5.0/plugin/zoom/zoom.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="807"></td><td class="line-content">		<span class="html-tag">&lt;script&gt;</span></td></tr><tr><td class="line-number" value="808"></td><td class="line-content">			// More info about initialization &amp; config:</td></tr><tr><td class="line-number" value="809"></td><td class="line-content">			// - https://revealjs.com/initialization/</td></tr><tr><td class="line-number" value="810"></td><td class="line-content">			// - https://revealjs.com/config/</td></tr><tr><td class="line-number" value="811"></td><td class="line-content">			Reveal.initialize({</td></tr><tr><td class="line-number" value="812"></td><td class="line-content">				katex: {</td></tr><tr><td class="line-number" value="813"></td><td class="line-content">					trust:true</td></tr><tr><td class="line-number" value="814"></td><td class="line-content">				},</td></tr><tr><td class="line-number" value="815"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="816"></td><td class="line-content">				hash: true,</td></tr><tr><td class="line-number" value="817"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="818"></td><td class="line-content">				slideNumber: true,</td></tr><tr><td class="line-number" value="819"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="820"></td><td class="line-content">				transitionSpeed: 'fast',</td></tr><tr><td class="line-number" value="821"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="822"></td><td class="line-content">				// Learn about plugins: https://revealjs.com/plugins/</td></tr><tr><td class="line-number" value="823"></td><td class="line-content">				// plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.MathJax2 ]</td></tr><tr><td class="line-number" value="824"></td><td class="line-content">				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom, RevealMath.KaTeX() ]</td></tr><tr><td class="line-number" value="825"></td><td class="line-content">			});</td></tr><tr><td class="line-number" value="826"></td><td class="line-content">		<span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="827"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="828"></td><td class="line-content"><span class="html-comment">&lt;!--		&lt;script src="../jquery-3.6.0.min.js"&gt;&lt;/script&gt;--&gt;</span></td></tr><tr><td class="line-number" value="829"></td><td class="line-content"><span class="html-comment">&lt;!--	  &lt;script&gt;--&gt;</span></td></tr><tr><td class="line-number" value="830"></td><td class="line-content"><span class="html-comment">&lt;!--			$(document).ready(function() {--&gt;</span></td></tr><tr><td class="line-number" value="831"></td><td class="line-content"><span class="html-comment">&lt;!--				$(".prml.center").removeClass('center').wrap('&lt;div class="pmrlref" style="text-align: center"&gt;&lt;/div&gt;').parent().append('&lt;span style="writing-mode: vertical-rl; display: inline-block; font-size: 30%; margin-top:10%; vertical-align: top"&gt;Pattern Recognition and Machine Learning, Bishop&lt;/span&gt;');--&gt;</span></td></tr><tr><td class="line-number" value="832"></td><td class="line-content"><span class="html-comment">&lt;!--			});--&gt;</span></td></tr><tr><td class="line-number" value="833"></td><td class="line-content"><span class="html-comment">&lt;!--		&lt;/script&gt;--&gt;</span></td></tr><tr><td class="line-number" value="834"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="835"></td><td class="line-content">				<span class="html-tag">&lt;script <span class="html-attribute-name">src</span>="<a class="html-attribute-value html-resource-link" target="_blank" href="https://wouterboomsma.github.io/pml2024/jquery-3.6.0.min.js" rel="noreferrer noopener">../jquery-3.6.0.min.js</a>"&gt;</span><span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="836"></td><td class="line-content">			  <span class="html-tag">&lt;script&gt;</span></td></tr><tr><td class="line-number" value="837"></td><td class="line-content">					$(document).ready(function() {</td></tr><tr><td class="line-number" value="838"></td><td class="line-content">						$(".prml").wrap('&lt;a href="https://www.microsoft.com/en-us/research/people/cmbishop/prml-book" title="Figure from Pattern Recognition and Machine Learning, by Christopher Bishop."/&gt;&lt;/a&gt;');</td></tr><tr><td class="line-number" value="839"></td><td class="line-content">					});</td></tr><tr><td class="line-number" value="840"></td><td class="line-content">				<span class="html-tag">&lt;/script&gt;</span></td></tr><tr><td class="line-number" value="841"></td><td class="line-content"><br></td></tr><tr><td class="line-number" value="842"></td><td class="line-content">	<span class="html-tag">&lt;/body&gt;</span></td></tr><tr><td class="line-number" value="843"></td><td class="line-content"><span class="html-tag">&lt;/html&gt;</span></td></tr><tr><td class="line-number" value="844"></td><td class="line-content"><span class="html-end-of-file"></span></td></tr></tbody></table></body></html>