{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributions as tdist\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=2, distribution=\"bernoulli\"):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.distribution = distribution\n",
    "\n",
    "        # Encoder network\n",
    "        # Convolutional layers for Encoder\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            1, 32, kernel_size=4, stride=2, padding=1\n",
    "        )  # Input: (batch, 1, 28, 28) -> Output: (batch, 32, 14, 14)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            32, 64, kernel_size=4, stride=2, padding=1\n",
    "        )  # Input: (batch, 32, 14, 14) -> Output: (batch, 64, 7, 7)\n",
    "        # Fully connected layers to produce mu and logvar\n",
    "        self.fc_mu = nn.Linear(64 * 7 * 7, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64 * 7 * 7, latent_dim)\n",
    "\n",
    "        # Decoder network\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(latent_dim, 64 * 7 * 7)\n",
    "        # Transposed convolutional layers\n",
    "        self.deconv1 = nn.ConvTranspose2d(\n",
    "            64, 32, kernel_size=4, stride=2, padding=1\n",
    "        )  # Input: (batch, 64, 7, 7) -> Output: (batch, 32, 14, 14)\n",
    "        self.deconv2 = nn.ConvTranspose2d(\n",
    "            32, 1, kernel_size=4, stride=2, padding=1\n",
    "        )  # Input: (batch, 32, 14, 14) -> Output: (batch, 1, 28, 28)\n",
    "\n",
    "        # Decoder network for gaussian with learned variance\n",
    "        self.deconv3 = nn.ConvTranspose2d(\n",
    "            32, 2, kernel_size=4, stride=2, padding=1\n",
    "        )  # Input: (batch, 32, 14, 14) -> Output: (batch, 2, 28, 28)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)  # Standard deviation\n",
    "        eps = torch.randn_like(std)  # Random tensor with same shape as std\n",
    "        return mu + eps * std  # Reparameterization trick\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = F.relu(self.fc(z))\n",
    "        x = x.view(-1, 64, 7, 7)  # Reshape\n",
    "        x = F.relu(self.deconv1(x))\n",
    "\n",
    "        if self.distribution != \"gaussian_with_learned_variance\":\n",
    "            x = self.deconv2(x)\n",
    "            return torch.sigmoid(x)\n",
    "        else:\n",
    "            output = self.deconv3(x)\n",
    "            # Split the output into mean and log-variance\n",
    "            mu_x = output[:, 0, :, :]  # Mean of reconstructed image\n",
    "            logvar_x = output[:, 1, :, :]  # Log-variance of reconstructed image\n",
    "            return (torch.sigmoid(mu_x), F.softplus(logvar_x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Robert-Aduviri/Continuous-Bernoulli-VAE\n",
    "def sumlogC(x, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Numerically stable implementation of\n",
    "    sum of logarithm of Continous Bernoulli\n",
    "    constant C, using Taylor 2nd degree approximation\n",
    "\n",
    "    Parameter\n",
    "    ----------\n",
    "    x : Tensor of dimensions (batch_size, dim)\n",
    "        x takes values in (0,1)\n",
    "    \"\"\"\n",
    "    x = torch.clamp(x, eps, 1.0 - eps)\n",
    "    mask = torch.abs(x - 0.5).ge(eps)\n",
    "    far = torch.masked_select(x, mask)\n",
    "    close = torch.masked_select(x, ~mask)\n",
    "    far_values = torch.log((torch.log(1.0 - far) - torch.log(far)).div(1.0 - 2.0 * far))\n",
    "    close_values = torch.log(torch.tensor((2.0))) + torch.log(\n",
    "        1.0 + torch.pow(1.0 - 2.0 * close, 2) / 3.0\n",
    "    )\n",
    "    return far_values.sum() + close_values.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumlogC_optimized(x, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Optimized numerically stable implementation of\n",
    "    sum of logarithm of Continuous Bernoulli constant C,\n",
    "    using Taylor 2nd degree approximation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : Tensor of dimensions (batch_size, dim)\n",
    "        x takes values in (0,1)\n",
    "    eps : float, optional\n",
    "        Small value to prevent numerical instability near 0 and 1\n",
    "    \"\"\"\n",
    "    # Clamp x to avoid issues with log(0)\n",
    "    x = torch.clamp(x, eps, 1.0 - eps)\n",
    "\n",
    "    # Compute mask for elements far from 0.5\n",
    "    mask = torch.abs(x - 0.5) >= eps\n",
    "\n",
    "    # Precompute constants\n",
    "    log2 = torch.log(torch.tensor(2.0))\n",
    "    one_minus_2x = 1.0 - 2.0 * x\n",
    "\n",
    "    # Compute 'far_values' for elements where |x - 0.5| >= eps\n",
    "    numerator = torch.log1p(-x) - torch.log(x)  # log(1 - x) - log(x)\n",
    "    denominator = one_minus_2x\n",
    "    far_values = torch.log(numerator / denominator)\n",
    "\n",
    "    # Compute 'close_values' using Taylor approximation for elements where |x - 0.5| < eps\n",
    "    close_values = log2 + torch.log(1.0 + (one_minus_2x**2) / 3.0)\n",
    "\n",
    "    # Use torch.where to select appropriate values based on the mask\n",
    "    values = torch.where(mask, far_values, close_values)\n",
    "\n",
    "    # Return the sum of values\n",
    "    return values.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction=\"sum\")\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_divergence(mu, logvar):\n",
    "    q_z = tdist.Normal(loc=mu, scale=(0.5 * logvar).exp())\n",
    "    p_z = tdist.Normal(loc=torch.zeros_like(mu), scale=torch.ones_like(logvar))\n",
    "    KLD = tdist.kl_divergence(q_z, p_z).sum()\n",
    "    return KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_lambda_loss(recon_x, x, mu, logvar):\n",
    "    tmp = tdist.ContinuousBernoulli(probs=recon_x)\n",
    "    recon_x = tmp.mean\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction=\"sum\")\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    logC = sumlogC(recon_x)\n",
    "    return BCE + KLD + logC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_loss(recon_x, x, mu, logvar):\n",
    "    batch_size = x.size(0)\n",
    "    # Flatten recon_x and x to [batch_size, 784]\n",
    "    recon_x = recon_x.view(batch_size, -1)\n",
    "    x = x.view(batch_size, -1)\n",
    "\n",
    "    # Reconstruction loss (assuming a fixed variance, can use MSE)\n",
    "    MSE = F.mse_loss(recon_x, x, reduction=\"sum\")\n",
    "    # MSE /= batch_size  # Normalize by batch size\n",
    "\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(x_reconstructed_mu, x_reconstructed_logvar, x_true):\n",
    "    # x_true: [batch_size, height, width]\n",
    "    # x_reconstructed_mu: [batch_size, height, width]\n",
    "    # x_reconstructed_logvar: [batch_size, height, width]\n",
    "\n",
    "    # Flatten the images\n",
    "    x_true = x_true.view(x_true.size(0), -1)\n",
    "    x_reconstructed_mu = x_reconstructed_mu.view(x_reconstructed_mu.size(0), -1)\n",
    "    x_reconstructed_logvar = x_reconstructed_logvar.view(\n",
    "        x_reconstructed_logvar.size(0), -1\n",
    "    )\n",
    "\n",
    "    # Compute the negative log-likelihood\n",
    "    recon_loss = 0.5 * torch.sum(\n",
    "        x_reconstructed_logvar\n",
    "        + ((x_true - x_reconstructed_mu) ** 2) / torch.exp(x_reconstructed_logvar)\n",
    "        + torch.log(torch.tensor(2) * torch.pi),  # Sum over pixels\n",
    "    )\n",
    "    return recon_loss  # Mean over the batch\n",
    "\n",
    "\n",
    "def kl_divergence(mu_z, logvar_z):\n",
    "    # mu_z and logvar_z are of shape [batch_size, latent_dim]\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar_z - mu_z.pow(2) - logvar_z.exp())\n",
    "    return kl_div  # Mean over the batch\n",
    "\n",
    "\n",
    "def loss_cont_gaussian(recon_x, x_true, mu_z, logvar_z):\n",
    "    x_reconstructed_mu, x_reconstructed_logvar = recon_x\n",
    "    recon_loss = reconstruction_loss(x_reconstructed_mu, x_reconstructed_logvar, x_true)\n",
    "    kl_loss = kl_divergence(mu_z, logvar_z)\n",
    "    return recon_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_loss(alphas, betas, x, mu, logvar, beta_reg):\n",
    "    x = x.view(-1, 784)\n",
    "    recon_dist = tdist.Beta(alphas, betas)\n",
    "    recon_x = recon_dist.mean\n",
    "    recon_x = recon_x.view(-1, 784)\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction=\"sum\")\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fct(recon_x, x, mu, logvar, distribution):\n",
    "    if distribution == \"bernoulli\":\n",
    "        return vae_loss(recon_x, x, mu, logvar)\n",
    "    elif distribution == \"continuous_bernoulli\":\n",
    "        return cb_lambda_loss(recon_x, x, mu, logvar)\n",
    "    elif distribution == \"gaussian\":\n",
    "        return gaussian_loss(recon_x, x, mu, logvar)\n",
    "    elif distribution == \"gaussian_with_learned_variance\":\n",
    "        return loss_cont_gaussian(recon_x, x, mu, logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "torch.manual_seed(1);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for GPU or MPS availability. Use CPU if neither is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n",
    "\n",
    "# DataLoader instances will load tensors directly into GPU memory if device is set to 'cuda'\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if device == \"cuda\" else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"../data\", train=True, download=True, transform=transform),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    **kwargs,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"../data\", train=False, transform=transform),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    **kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, epoch, distribution):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for _, (data, _) in enumerate(\n",
    "        tqdm(\n",
    "            train_loader,\n",
    "            desc=f\"Distribution: {distribution} - Training Epoch {epoch}/{EPOCHS}\",\n",
    "        )\n",
    "    ):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_fn(recon_batch, data, mu, logvar, distribution)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print(f\"Epoch: {epoch} Average loss: {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loss_fn, epoch, distribution):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(\n",
    "            tqdm(\n",
    "                test_loader,\n",
    "                desc=f\"Distribution: {distribution} - Test Epoch {epoch}/{EPOCHS}\",\n",
    "            )\n",
    "        ):\n",
    "            data = data.to(device)\n",
    "\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_fn(recon_batch, data, mu, logvar, distribution)\n",
    "            test_loss += loss\n",
    "\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                if distribution == \"gaussian_with_learned_variance\":\n",
    "                    recon_batch = recon_batch[0]\n",
    "                recon_batch = recon_batch.view(BATCH_SIZE, 1, 28, 28)\n",
    "                comparison = torch.cat([data[:n], recon_batch[:n]])\n",
    "\n",
    "                save_image(\n",
    "                    comparison.cpu(),\n",
    "                    f\"../images/{model.distribution}/reconstruction_\"\n",
    "                    + str(epoch)\n",
    "                    + \".png\",\n",
    "                    nrow=n,\n",
    "                )\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"Test set loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = [\n",
    "    \"gaussian_with_learned_variance\",\n",
    "    # \"gaussian\",\n",
    "    # \"bernoulli\",\n",
    "    # \"continuous_bernoulli\",\n",
    "]\n",
    "\n",
    "for distribution in distributions:\n",
    "    model = VAE(latent_dim=latent_dim, distribution=distribution).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(model, optimizer, loss_fct, epoch, model.distribution)\n",
    "        test(model, loss_fct, epoch, model.distribution)\n",
    "        if distribution != \"gaussian_with_learned_variance\":\n",
    "            with torch.no_grad():\n",
    "                sample = torch.randn(64, latent_dim).to(device)\n",
    "                sample = model.decode(sample).cpu()\n",
    "                save_image(\n",
    "                    sample.view(64, 1, 28, 28),\n",
    "                    f\"../images/{model.distribution}/sample_\" + str(epoch) + \".png\",\n",
    "                )\n",
    "\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    torch.save(model, f\"../models/{model.distribution}_{timestr}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title=\"MNIST Samples\"):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation=\"nearest\")\n",
    "\n",
    "\n",
    "# Visualize dataset\n",
    "dataiter = iter(test_loader)\n",
    "mnist_images, mnist_labels = next(dataiter)\n",
    "\n",
    "\n",
    "model_vae = VAE(latent_dim=latent_dim, distribution=\"bernoulli\").to(device)\n",
    "model_cbvae = VAE(latent_dim=latent_dim, distribution=\"continuous_bernoulli\").to(device)\n",
    "model_gvae = VAE(latent_dim=latent_dim, distribution=\"gaussian\").to(device)\n",
    "model_gvvae = VAE(\n",
    "    latent_dim=latent_dim, distribution=\"gaussian_with_learned_variance\"\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# Load models\n",
    "model_vae = torch.load(\"../models/bernoulli_20250105-170534.pt\")\n",
    "model_cbvae = torch.load(\"../models/continuous_bernoulli_20250105-172440.pt\")\n",
    "model_gvae = torch.load(\"../models/gaussian_20250105-180253.pt\")\n",
    "model_gvvae = torch.load(\"../models/gaussian_with_learned_variance_20250105-185346.pt\")\n",
    "\n",
    "# Sample from models\n",
    "model_vae.eval()\n",
    "model_cbvae.eval()\n",
    "model_gvae.eval()\n",
    "model_gvvae.eval()\n",
    "\n",
    "num_samples = 12\n",
    "\n",
    "z = torch.randn(num_samples, 2).to(device)\n",
    "sample_cbvae = model_cbvae.decode(z).cpu().view(num_samples, 1, 28, 28).detach()\n",
    "sample_vae = model_vae.decode(z).cpu().view(num_samples, 1, 28, 28).detach()\n",
    "sample_gvae = model_gvae.decode(z).cpu().view(num_samples, 1, 28, 28).detach()\n",
    "\n",
    "\n",
    "mu_x, logvar_x = model_gvvae.decode(z)\n",
    "# Step 3: Sample x ~ N(μ_x, diag(σ_x^2))\n",
    "std_x = torch.exp(0.5 * logvar_x)\n",
    "eps = torch.randn_like(logvar_x)\n",
    "x_sampled = mu_x + eps * logvar_x\n",
    "# x_sampled = torch.sigmoid(x_sampled)\n",
    "sample_gvvae = x_sampled.cpu().view(num_samples, 1, 28, 28).detach()\n",
    "\n",
    "# Plot\n",
    "\n",
    "imshow(\n",
    "    torchvision.utils.make_grid(mnist_images[:num_samples], num_samples),\n",
    "    r\"MNIST Data Samples\",\n",
    ")\n",
    "imshow(\n",
    "    torchvision.utils.make_grid(sample_cbvae[:num_samples], num_samples),\n",
    "    r\"Samples from $\\mathcal{CB}$-VAE\",\n",
    ")\n",
    "imshow(\n",
    "    torchvision.utils.make_grid(sample_vae[:num_samples], num_samples),\n",
    "    r\"Samples from $\\mathcal{B}$-VAE\",\n",
    ")\n",
    "imshow(\n",
    "    torchvision.utils.make_grid(sample_gvae[:num_samples], num_samples),\n",
    "    r\"Samples from $\\mathcal{G}$-VAE\",\n",
    ")\n",
    "imshow(\n",
    "    torchvision.utils.make_grid(sample_gvvae[:num_samples], num_samples),\n",
    "    r\"Samples from $\\mathcal{G}$-VAE learned variance\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
