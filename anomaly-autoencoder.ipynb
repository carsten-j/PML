{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure! I'll provide an example of using an autoencoder for anomaly detection using the PyTorch framework. We'll go through the following steps:\n",
    "\n",
    "1. **Understanding Autoencoders and Anomaly Detection**\n",
    "2. **Setting Up the Environment**\n",
    "3. **Preparing the Dataset**\n",
    "4. **Defining the Autoencoder Model**\n",
    "5. **Training the Autoencoder**\n",
    "6. **Performing Anomaly Detection**\n",
    "7. **Evaluating the Results**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1. Understanding Autoencoders and Anomaly Detection\n",
    "\n",
    "**Autoencoders** are neural networks designed to learn efficient codings of input data in an unsupervised manner. They consist of two main parts:\n",
    "\n",
    "- **Encoder**: Compresses the input into a latent-space representation.\n",
    "- **Decoder**: Reconstructs the input from the latent space.\n",
    "\n",
    "The goal is to minimize the reconstruction error between the input and the output.\n",
    "\n",
    "In **anomaly detection**, autoencoders are trained on \"normal\" data and learn to reconstruct it well. When they see \"anomalous\" data (data that differs from the training distribution), they struggle to reconstruct it, resulting in a higher reconstruction error. By setting a threshold on this error, we can classify inputs as normal or anomalous.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Setting Up the Environment\n",
    "\n",
    "First, ensure you have PyTorch installed:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Preparing the Dataset\n",
    "\n",
    "We'll use the MNIST dataset for this example. We'll consider the digit '0' as normal data and all other digits as anomalies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation to apply to the images\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"data\", train=True, transform=transform, download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"data\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Filter the dataset to only include the normal class (digit '0')\n",
    "normal_class = 0\n",
    "\n",
    "# Indices of normal data in training set\n",
    "train_indices = [i for i, (x, y) in enumerate(train_dataset) if y != normal_class]\n",
    "# Indices of normal and anomalous data in test set\n",
    "test_indices_normal = [i for i, (x, y) in enumerate(test_dataset) if y != normal_class]\n",
    "test_indices_anomalous = [\n",
    "    i for i, (x, y) in enumerate(test_dataset) if y == normal_class\n",
    "]\n",
    "\n",
    "# Subset the datasets\n",
    "train_dataset_normal = Subset(train_dataset, train_indices)\n",
    "test_dataset_normal = Subset(test_dataset, test_indices_normal)\n",
    "test_dataset_anomalous = Subset(test_dataset, test_indices_anomalous)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset_normal, batch_size=batch_size, shuffle=True)\n",
    "test_loader_normal = DataLoader(\n",
    "    test_dataset_normal, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "test_loader_anomalous = DataLoader(\n",
    "    test_dataset_anomalous, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- We define a transformation to convert images to tensors.\n",
    "- We load the MNIST dataset.\n",
    "- We filter the dataset to only include images of the digit '0' for normal data.\n",
    "- For testing, we have both normal and anomalous data.\n",
    "- We create data loaders for easy batch processing.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Defining the Autoencoder Model\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 3),  # Latent space\n",
    "        )\n",
    "        # Decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid(),  # To get output values between 0 and 1\n",
    "            nn.Unflatten(1, (1, 28, 28)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **Encoder**: Compresses the 28x28 image into a 3-dimensional latent space.\n",
    "- **Decoder**: Reconstructs the image from the latent space.\n",
    "- Uses `ReLU` activations in hidden layers and `Sigmoid` activation in the output layer to ensure pixel values are between 0 and 1.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Training the Autoencoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0597\n",
      "Epoch [2/5], Loss: 0.0424\n",
      "Epoch [3/5], Loss: 0.0385\n",
      "Epoch [4/5], Loss: 0.0369\n",
      "Epoch [5/5], Loss: 0.0357\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        imgs, _ = data  # Ignore labels\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, imgs)  # Reconstruction loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- We define the mean squared error loss between the input and the reconstructed output.\n",
    "- The model is trained only on normal data (digit '0').\n",
    "- After each epoch, the average loss is printed to monitor training progress.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Performing Anomaly Detection\n",
    "\n",
    "We use the reconstruction error to detect anomalies. Higher errors indicate anomalies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute reconstruction errors\n",
    "def compute_reconstruction_errors(loader):\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            imgs, _ = data\n",
    "            outputs = model(imgs)\n",
    "            # Reshape images and outputs to (batch_size, -1)\n",
    "            imgs = imgs.view(imgs.size(0), -1)\n",
    "            outputs = outputs.view(outputs.size(0), -1)\n",
    "            # Compute per-sample reconstruction errors\n",
    "            batch_errors = torch.mean((outputs - imgs) ** 2, dim=1)\n",
    "            errors.extend(batch_errors.cpu().numpy())\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- **Flattening the Inputs and Outputs:**\n",
    "  - We reshape `imgs` and `outputs` to 2D tensors with shape `[batch_size, num_features]` using `view(imgs.size(0), -1)`.\n",
    "  \n",
    "- **Computing Reconstruction Error Per Sample:**\n",
    "  - We calculate the mean squared error between each reconstructed sample and its corresponding input.\n",
    "  - `torch.mean((outputs - imgs) ** 2, dim=1)` computes the mean squared error for each sample in the batch (along the feature dimension).\n",
    "\n",
    "- **Collecting Errors:**\n",
    "  - We extend the `errors` list with the per-sample errors by converting them to NumPy arrays.\n",
    "\n",
    "**Now, compute the errors:**\n",
    "\n",
    "```python\n",
    "# Ensure the model is in evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# Compute errors on normal and anomalous test data\n",
    "errors_normal = compute_reconstruction_errors(test_loader_normal)\n",
    "errors_anomalous = compute_reconstruction_errors(test_loader_anomalous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Evaluating the Results\n",
    "\n",
    "Plot the reconstruction errors and set a threshold to distinguish between normal and anomalous data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error threshold: 0.0704\n",
      "Anomaly detection accuracy: 93.48%\n"
     ]
    }
   ],
   "source": [
    "# Plot histograms of reconstruction errors\n",
    "plt.hist(errors_normal, bins=50, alpha=0.5, label=\"Normal\")\n",
    "plt.hist(errors_anomalous, bins=50, alpha=0.5, label=\"Anomalous\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Reconstruction error\")\n",
    "plt.ylabel(\"Number of examples\")\n",
    "plt.show()\n",
    "\n",
    "# Compute threshold (e.g., mean + 2*std of normal errors)\n",
    "threshold = np.mean(errors_normal) + 2 * np.std(errors_normal)\n",
    "print(f\"Reconstruction error threshold: {threshold:.4f}\")\n",
    "\n",
    "# Classification based on threshold\n",
    "true_labels = np.concatenate(\n",
    "    [np.zeros(len(errors_normal)), np.ones(len(errors_anomalous))]\n",
    ")\n",
    "predicted_labels = np.concatenate(\n",
    "    [np.array(errors_normal) > threshold, np.array(errors_anomalous) > threshold]\n",
    ")\n",
    "\n",
    "# Compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Anomaly detection accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- We plot histograms of reconstruction errors for normal and anomalous data to visualize the separation.\n",
    "- We set a threshold based on the distribution of normal errors.\n",
    "- We classify examples as anomalies if their reconstruction error exceeds the threshold.\n",
    "- We compute the accuracy of our anomaly detection model.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Detailed Explanation\n",
    "\n",
    "**Data Preparation:**\n",
    "\n",
    "- **Normal Data**: All images of digit '0'.\n",
    "- **Anomalous Data**: Images of digits '1' to '9'.\n",
    "\n",
    "**Model Training:**\n",
    "\n",
    "- The autoencoder learns to reconstruct images of digit '0'.\n",
    "- Since it's only trained on normal data, it expects inputs similar to the normal class.\n",
    "\n",
    "**Anomaly Detection:**\n",
    "\n",
    "- **Reconstruction Error**: Calculated as the mean squared error between input and output.\n",
    "- **Threshold Setting**: Based on the reconstruction errors of normal data.\n",
    "  - We use `threshold = mean + 2 * std` of normal errors.\n",
    "- **Classification**:\n",
    "  - **Normal**: Reconstruction error ≤ threshold.\n",
    "  - **Anomalous**: Reconstruction error > threshold.\n",
    "\n",
    "**Evaluation:**\n",
    "\n",
    "- **Accuracy**: Percentage of correctly classified examples (both normal and anomalous).\n",
    "- **Visualization**: Histograms show the separation between normal and anomalous reconstruction errors.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This example demonstrates how an autoencoder can be used for anomaly detection. By training the model on normal data, it learns to reconstruct this data well. When it encounters data that differs from the training distribution (anomalies), the reconstruction error increases, allowing us to detect anomalies.\n",
    "\n",
    "**Important Points:**\n",
    "\n",
    "- The choice of threshold is crucial for the performance of anomaly detection.\n",
    "- The model's capacity and training quality affect its ability to reconstruct normal data accurately.\n",
    "- This approach assumes that anomalies are sufficiently different from normal data so that the autoencoder cannot reconstruct them well.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you have any questions or need further clarification on any part of the code or the concepts involved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where are we explicit for anomaly detecting using that this neurale network is an autoencoder and not just a network that can recognize images of digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's an excellent question! Let me clarify how we are utilizing the autoencoder architecture specifically for anomaly detection and how it differs from a typical classification neural network that recognizes digits.\n",
    "\n",
    "---\n",
    "\n",
    "## **Understanding the Difference: Autoencoder vs. Classifier**\n",
    "\n",
    "### **Autoencoder:**\n",
    "\n",
    "- **Purpose:** Learn to **reconstruct its input** data.\n",
    "- **Training Data:** Typically trained **only on normal data**.\n",
    "- **Anomaly Detection Mechanism:** Based on **reconstruction error**.\n",
    "  - **Normal Data:** Low reconstruction error.\n",
    "  - **Anomalous Data:** High reconstruction error because the autoencoder hasn't learned features from anomalous data.\n",
    "\n",
    "### **Classifier:**\n",
    "\n",
    "- **Purpose:** Learn to **assign labels** to input data (e.g., digit recognition).\n",
    "- **Training Data:** Requires labeled data for **all classes** you want to recognize.\n",
    "- **Anomaly Detection Mechanism:** Can detect known classes but may not generalize well to unknown anomalies; typically doesn't perform well in **unsupervised anomaly detection** without retraining.\n",
    "\n",
    "---\n",
    "\n",
    "## **How the Autoencoder is Used for Anomaly Detection in Our Code**\n",
    "\n",
    "In the provided code:\n",
    "\n",
    "1. **Training Phase:**\n",
    "\n",
    "   - **Data Used:** We train the autoencoder **only on images of the digit '0'** (our normal class).\n",
    "   - **Objective:** The autoencoder learns to **encode and then decode** these images, minimizing the reconstruction error (difference between the input and reconstructed output).\n",
    "   - **No Labels Used for Reconstruction:** The labels (digits) are not used during training, except for filtering normal data. The autoencoder doesn't learn to classify or recognize digits.\n",
    "\n",
    "2. **Anomaly Detection Phase:**\n",
    "\n",
    "   - **Data Used:** We test the autoencoder on both **normal data** (digit '0') and **anomalous data** (digits '1' to '9').\n",
    "   - **Mechanism:**\n",
    "     - **Reconstruction Error Computed:** For each test image, we compute the **reconstruction error** (mean squared error between the original and reconstructed images).\n",
    "     - **Threshold Applied:** We use a threshold (e.g., mean plus two standard deviations of normal data errors) to decide whether a test image is normal or anomalous.\n",
    "       - **If the reconstruction error is below the threshold:** The image is considered **normal**.\n",
    "       - **If the reconstruction error is above the threshold:** The image is considered **anomalous**.\n",
    "\n",
    "3. **No Classification of Digits:**\n",
    "\n",
    "   - The autoencoder **does not learn to classify digits**.\n",
    "   - It doesn't output labels or probabilities for different digits.\n",
    "   - It **only tries to reconstruct** the input images it was trained on (digit '0' images).\n",
    "\n",
    "---\n",
    "\n",
    "## **Why It's Not Just a Digit Recognizer**\n",
    "\n",
    "- **Absence of Classification Layers:**\n",
    "  - There are **no layers dedicated to classification** (e.g., softmax or logistic regression layers).\n",
    "  - The network ends with reconstruction layers, aiming to output an image, not a class label.\n",
    "\n",
    "- **Use of Reconstruction Error:**\n",
    "  - The decision to label data as normal or anomalous is based on **how well the data can be reconstructed**, not on classification accuracy.\n",
    "  - An image of digit '1' will likely have a **higher reconstruction error** because the autoencoder hasn't learned the features specific to digit '1'.\n",
    "\n",
    "- **Unsupervised Learning Approach:**\n",
    "  - The autoencoder is trained in an **unsupervised manner** with respect to class labels.\n",
    "  - It learns the **underlying structure of normal data** without any explicit instruction about anomalies.\n",
    "\n",
    "---\n",
    "\n",
    "## **Detailed Explanation with Code References**\n",
    "\n",
    "### **Training the Autoencoder on Normal Data Only**\n",
    "\n",
    "```python\n",
    "# Filter the dataset to only include the normal class (digit '0')\n",
    "normal_class = 0\n",
    "\n",
    "# Indices of normal data in training set\n",
    "train_indices = [i for i, (x, y) in enumerate(train_dataset) if y == normal_class]\n",
    "\n",
    "# Subset the training dataset to include only normal data\n",
    "train_dataset_normal = Subset(train_dataset, train_indices)\n",
    "\n",
    "# Data loader for training on normal data only\n",
    "train_loader = DataLoader(train_dataset_normal, batch_size=batch_size, shuffle=True)\n",
    "```\n",
    "\n",
    "- **Purpose:** Ensures the autoencoder **only sees normal data** during training.\n",
    "\n",
    "### **Autoencoder Architecture**\n",
    "\n",
    "```python\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            # ...\n",
    "        )\n",
    "        # Decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            # ...\n",
    "            nn.Unflatten(1, (1, 28, 28))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "- **Key Points:**\n",
    "  - **No classification layers:** The network is designed to **reconstruct** input images.\n",
    "  - **Latent Space Representation:** The encoder compresses the data into a lower-dimensional latent space.\n",
    "\n",
    "### **Computing Reconstruction Errors for Anomaly Detection**\n",
    "\n",
    "```python\n",
    "def compute_reconstruction_errors(loader):\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            imgs, _ = data\n",
    "            outputs = model(imgs)\n",
    "            # Reshape images and outputs to (batch_size, -1)\n",
    "            imgs = imgs.view(imgs.size(0), -1)\n",
    "            outputs = outputs.view(outputs.size(0), -1)\n",
    "            # Compute per-sample reconstruction errors\n",
    "            batch_errors = torch.mean((outputs - imgs) ** 2, dim=1)\n",
    "            errors.extend(batch_errors.cpu().numpy())\n",
    "    return errors\n",
    "```\n",
    "\n",
    "- **Function Purpose:** Computes the **reconstruction error** for each sample in the dataset.\n",
    "- **Error Calculation:** Mean squared error between the input image and its reconstruction.\n",
    "\n",
    "### **Setting Threshold and Detecting Anomalies**\n",
    "\n",
    "```python\n",
    "# Compute errors on normal and anomalous test data\n",
    "errors_normal = compute_reconstruction_errors(test_loader_normal)\n",
    "errors_anomalous = compute_reconstruction_errors(test_loader_anomalous)\n",
    "\n",
    "# Compute threshold based on normal data reconstruction errors\n",
    "threshold = np.mean(errors_normal) + 2 * np.std(errors_normal)\n",
    "\n",
    "# Classify samples based on whether their reconstruction error exceeds the threshold\n",
    "predicted_labels_normal = np.array(errors_normal) > threshold\n",
    "predicted_labels_anomalous = np.array(errors_anomalous) > threshold\n",
    "```\n",
    "\n",
    "- **Threshold Setting:** Based on statistics of the reconstruction errors of normal data.\n",
    "- **Anomaly Detection:** Samples exceeding the threshold are labeled as anomalies.\n",
    "- **No Classification Based on Digit Recognition:** We are not using any digit recognition logic; instead, we rely solely on the autoencoder's reconstruction capability.\n",
    "\n",
    "---\n",
    "\n",
    "## **Why a Classifier Would Not Serve the Same Purpose**\n",
    "\n",
    "- **Limitation in Detecting Unknown Anomalies:**\n",
    "  - A classifier trained to recognize digits '0' to '9' may not detect **anomalies that are outside the known classes**.\n",
    "  - It would attempt to classify any input into one of the known classes.\n",
    "\n",
    "- **Supervised vs. Unsupervised Learning:**\n",
    "  - Classifiers require **labeled data** and **supervised learning**.\n",
    "  - Our goal is to detect anomalies **without explicit labels for anomalies**, which is better suited for **unsupervised learning** methods like autoencoders.\n",
    "\n",
    "- **Generalization to Unknown Anomalies:**\n",
    "  - Autoencoders can potentially detect any data that deviates from the normal pattern, including **unknown or unforeseen anomalies**.\n",
    "  - Classifiers are limited to distinguishing between predefined classes.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conceptual Summary**\n",
    "\n",
    "- **Autoencoder for Anomaly Detection:**\n",
    "  - Learns to reconstruct normal data patterns.\n",
    "  - Anomalies are detected when the data cannot be reconstructed well (high reconstruction error).\n",
    "\n",
    "- **Classifier for Digit Recognition:**\n",
    "  - Learns to assign labels to input data based on features.\n",
    "  - Doesn't inherently have a mechanism for detecting data that doesn't fit into known classes.\n",
    "\n",
    "---\n",
    "\n",
    "## **An Illustration with Reconstruction Examples**\n",
    "\n",
    "To further clarify, let's consider what happens when the autoencoder processes normal vs. anomalous data:\n",
    "\n",
    "### **Processing Normal Data (Digit '0'):**\n",
    "\n",
    "- **Input:** Image of digit '0'.\n",
    "- **Reconstruction:** Since the autoencoder is trained on digit '0', it can reconstruct it accurately.\n",
    "- **Reconstruction Error:** Low.\n",
    "\n",
    "### **Processing Anomalous Data (Digit '2'):**\n",
    "\n",
    "- **Input:** Image of digit '2'.\n",
    "- **Reconstruction:** The autoencoder has never seen digit '2' during training; thus, it cannot reconstruct it accurately.\n",
    "- **Reconstruction Error:** High.\n",
    "\n",
    "**Visualization:**\n",
    "\n",
    "- **Original and Reconstructed Images:**\n",
    "  - For normal data, the reconstructed image closely matches the original.\n",
    "  - For anomalous data, the reconstructed image differs significantly, often resembling features of the normal data it was trained on.\n",
    "\n",
    "---\n",
    "\n",
    "## **Practical Implications**\n",
    "\n",
    "- **Detection of Novel Anomalies:**\n",
    "  - The autoencoder can detect anomalies that are **not predefined**, making it useful in scenarios where anomalies are rare or unknown.\n",
    "\n",
    "- **No Need for Anomaly Labels:**\n",
    "  - Since anomalies are defined by deviation from normal patterns, we don't need labeled anomalous data.\n",
    "\n",
    "- **Applicability:**\n",
    "  - This approach is widely used in fields like **fraud detection**, **fault detection in machinery**, and **network intrusion detection**, where anomalies are rare and varied.\n",
    "\n",
    "---\n",
    "\n",
    "## **Summary**\n",
    "\n",
    "- **Explicit Use of Autoencoder:**\n",
    "  - The network's architecture and training procedure are designed specifically for **reconstruction**, not classification.\n",
    "  - Anomaly detection leverages the autoencoder's inability to reconstruct unseen or anomalous data accurately.\n",
    "\n",
    "- **Not a Digit Recognition Network:**\n",
    "  - The model doesn't recognize or classify digits; it doesn't output labels.\n",
    "  - Labels are only used to select **normal data** during training and to evaluate performance during testing.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "- By training an autoencoder solely on normal data and using the reconstruction error as a metric, we explicitly use the autoencoder's properties for anomaly detection.\n",
    "- This method is fundamentally different from a classification network that recognizes digits, both in architecture and in the way we use the network for detecting anomalies.\n",
    "\n",
    "---\n",
    "\n",
    "**Feel free to ask if you have further questions or need more clarification on any aspect!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
