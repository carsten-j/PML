# Automatically generated by Colab.

# Original file is located at
#    https://colab.research.google.com/drive/1qnfTtq_hGrOn4c8iKdJZsIFNIdW5fyrd

# Iris data set: inference with NUTS solution

import numpy
import pyro
import pyro.distributions as pdist
import torch
from sklearn import model_selection
from sklearn.datasets import load_iris

"""Function to evaluate the accuracy of our trained model."""


def accuracy(pred, data):
    """
    Calculate accuracy of predicted labels (integers).

    pred: predictions, tensor[sample_index, chain_index, data_index, logits]
    data: actual data (digit), tensor[data_index]

    Prediction is taken as most common predicted value.
    Returns accuracy (#correct/#total).
    """
    n = data.shape[0]
    correct = 0
    total = 0
    for i in range(0, n):
        # Get most common prediction value from logits
        pred_i = int(torch.argmax(torch.sum(pred[:, 0, i, :], 0)))
        # Compare prediction with data
        if int(data[i]) == int(pred_i):
            correct += 1.0
        total += 1.0
    # Return fractional accuracy
    return correct / total


def accuracy2(pred, data):
    # Sum over samples and chains
    pred_sum = torch.sum(pred, dim=(0, 1))
    # Get predictions
    pred_i = torch.argmax(pred_sum, dim=1)
    # Calculate accuracy
    correct = torch.sum(pred_i == data).item()
    return correct / data.shape[0]


"""The probabilistic model, implemented as a callable class. We could also simply use a function.
"""


class Model:
    def __init__(self, x_dim=4, y_dim=3, h_dim=5):
        self.x_dim = x_dim
        self.y_dim = y_dim
        self.h_dim = h_dim

    def __call__(self, x, y=None):
        """
        We need None for predictive
        """
        x_dim = self.x_dim
        y_dim = self.y_dim
        h_dim = self.h_dim
        # Number of observations
        n = x.shape[0]
        # standard deviation of Normals
        sd = 1  # EXERCISE: 100->1
        # Layer 1
        w1 = pyro.sample("w1", pdist.Normal(0, sd).expand([x_dim, h_dim]).to_event(2))
        b1 = pyro.sample("b1", pdist.Normal(0, sd).expand([h_dim]).to_event(1))
        # Layer 2 # EXERCISE: added layer
        w2 = pyro.sample("w2", pdist.Normal(0, sd).expand([h_dim, h_dim]).to_event(2))
        b2 = pyro.sample("b2", pdist.Normal(0, sd).expand([h_dim]).to_event(1))
        # Layer 3
        w3 = pyro.sample("w3", pdist.Normal(0, sd).expand([h_dim, y_dim]).to_event(2))
        b3 = pyro.sample("b3", pdist.Normal(0, sd).expand([y_dim]).to_event(1))
        # NN
        h1 = torch.tanh((x @ w1) + b1)
        h2 = torch.tanh((h1 @ w2) + b2)  # EXERCISE: added layer
        logits = h2 @ w3 + b3
        # Save deterministc variable (logits) in trace
        pyro.deterministic("logits", logits)
        # Categorical likelihood
        with pyro.plate("labels", n):
            obs = pyro.sample("obs", pdist.Categorical(logits=logits), obs=y)


if __name__ == "__main__":
    # Set some parameters for inference and make reproducible.
    seed_value = 42  # Replace with your desired seed value
    torch.manual_seed(seed_value)
    pyro.set_rng_seed(seed_value)
    numpy.random.seed(seed_value)

    # Iris data set
    iris = load_iris()
    x_all = torch.tensor(iris.data, dtype=torch.float)  # Input vector (4D)
    y_all = torch.tensor(iris.target, dtype=torch.int)  # Label(3 classes)

    # Make training and test set
    x_train, x_test, y_train, y_test = model_selection.train_test_split(
        x_all, y_all, test_size=0.33, random_state=42
    )

    print("Data set / test set sizes: %i, %i." % (x_train.shape[0], x_test.shape[0]))

    # Instantiate the Model object
    model = Model()

    nuts_kernel = pyro.infer.NUTS(model, jit_compile=True)
    mcmc = pyro.infer.MCMC(nuts_kernel, num_samples=100, num_chains=2, warmup_steps=100)

    # Clear any previously used parameters
    pyro.clear_param_store()
    mcmc.run(x_train, y_train)

    posterior_samples = mcmc.get_samples()
    posterior_predictive = pyro.infer.Predictive(model, posterior_samples)(
        x=x_test, y=None
    )

    # Evaluate the accuracy of the model on the test set.
    # Print accuracy
    logits = posterior_predictive["logits"]
    print("Shape of posterior preditive for y (logits):", logits.shape)
    print("Success: %.2f" % accuracy(logits, y_test))
    print("Success: %.2f" % accuracy2(logits, y_test))

    # Az summary
    # data = az.from_pyro(mcmc)
    # summary = az.summary(data)
    # print(summary)
    # # Density plot
    # az.plot_posterior(data, var_names=("b1"))
    # plt.show()
    # # Trace plot
    # az.plot_trace(data, var_names=("b1"), kind="rank_bars")
    # plt.show()
